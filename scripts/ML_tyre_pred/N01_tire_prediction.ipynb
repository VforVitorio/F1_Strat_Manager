{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tire Degradation Prediction Model - Week 5\n",
    "\n",
    "## Overview\n",
    "This notebook implements advanced models to predict tire degradation in Formula 1 races. Since tire degradation is not strictly linear and depends on multiple factors (compound type, track temperature, driving style, etc.), we'll use sequence models like LSTM to capture these complex patterns.\n",
    "\n",
    "## Approach\n",
    "1. **Data Exploration**\n",
    "   - Analyze the relationship between lap times and tire age\n",
    "   - Visualize performance degradation patterns by compound\n",
    "   - Determine how to quantify \"degradation\" (lap time delta or derived metric)\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Create a derived tire degradation metric\n",
    "   - Organize data into sequential format for LSTM\n",
    "   - Normalize features appropriately\n",
    "   - Create sliding windows of previous laps to predict future performance\n",
    "\n",
    "3. **Model Development**\n",
    "   - **Primary Model**: LSTM network to predict degradation trajectory\n",
    "   - **Alternative Model**: XGBoost with quantile regression for uncertainty estimation\n",
    "\n",
    "4. **Evaluation & Visualization**\n",
    "   - Compare predicted vs. actual degradation curves\n",
    "   - Analyze performance across different compounds and race conditions\n",
    "   - Create interactive Plotly visualizations of degradation patterns\n",
    "\n",
    "5. **Implementation Details**\n",
    "   - Sequence length: 5 laps (input) → predict next 3-5 laps\n",
    "   - Features: Tire age, compound, lap time trends, fuel load\n",
    "   - Target: Derived degradation metric or direct lap time prediction\n",
    "\n",
    "## Expected Outcomes\n",
    "- Trained model to predict tire performance over extended stints\n",
    "- Uncertainty bounds for degradation predictions (10th, 50th, 90th percentiles)\n",
    "- Interactive visualization of degradation curves by compound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries and Creatind New Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions from our module\n",
    "from ML_utils.lap_prediction import compound_colors, compound_names\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs('../../outputs/week5', exist_ok=True)\n",
    "os.makedirs('../../models/week5', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../outputs/week3/lap_prediction_data.csv\")\n",
    "print(\"\\nRegular data sample:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = pd.read_csv(\"../../outputs/week3/sequential_lap_prediction_data.csv\")\n",
    "print(\"\\nSequential data sample:\")\n",
    "display(seq_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Basic dataset information:\")\n",
    "print(f\"Regular data shape: {data.shape}\")\n",
    "print(f\"Sequential data shape: {seq_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Locating Tire Related Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for tire-related columns\n",
    "tire_columns = ['CompoundID', 'TyreAge']\n",
    "print(f\"\\nTire-related columns: {tire_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for tire-related columns\n",
    "print(\"\\nTire-related statistics:\")\n",
    "display(data[tire_columns].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compound Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print compound mappings for reference\n",
    "print(\"\\nCompound mappings:\")\n",
    "print(f\"Compound names: {compound_names}\")\n",
    "print(f\"Compound colors: {compound_colors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Relationship between Tire Age and Lap Time by compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between tire age and lap time by compound\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Group by compound and tire age\n",
    "for compound_id in data['CompoundID'].unique():\n",
    "    subset = data[data['CompoundID'] == compound_id]\n",
    "    \n",
    "    # Aggregate by tire age\n",
    "    agg_data = subset.groupby('TyreAge')['LapTime'].agg(['mean', 'std', 'count']).reset_index()\n",
    "    \n",
    "    # Only plot if we have enough data points\n",
    "    if len(agg_data) > 1:\n",
    "        color = compound_colors.get(compound_id, 'black')\n",
    "        compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "        \n",
    "        plt.plot(agg_data['TyreAge'], agg_data['mean'], 'o-', \n",
    "                 color=color, label=f'{compound_name} Tire')\n",
    "        \n",
    "        # Add error bands (standard deviation)\n",
    "        if 'std' in agg_data.columns:\n",
    "            plt.fill_between(agg_data['TyreAge'], \n",
    "                            agg_data['mean'] - agg_data['std'], \n",
    "                            agg_data['mean'] + agg_data['std'],\n",
    "                            color=color, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Tire Age (laps)')\n",
    "plt.ylabel('Lap Time (s)')\n",
    "plt.title('Tire Degradation: Effect on Lap Time')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../../outputs/week5/tire_deg_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploring Lap Times Deltas and Tire Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore lap time deltas as tire ages\n",
    "if 'LapTime_Delta' in seq_data.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for compound_id in seq_data['CompoundID'].unique():\n",
    "        subset = seq_data[seq_data['CompoundID'] == compound_id]\n",
    "        \n",
    "        # Aggregate by tire age\n",
    "        agg_data = subset.groupby('TyreAge')['LapTime_Delta'].mean().reset_index()\n",
    "        \n",
    "        # Only plot if we have enough data points\n",
    "        if len(agg_data) > 1:\n",
    "            color = compound_colors.get(compound_id, 'black')\n",
    "            compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "            \n",
    "            plt.plot(agg_data['TyreAge'], agg_data['LapTime_Delta'], 'o-', \n",
    "                     color=color, label=f'{compound_name} Tire')\n",
    "    \n",
    "    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Tire Age (laps)')\n",
    "    plt.ylabel('Lap Time Delta (s) - Positive means getting slower')\n",
    "    plt.title('Lap Time Degradation Rate by Tire Age')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('../../outputs/week5/tire_deg_rate.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploring if Tire Age affects Speed in different Sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how tire age affects speed in different sectors\n",
    "speed_columns = ['SpeedI1', 'SpeedI2', 'SpeedFL']\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for speed_col in speed_columns:\n",
    "    # Focus on compound ID 2 (Medium) since that's what we have in the data\n",
    "    subset = data[data['CompoundID'] == 2]\n",
    "    \n",
    "    # Aggregate by tire age\n",
    "    agg_data = subset.groupby('TyreAge')[speed_col].mean().reset_index()\n",
    "    \n",
    "    if len(agg_data) > 1:\n",
    "        plt.plot(agg_data['TyreAge'], agg_data[speed_col], 'o-', \n",
    "                 label=f'{speed_col}')\n",
    "\n",
    "plt.xlabel('Tire Age (laps)')\n",
    "plt.ylabel('Speed (kph)')\n",
    "plt.title(f'Effect of Tire Age on Speed - {compound_names.get(2)} Tires')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../../outputs/week5/tire_age_speed_effect.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Creating Tire Degradation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For being able to predict tyre degradation more effectively, a good option can be generate more variables with the current data that we have. Therefore, I´ll add this new variables:\n",
    "\n",
    "## Disclaimer: importance of fuel load.\n",
    "\n",
    "After making the cells and looking at the data, some tires shows positive degradation. That means that lap times are descending instead of going up. This is caused due to the less amount of fuel during the race. Therefore, I need to **create an adjusted lap time** that takes into account this fuel factor before creating our prediction models. \n",
    "\n",
    "Then, I will create this variable and then adjust the plots and variable calculation for fitting this feature.\n",
    "\n",
    "*NOTE*: fuel burn calculation and impact will be calculated according to this articles: \n",
    "\n",
    "- [BBC Sport Weight Reduction](https://www.bbc.com/sport/articles/cv2g715dkk1o#:~:text=A%201.5kg%20reduction%20in,so%20over%20a%20race%20distance.)\n",
    "\n",
    "- [Fuel Correction Analysis, Medium](https://medium.com/@umakschually/fuel-correction-29ccd98ae62b#:~:text=Rule%20of%20thumb%20is%20that,tyre%20age%20or%20anything%20else.)\n",
    "\n",
    "#### 1. Absolute Tire Degradation (TireDegAbsolute)\n",
    "\n",
    "Its objective is to **measure how much seconds is the actual lap time slower, compared with the baseline** (new tires or with the less degradation possible, for instance, only 2 laps).\n",
    "\n",
    "**Positive values** implie degradation (car is getting slower). As I said, it would be measured in **seconds**.\n",
    "\n",
    "- *Utility*:\n",
    "    - Allows knowing the direct impact on lap time.\n",
    "    - Helps to determine the *cross point* when a pit stop becomes an advantage.\n",
    "    - Fundamental for strategic calculus, as teams work with absolute times.\n",
    "    - Helps us answering the following: **How many seconds are we losing per lap with degradation?**\n",
    "\n",
    "#### 2. Tire Degradation Percentage \n",
    "\n",
    "It expresses degradation as an **augmenting percentage** to base time. For instance, 2% means the car is 2% slower than with new tires.\n",
    "\n",
    "- *Utility*:\n",
    "    - Allows more intuitive comparisons between different conditions.\n",
    "    - Normalizes the data for more clear comparisons between tires.\n",
    "    - Helps us aswering the following:**Which compound maintains better its relative performance?**\n",
    "\n",
    "#### 3. Degradation Rate\n",
    "\n",
    "Means how much time increases per lap with each aditional lap. Represents the first derivative of degradation curve. \n",
    "\n",
    "- *Utility:*\n",
    "    - Allows knowing if degradation is lineal, progressive or if it stabilizes.\n",
    "    - Crucial for estimating optimum pit stop window during races.\n",
    "    - Allows anticipating future compound´s behaviour.\n",
    "    - Helps us answering the following: **Degradation is getting worse or it is stabilizing?**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Lap Time Improvement Per Lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear métricas de degradación ajustadas usando directamente la mejora de tiempo por vuelta\n",
    "# Tiempo que mejora cada vuelta debido a la reducción de combustible\n",
    "LAP_TIME_IMPROVEMENT_PER_LAP = 0.055  # segundos por vuelta (punto medio de 0.05-0.06s)\n",
    "\n",
    "# Create a DataFrame to store all results with fuel adjustment\n",
    "tire_deg_data = pd.DataFrame()\n",
    "\n",
    "# Process each compound separately\n",
    "for compound_id in data['CompoundID'].unique():\n",
    "    compound_name = compound_names.get(compound_id, f\"Unknown ({compound_id})\")\n",
    "    print(f\"Processing {compound_name} tires (ID: {compound_id})...\")\n",
    "    \n",
    "    # Filter for this compound\n",
    "    compound_data = data[data['CompoundID'] == compound_id].copy()\n",
    "    \n",
    "    # Sort by TyreAge to see the degradation trend\n",
    "    compound_data = compound_data.sort_values('TyreAge')\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(compound_data) < 5:\n",
    "        print(f\"  Not enough data for {compound_name} tires, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Find baseline information\n",
    "    if 1 in compound_data['TyreAge'].values:\n",
    "        # Get baseline data (TyreAge=1)\n",
    "        baseline_data = compound_data[compound_data['TyreAge'] == 1]\n",
    "        baseline_lap_time = baseline_data['LapTime'].mean()\n",
    "        baseline_tire_age = 1\n",
    "    else:\n",
    "        # If no 'new tire' laps, use the minimum TyreAge available\n",
    "        min_age = compound_data['TyreAge'].min()\n",
    "        baseline_data = compound_data[compound_data['TyreAge'] == min_age]\n",
    "        baseline_lap_time = baseline_data['LapTime'].mean()\n",
    "        baseline_tire_age = min_age\n",
    "        print(f\"  No laps with new tires for {compound_name}, using TyreAge={min_age} as baseline\")\n",
    "    \n",
    "    # Calculate fuel adjustment directly based on laps from baseline\n",
    "    compound_data['LapsFromBaseline'] = compound_data['TyreAge'] - baseline_tire_age\n",
    "    compound_data['FuelEffect'] = compound_data['LapsFromBaseline'] * LAP_TIME_IMPROVEMENT_PER_LAP\n",
    "    \n",
    "    # Calculate fuel-adjusted lap time\n",
    "    compound_data['FuelAdjustedLapTime'] = compound_data['LapTime'] + compound_data['FuelEffect']\n",
    "    \n",
    "    # Calculate traditional degradation metrics\n",
    "    compound_data['TireDegAbsolute'] = compound_data['LapTime'] - baseline_lap_time\n",
    "    compound_data['TireDegPercent'] = (compound_data['LapTime'] / baseline_lap_time - 1) * 100\n",
    "    \n",
    "    # Calculate fuel-adjusted degradation metrics\n",
    "    baseline_adjusted_lap_time = baseline_lap_time  # For new tires, no adjustment needed\n",
    "    compound_data['FuelAdjustedDegAbsolute'] = compound_data['FuelAdjustedLapTime'] - baseline_adjusted_lap_time\n",
    "    compound_data['FuelAdjustedDegPercent'] = (compound_data['FuelAdjustedLapTime'] / baseline_adjusted_lap_time - 1) * 100\n",
    "    \n",
    "    # Add compound info for later aggregation\n",
    "    compound_data['CompoundName'] = compound_name\n",
    "    \n",
    "    # Add to the combined DataFrame\n",
    "    tire_deg_data = pd.concat([tire_deg_data, compound_data])\n",
    "    \n",
    "    # Calculate maximum laps and total fuel effect\n",
    "    max_laps = compound_data['TyreAge'].max() - baseline_tire_age\n",
    "    total_fuel_effect = max_laps * LAP_TIME_IMPROVEMENT_PER_LAP\n",
    "    \n",
    "    print(f\"  Baseline lap time for {compound_name}: {baseline_lap_time:.3f}s\")\n",
    "    print(f\"  Maximum laps from baseline: {max_laps:.0f}\")\n",
    "    print(f\"  Estimated total fuel benefit: ~{total_fuel_effect:.2f}s\")\n",
    "    print(f\"  Processed {len(compound_data)} laps with {compound_name} tires\")\n",
    "\n",
    "# Display comparison between regular and fuel-adjusted metrics\n",
    "print(\"\\nComparison of regular vs. fuel-adjusted metrics (sample):\")\n",
    "sample_comparison = tire_deg_data.groupby(['CompoundName', 'TyreAge'])[\n",
    "    ['TireDegAbsolute', 'FuelAdjustedDegAbsolute', 'FuelEffect']\n",
    "].mean().reset_index()\n",
    "display(sample_comparison.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Diferrence between regular and Fuel Adjusted Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison of regular vs fuel-adjusted degradation\n",
    "plt.figure(figsize=(16, 12))\n",
    "compound_ids = tire_deg_data['CompoundID'].unique()\n",
    "# Loop through the compounds to create comparison plots\n",
    "for i, compound_id in enumerate(compound_ids):\n",
    "    compound_subset = tire_deg_data[tire_deg_data['CompoundID'] == compound_id]\n",
    "    color = compound_colors.get(compound_id, 'black')\n",
    "    compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "    \n",
    "    # Calculate means for regular and adjusted degradation\n",
    "    reg_agg = compound_subset.groupby('TyreAge')['TireDegAbsolute'].mean()\n",
    "    adj_agg = compound_subset.groupby('TyreAge')['FuelAdjustedDegAbsolute'].mean()\n",
    "    \n",
    "    # Create subplot\n",
    "    plt.subplot(len(compound_ids), 1, i+1)\n",
    "    \n",
    "    # Plot regular degradation\n",
    "    plt.plot(reg_agg.index, reg_agg.values, 'o--', \n",
    "             color=color, alpha=0.5, label=f'{compound_name} (Regular)')\n",
    "    \n",
    "    # Plot fuel-adjusted degradation\n",
    "    plt.plot(adj_agg.index, adj_agg.values, 'o-', \n",
    "             color=color, linewidth=2, label=f'{compound_name} (Fuel Adjusted)')\n",
    "    \n",
    "    plt.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "    plt.ylabel('Degradation (s)')\n",
    "    plt.title(f'{compound_name} Tire Degradation: Regular vs. Fuel-Adjusted')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Anotar la diferencia total estimada del efecto combustible\n",
    "    min_lap = reg_agg.index.min()\n",
    "    max_lap = reg_agg.index.max()\n",
    "    total_laps = max_lap - min_lap\n",
    "    total_fuel_effect = total_laps * LAP_TIME_IMPROVEMENT_PER_LAP\n",
    "    plt.annotate(f\"Est. total fuel effect: ~{total_fuel_effect:.2f}s\", \n",
    "                 xy=(0.02, 0.05), xycoords='axes fraction',\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8))\n",
    "    \n",
    "    if i == len(compound_ids)-1:  # Solo añadir etiqueta x para el subgráfico inferior\n",
    "        plt.xlabel('Tire Age (laps)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/week5/regular_vs_adjusted_comparison.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Absolute Tire Degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fuel-adjusted absolute degradation\n",
    "plt.figure(figsize=(14, 7))\n",
    "compound_ids = tire_deg_data['CompoundID'].unique()\n",
    "\n",
    "for compound_id in compound_ids:\n",
    "    compound_subset = tire_deg_data[tire_deg_data['CompoundID'] == compound_id]\n",
    "    color = compound_colors.get(compound_id, 'black')\n",
    "    compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "    \n",
    "    # Aggregate data for line plot\n",
    "    agg_data = compound_subset.groupby('TyreAge')['FuelAdjustedDegAbsolute'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Plot mean line\n",
    "    plt.plot(agg_data['TyreAge'], agg_data['mean'], 'o-', \n",
    "             color=color, linewidth=2, label=f'{compound_name}')\n",
    "    \n",
    "    # Add error bands if we have standard deviation\n",
    "    if 'std' in agg_data.columns and not agg_data['std'].isnull().all():\n",
    "        plt.fill_between(agg_data['TyreAge'], \n",
    "                        agg_data['mean'] - agg_data['std'], \n",
    "                        agg_data['mean'] + agg_data['std'],\n",
    "                        color=color, alpha=0.2)\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Tire Age (laps)')\n",
    "plt.ylabel('Fuel-Adjusted Absolute Degradation (s)')\n",
    "plt.title('Tire Degradation by Compound and Age (Fuel Effect Removed)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../../outputs/week5/fuel_adjusted_deg_by_compound.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Tire Degradation Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the fuel-adjusted percentage degradation\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for compound_id in compound_ids:\n",
    "    compound_subset = tire_deg_data[tire_deg_data['CompoundID'] == compound_id]\n",
    "    color = compound_colors.get(compound_id, 'black')\n",
    "    compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "    \n",
    "    # Aggregate data for line plot\n",
    "    agg_data = compound_subset.groupby('TyreAge')['FuelAdjustedDegPercent'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Plot mean line\n",
    "    plt.plot(agg_data['TyreAge'], agg_data['mean'], 'o-', \n",
    "             color=color, linewidth=2, label=f'{compound_name}')\n",
    "    \n",
    "    # Add error bands if we have standard deviation\n",
    "    if 'std' in agg_data.columns and not agg_data['std'].isnull().all():\n",
    "        plt.fill_between(agg_data['TyreAge'], \n",
    "                        agg_data['mean'] - agg_data['std'], \n",
    "                        agg_data['mean'] + agg_data['std'],\n",
    "                        color=color, alpha=0.2)\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Tire Age (laps)')\n",
    "plt.ylabel('Fuel-Adjusted Percentage Degradation (%)')\n",
    "plt.title('Percentage Tire Degradation by Compound and Age (Fuel Effect Removed)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../../outputs/week5/fuel_adjusted_deg_percent_by_compound.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Tire Degradation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After plotting, add the variable to the dataframe\n",
    "for compound_id in compound_ids:\n",
    "    # Recalculate using the same method as in the visualization\n",
    "    compound_subset = tire_deg_data[tire_deg_data['CompoundID'] == compound_id]\n",
    "    avg_laptimes = compound_subset.groupby('TyreAge')['FuelAdjustedLapTime'].mean()\n",
    "    deg_rates = avg_laptimes.diff()\n",
    "    \n",
    "    # Assign values to the dataframe\n",
    "    for age, rate in zip(deg_rates.index, deg_rates.values):\n",
    "        mask = (tire_deg_data['CompoundID'] == compound_id) & (tire_deg_data['TyreAge'] == age)\n",
    "        tire_deg_data.loc[mask, 'DegradationRate'] = rate\n",
    "\n",
    "# Verify that it has been added correctly\n",
    "print(\"\\nFirst rows with DegradationRate:\")\n",
    "display(tire_deg_data[['CompoundID', 'TyreAge', 'FuelAdjustedLapTime', 'DegradationRate']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart showing Tire Degradation Rate by compound with error bands\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "for compound_id in compound_ids:\n",
    "    # Filter the data for the current compound\n",
    "    compound_subset = tire_deg_data[tire_deg_data['CompoundID'] == compound_id]\n",
    "    \n",
    "    # Calculate the average and standard deviation of degradation rate per tire age\n",
    "    deg_stats = compound_subset.groupby('TyreAge')['DegradationRate'].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Get color and compound name for the plot\n",
    "    color = compound_colors.get(compound_id, 'black')\n",
    "    compound_name = compound_names.get(compound_id, f'Unknown ({compound_id})')\n",
    "    \n",
    "    # Plot the line for this compound\n",
    "    plt.plot(deg_stats['TyreAge'], deg_stats['mean'], marker='o', linestyle='-',\n",
    "             color=color, linewidth=2, label=compound_name)\n",
    "    \n",
    "    # Add error bands (standard deviation)\n",
    "    # Check if we have valid standard deviation values\n",
    "    if 'std' in deg_stats.columns and not deg_stats['std'].isnull().all():\n",
    "        plt.fill_between(deg_stats['TyreAge'], \n",
    "                        deg_stats['mean'] - deg_stats['std'], \n",
    "                        deg_stats['mean'] + deg_stats['std'],\n",
    "                        color=color, alpha=0.)\n",
    "\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Tire Age (laps)')\n",
    "plt.ylabel('Fuel-Adjusted Degradation Rate (s/lap)')\n",
    "plt.title('Tire Degradation Rate by Compound (Fuel Effect Removed)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing NaNs. This are due to diff pandas method. Assume 0 as new tires do not have degradation still\n",
    "\n",
    "num_nans = tire_deg_data['DegradationRate'].isna().sum()\n",
    "print(num_nans)\n",
    "\n",
    "tire_deg_data['DegradationRate'] = tire_deg_data['DegradationRate'].fillna(0)\n",
    "print(f\"Number of NaN after sustitution: {tire_deg_data['DegradationRate'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "#### Medium Tire (Yellow).\n",
    "\n",
    "- The fuel effect was masking significantly degradation. With the adjustment, mroe degradation can be seen.\n",
    "\n",
    "- They offer the best initial advantage (-4 seconds), that stabilizes in -3 seconds until aproximately lap 30.\n",
    "\n",
    "- Total fuel impact is about 1.73 seconds faster at the end of the stint.\n",
    "\n",
    "- They represent the best balance between performance and durability.\n",
    "\n",
    "#### Hard Tire (Gray)\n",
    "\n",
    "- Fuel effect made an stabilization ilusion and even improvement. The adjust reveals a constant and progressive degradation that goes up to +2seconds.\n",
    "\n",
    "- Fuel effect on this tires are the biggest, with 2.64 fastet.\n",
    "\n",
    "- Degradation rate is more stable and predictable, making them ideal for long stints.\n",
    "\n",
    "#### Soft Tire (Red)\n",
    "\n",
    "- There is a bigger volatile effect that it seemed without fuel effect.\n",
    "- Erratic behaviour and big fluctuations after lap 20.\n",
    "- Highly unpredictable and dramatically fluctating, specially after lap 20, with extreme degradation peaks of +2 seconds slower per lap.\n",
    "\n",
    "### Detected Turning Points\n",
    "\n",
    "- *SOFT*: show a cliff degradation over 20 laps.\n",
    "- *MEDIUM*: change in pattern near lap 30.\n",
    "- *HARD*: show a degradation increase after lap 40.\n",
    "\n",
    "\n",
    "### Good Conclussions for predictive model. \n",
    "\n",
    "1. Fuel adjustment was essential for identifying true degradation.\n",
    "2. Each compound shows unique patterns that can be useful for the model:\n",
    "    - Soft tire as high volatile with critic points of sudden degradation.\n",
    "    - Medium tire has a fast fall followed by stabilization.\n",
    "    - Hard tire with slow but continous degradation.\n",
    "\n",
    "3. Identified turning points are going to be crucial parameters for the LSTM or XgBoost, as they show critic moments for pit stop strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Correlation Analysis: Tire-Related Factors with Lap Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert dictionary to apply conversion to compound names to numbers \n",
    "compound_names_inv = {value: key for key, value in compound_names.items()}\n",
    "# Replace the names with its according numbers\n",
    "tire_deg_data[\"CompoundName\"] = tire_deg_data[\"CompoundName\"].replace(compound_names_inv)\n",
    "\n",
    "# We can eliminate this column as it does not provide any information\n",
    "tire_deg_data = tire_deg_data.drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making correlation matrix\n",
    "correlation_matrix = tire_deg_data.corr()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear un heatmap\n",
    "plt.figure(figsize=(24,12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclussions and Variable Cleaning\n",
    "\n",
    "**Variables to Keep**  \n",
    "- **FuelAdjustedLapTime** (remove `LapTime`, correlation 0.95)  \n",
    "  - Main lap time metric adjusted without the misleading fuel effect  \n",
    "- **FuelAdjustedDegPercent** (remove other degradation metrics)  \n",
    "  - Best metric for comparing compounds  \n",
    "  - The four degradation metrics have very high correlations with each other (0.98–1.00). The pther 3 variables were only created to add more explicability to the data analysis.\n",
    "- **DegradationRate**  \n",
    "  - Captures the changing dynamics of degradation  \n",
    "  - Its low correlation with other variables confirms it adds unique information  \n",
    "  - Crucial for detecting inflection points and sudden changes  \n",
    "- **TyreAge**  \n",
    "  - A fundamental variable for the model  \n",
    "  - Tire age is the main predictor of its condition  \n",
    "- **CompoundID** (remove `CompoundName`)  \n",
    "  - Needed to distinguish between different compounds  \n",
    "\n",
    "- **Rest of variables**\n",
    "\n",
    "**Optional Variables (if they improve the model)**  \n",
    "- **SpeedI1**, **SpeedI2**, **SpeedFL**: to capture sector effects  \n",
    "- **FuelLoad**: as a control variable  \n",
    "\n",
    "**Variables to Remove**  \n",
    "- **LapTime** (use only `FuelAdjustedLapTime`)  \n",
    "- **TireDegAbsolute**, **TireDegPercent**, **FuelAdjustedDegAbsolute**  \n",
    "- **CompoundName** (redundant with `CompoundID`)  \n",
    "- **LapsFromBaseline** and **FuelEffect** (perfect correlation)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove only the specified redundant variables\n",
    "columns_to_remove = [\n",
    "    'LapTime',                 # Use only FuelAdjustedLapTime\n",
    "    'TireDegAbsolute',         # Redundant with FuelAdjustedDegPercent\n",
    "    'TireDegPercent',          # Redundant with FuelAdjustedDegPercent\n",
    "    'FuelAdjustedDegAbsolute', # Redundant with FuelAdjustedDegPercent\n",
    "    'CompoundName',            # Redundant with CompoundID\n",
    "    'LapsFromBaseline',        # Perfect correlation\n",
    "    'FuelEffect'               # Perfect correlation\n",
    "]\n",
    "\n",
    "# Drop columns from the dataframe\n",
    "tire_deg_data = tire_deg_data.drop(columns=columns_to_remove)\n",
    "\n",
    "# Show how many variables were removed and display a new correlation matrix\n",
    "print(f\"Removed {len(columns_to_remove)} redundant variables.\")\n",
    "print(f\"The dataframe now has {tire_deg_data.shape[1]} columns.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. New Correlation Matrix to see interesting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new correlation matrix\n",
    "updated_correlation_matrix = tire_deg_data.corr()\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.heatmap(updated_correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Updated Correlation Matrix after Removing Redundant Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing the data and applying fuel adjustment, the correlation matrix reveals critical relationships that will inform our LSTM model. Here are the main points:\n",
    "\n",
    "- **Key Correlations:**\n",
    "  - **FuelAdjustedLapTime & FuelAdjustedDegPercent:** Strong correlation (0.59) indicates similar degradation dynamics from different perspectives.\n",
    "  - **TyreAge & LapsSincePitStop:** Almost perfect correlation (0.90), as both track similar information.\n",
    "  - **CompoundID & FuelAdjustedDegPercent:** Moderate correlation (0.40) shows that tire compound significantly influences degradation.\n",
    "  - **FuelLoad & Performance Metrics:** Strong negative correlation with Stint (-0.86) and moderate correlation with adjusted lap time (0.42), emphasizing the importance of fuel weight.\n",
    "  - **DegradationRate:** Low correlation with most variables, including FuelAdjustedDegPercent (0.19), suggesting it captures unique degradation dynamics.\n",
    "\n",
    "- **LSTM Model Input Selection:**\n",
    "  - **Primary Variables:**\n",
    "    - **FuelAdjustedLapTime:** Core performance metric without fuel effects.\n",
    "    - **FuelAdjustedDegPercent:** Best metric for comparing compound performance.\n",
    "    - **DegradationRate:** Captures lap-to-lap changes and critical inflection points.\n",
    "    - **TyreAge:** Fundamental predictor of tire condition.\n",
    "    - **CompoundID:** Essential for distinguishing between different tire compounds.\n",
    "  - **Supporting Variables:**\n",
    "    - **Speed Metrics (SpeedI1, SpeedI2, SpeedFL):** Capture sector-specific effects.\n",
    "    - **FuelLoad:** Used as a control variable.\n",
    "    - **Position:** Provides contextual race information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Saving my final Dataframe as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardar el DataFrame procesado con las métricas de degradación ajustadas por combustible\n",
    "output_path = \"../../outputs/week5/tire_degradation_fuel_adjusted.csv\"\n",
    "\n",
    "# Guardar el DataFrame\n",
    "tire_deg_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Creating Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../outputs/week5/tire_degradation_fuel_adjusted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing Process for LSTM\n",
    "\n",
    "### Creating Temporal Sequences:\n",
    "- We need to transform our tabular data into chronologically ordered sequences.\n",
    "- Each sequence should contain a sliding window of N consecutive laps (typically 5 laps).\n",
    "\n",
    "### Data Format for LSTM:\n",
    "**Input:** [lap_t-5, lap_t-4, lap_t-3, lap_t-2, lap_t-1]  \n",
    "\n",
    "**Output:** [lap_t, lap_t+1, lap_t+2]\n",
    "\n",
    "### Variables to Include in Each Sequence Element:\n",
    "- FuelAdjustedLapTime\n",
    "- FuelAdjustedDegPercent\n",
    "- DegradationRate\n",
    "- TyreAge\n",
    "- CompoundID\n",
    "- Contextual variables (FuelLoad, position, sector speeds)\n",
    "\n",
    "It is crucial to ensure that the sequences maintain temporal integrity and do not mix data from different stints or pit stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, input_length=5, prediction_horizon=3, target_column='FuelAdjustedDegPercent'):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM model from the tire degradation data.\n",
    "    Groups by driver, stint and compound to ensure proper sequencing.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with tire degradation data\n",
    "        input_length: Number of consecutive laps to include in input sequence\n",
    "        prediction_horizon: Number of future laps to predict\n",
    "        target_column: Column to predict\n",
    "        \n",
    "    Returns:\n",
    "        sequences: List of DataFrame sequences\n",
    "        targets: List of target arrays\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Group by DriverNumber, Stint, and CompoundID\n",
    "    groupby_columns = ['DriverNumber', 'Stint', 'CompoundID']\n",
    "    \n",
    "    # Process each driver-stint-compound group separately\n",
    "    for name, group in df.groupby(groupby_columns):\n",
    "        # Sort by TyreAge to ensure chronological order\n",
    "        sorted_group = group.sort_values('TyreAge').reset_index(drop=True)\n",
    "        \n",
    "        # Skip if we don't have enough laps for a sequence\n",
    "        if len(sorted_group) < input_length + prediction_horizon:\n",
    "            continue\n",
    "        \n",
    "        # Create sliding window sequences\n",
    "        for i in range(len(sorted_group) - input_length - prediction_horizon + 1):\n",
    "            # Get input sequence (all features)\n",
    "            seq = sorted_group.iloc[i:i+input_length]\n",
    "            \n",
    "            # Get target values (future values to predict)\n",
    "            target = sorted_group.iloc[i+input_length:i+input_length+prediction_horizon][target_column].values\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    print(f\"Created {len(sequences)} sequences of {input_length} laps each\")\n",
    "    return sequences, targets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, targets = create_sequences(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Sequences and Targets\n",
    "#### What does the `create_sequences` function do?\n",
    "The function creates data in a sequential format, necessary for training LSTM models. Specifically:\n",
    "\n",
    "**Sequences:**\n",
    "- They are \"sliding windows\" of consecutive data from the same set of tires.\n",
    "- Each sequence contains data from 5 consecutive laps (all DataFrame columns).\n",
    "- They represent the \"recent history\" that the model will use to make predictions.\n",
    "\n",
    "**Targets:**\n",
    "- These are the values we want to predict in the future.\n",
    "- Each target contains the degradation values for the next 3 laps after the sequence.\n",
    "- It only includes the column we want to predict (`FuelAdjustedDegPercent`).\n",
    "\n",
    "#### Concrete Example\n",
    "Imagine we have data from 10 laps with the same tire:\n",
    "\n",
    "- **Sequence 1:** Laps 1-5\n",
    "  - **Target 1:** Degradation in laps 6-8\n",
    "- **Sequence 2:** Laps 2-6\n",
    "  - **Target 2:** Degradation in laps 7-9\n",
    "- **Sequence 3:** Laps 3-7\n",
    "  - **Target 3:** Degradation in laps 8-10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Verifying the Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sequences_with_targets(sequences, targets, num_to_check=3):\n",
    "    print(\"COMPLETE SEQUENCE VERIFICATION (WITH TARGETS):\")\n",
    "    print(\"=============================================\")\n",
    "    \n",
    "    # Check a few consecutive sequences from the same group\n",
    "    driver_stint_compounds = []\n",
    "    \n",
    "    for i, seq in enumerate(sequences):\n",
    "        # Get identifier for this sequence\n",
    "        identifier = (seq['DriverNumber'].iloc[0], seq['Stint'].iloc[0], seq['CompoundID'].iloc[0])\n",
    "        driver_stint_compounds.append(identifier)\n",
    "    \n",
    "    # Find groups with consecutive sequences\n",
    "    for i in range(len(sequences)-1):\n",
    "        # Check if consecutive sequences are from same driver-stint-compound\n",
    "        if driver_stint_compounds[i] == driver_stint_compounds[i+1]:\n",
    "            seq1 = sequences[i]\n",
    "            seq2 = sequences[i+1]\n",
    "            \n",
    "            # Get tire ages and targets\n",
    "            ages1 = seq1['TyreAge'].values\n",
    "            ages2 = seq2['TyreAge'].values\n",
    "            target1 = targets[i]\n",
    "            target2 = targets[i+1]\n",
    "            \n",
    "            # Calculate what the next tire ages should be (for targets)\n",
    "            expected_target_ages1 = np.array([ages1[-1] + j + 1 for j in range(len(target1))])\n",
    "            expected_target_ages2 = np.array([ages2[-1] + j + 1 for j in range(len(target2))])\n",
    "            \n",
    "            # Check if sliding window pattern is correct\n",
    "            sliding_window_correct = np.array_equal(ages1[1:], ages2[:-1])\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"\\nSequences {i} and {i+1}:\")\n",
    "            print(f\"Driver: {seq1['DriverNumber'].iloc[0]}, Stint: {seq1['Stint'].iloc[0]}, Compound: {seq1['CompoundID'].iloc[0]}\")\n",
    "            print(f\"Tire ages seq {i}: {ages1}\")\n",
    "            print(f\"TARGET values seq {i}: {target1}\")\n",
    "            print(f\"Expected target ages seq {i}: {expected_target_ages1}\")\n",
    "            print(f\"Tire ages seq {i+1}: {ages2}\")\n",
    "            print(f\"TARGET values seq {i+1}: {target2}\")\n",
    "            print(f\"Expected target ages seq {i+1}: {expected_target_ages2}\")\n",
    "            print(f\"Sliding window pattern: {sliding_window_correct}\")\n",
    "            \n",
    "            # Verify that target1 corresponds to the next values after seq1\n",
    "            # We'd need the original dataframe to check this precisely\n",
    "            \n",
    "            # Only check a limited number\n",
    "            num_to_check -= 1\n",
    "            if num_to_check <= 0:\n",
    "                break\n",
    "    \n",
    "    print(\"\\nVERIFICATION SUMMARY:\")\n",
    "    print(\"1. Each sequence should advance by one lap (sliding window pattern)\")\n",
    "    print(\"2. Targets should contain the FuelAdjustedDegPercent values for the next 3 laps\")\n",
    "    print(\"3. Each target should start exactly where its sequence ends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verirfy sequences with their targets\n",
    "verify_sequences_with_targets(sequences, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of Data Sequencing\n",
    "#### Sliding Window Pattern:\n",
    "- Each sequence advances exactly one lap relative to the previous one.\n",
    "- Example: `[1,2,3,4,5] → [2,3,4,5,6] → [3,4,5,6,7] → [4,5,6,7,8]`\n",
    "\n",
    "#### Consistency in Targets:\n",
    "- Targets always represent the next 3 laps after each sequence.\n",
    "- Example: Sequence 0 ends at lap 5, targets are laps 6, 7, 8.\n",
    "\n",
    "#### Coherence Between Sequences and Targets:\n",
    "- The target values also \"slide\" accordingly:\n",
    "  - **Target of Sequence 0:** `[-3.88, -3.73, -4.36]`\n",
    "  - **Target of Sequence 1:** `[-3.73, -4.36, -3.83]`\n",
    "- The first two values of Target 1 match the last two of Target 0.\n",
    "\n",
    "#### Maintaining Structure by Driver, Stint, and Compound:\n",
    "- All shown sequences belong to the same driver (1), same stint (1.0), and same compound (2).\n",
    "- This ensures we are analyzing the degradation of a single set of tires.\n",
    "\n",
    "### Implications for Our LSTM Model\n",
    "- The model can learn degradation patterns based on consecutive lap sequences.\n",
    "- It can predict degradation for the next 3 laps using the previous 5 laps.\n",
    "- The data structure captures both the absolute degradation level and its rate of change.\n",
    "\n",
    "With this verification, we confirm that the data is correctly prepared for training the LSTM model. We have selected `FuelAdjustedDegPercent` as our target, which is appropriate since it represents degradation adjusted for fuel effects, precisely what we aim to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 LSTM: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_lstm(sequences, targets):\n",
    "    \"\"\"\n",
    "    Convert the list of DataFrames and targets into numpy arrays suitable for LSTM training\n",
    "    \"\"\"\n",
    "    # Get the number of features (columns) in the sequence DataFrames\n",
    "    n_features = len(sequences[0].columns)\n",
    "    sequence_length = len(sequences[0])\n",
    "    prediction_horizon = len(targets[0])\n",
    "    \n",
    "    # Initialize arrays\n",
    "    X = np.zeros((len(sequences), sequence_length, n_features))\n",
    "    y = np.zeros((len(sequences), prediction_horizon))\n",
    "    \n",
    "    # Fill the arrays\n",
    "    for i, (seq, target) in enumerate(zip(sequences, targets)):\n",
    "        X[i] = seq.values\n",
    "        y[i] = target\n",
    "    \n",
    "    print(f\"Prepared data for LSTM with shape: X: {X.shape}, y: {y.shape}\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM (convert to numpy arrays)\n",
    "X, y = prepare_for_lstm(sequences, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1 **Prepared Data:**\n",
    "- **X**: (763, 5, 16) → 763 sequences, each containing 5 laps and 16 features per lap\n",
    "- **y**: (763, 3) → For each sequence, we predict 3 future laps of degradation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 **Dataset Split:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation and test sets (70-15-15)\n",
    "# First split: separate test set (15%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: divide remaining data into train (70%) and validation (15%)\n",
    "# The validation should be 17.65% of the temporary set (0.15/0.85)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.15/0.85, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shapes of the resulting datasets\n",
    "print(\"Data split:\")\n",
    "print(f\"X_train shape: {X_train.shape} ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"X_val shape: {X_val.shape} ({len(X_val)/len(X):.1%})\")\n",
    "print(f\"X_test shape: {X_test.shape} ({len(X_test)/len(X):.1%})\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Train**: 533 sequences (69.9%) - very close to the 70% target\n",
    "- **Validation**: 115 sequences (15.1%) - very close to the 15% target\n",
    "- **Test**: 115 sequences (15.1%) - very close to the 15% target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
