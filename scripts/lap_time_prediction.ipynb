{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import fastf1\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Configuración de fastf1\n",
    "fastf1.Cache.enable_cache('f1_cache')  # Asegúrate de que esta carpeta exista\n",
    "\n",
    "# Clase para el modelo PyTorch\n",
    "class LapTimeNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LapTimeNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(race_year=2023, race_name='Spain'):\n",
    "    \"\"\"\n",
    "    Carga y prepara los datos de la carrera especificada\n",
    "    \"\"\"\n",
    "    # Cargar la sesión de carrera\n",
    "    race = fastf1.get_session(race_year, race_name, 'R')\n",
    "    race.load()\n",
    "    \n",
    "    # Obtener laps y telemetría\n",
    "    laps_data = race.laps\n",
    "    \n",
    "    # Convertir a DataFrame para manipulación\n",
    "    df = pd.DataFrame(laps_data)\n",
    "    \n",
    "    # Eliminar outliers (vueltas muy lentas por safety car, paradas, etc.)\n",
    "    # Esto requiere análisis exploratorio para determinar umbrales apropiados\n",
    "    q1 = df['LapTime'].quantile(0.05)\n",
    "    q3 = df['LapTime'].quantile(0.95)\n",
    "    df = df[(df['LapTime'] >= q1) & (df['LapTime'] <= q3)]\n",
    "    \n",
    "    # Convertir LapTime a segundos (si viene como timedelta)\n",
    "    if df['LapTime'].dtype == 'timedelta64[ns]':\n",
    "        df['LapTime'] = df['LapTime'].dt.total_seconds()\n",
    "    \n",
    "    # Feature Engineering\n",
    "    # 1. Edad de los neumáticos\n",
    "    df['TyreAge'] = df['TyreLife']\n",
    "    \n",
    "    # 2. Cambio de posición (comparado con la vuelta anterior)\n",
    "    df['PositionChange'] = df.groupby('Driver')['Position'].diff().fillna(0)\n",
    "    \n",
    "    # 3. Sector times (si están disponibles)\n",
    "    if 'Sector1Time' in df.columns and df['Sector1Time'].dtype == 'timedelta64[ns]':\n",
    "        df['Sector1Time'] = df['Sector1Time'].dt.total_seconds()\n",
    "        df['Sector2Time'] = df['Sector2Time'].dt.total_seconds()\n",
    "        df['Sector3Time'] = df['Sector3Time'].dt.total_seconds()\n",
    "    \n",
    "    # 4. Carga de combustible (aproximación basada en la vuelta)\n",
    "    max_lap = df['LapNumber'].max()\n",
    "    df['FuelLoad'] = 1 - (df['LapNumber'] / max_lap)  # Aproximación simple\n",
    "    \n",
    "    # Seleccionar variables para el modelo\n",
    "    features = ['TyreCompound', 'TrackTemp', 'AirTemp', 'TyreAge', \n",
    "                'PositionChange', 'FuelLoad', 'Driver']\n",
    "    \n",
    "    # Asegurarse de que todas las variables existan en el dataframe\n",
    "    features = [f for f in features if f in df.columns]\n",
    "    \n",
    "    # Añadir columnas adicionales si están disponibles\n",
    "    if 'Rainfall' in df.columns:\n",
    "        features.append('Rainfall')\n",
    "    if 'WindSpeed' in df.columns:\n",
    "        features.append('WindSpeed')\n",
    "    \n",
    "    # Seleccionar solo las filas con todos los datos completos\n",
    "    model_df = df[features + ['LapTime']].dropna()\n",
    "    \n",
    "    return model_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos para el modelado\n",
    "    \"\"\"\n",
    "    # Separar características y objetivo\n",
    "    X = df.drop('LapTime', axis=1)\n",
    "    y = df['LapTime']\n",
    "    \n",
    "    # Identificar columnas categóricas y numéricas\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Crear preprocesadores\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Combinar preprocesadores\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)\n",
    "        ])\n",
    "    \n",
    "    # Dividir datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, preprocessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    \"\"\"\n",
    "    Entrena un modelo XGBoost\n",
    "    \"\"\"\n",
    "    # Crear pipeline con preprocesamiento y modelo\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', xgb.XGBRegressor(objective='reg:squarederror'))\n",
    "    ])\n",
    "    \n",
    "    # Parámetros para Grid Search\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [100, 200],\n",
    "        'regressor__learning_rate': [0.01, 0.1],\n",
    "        'regressor__max_depth': [3, 5, 7],\n",
    "        'regressor__min_child_weight': [1, 3]\n",
    "    }\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Mejores parámetros\n",
    "    print(\"Mejores parámetros XGBoost:\", grid_search.best_params_)\n",
    "    \n",
    "    # Predecir\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Evaluar\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"XGBoost - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    return best_model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_pytorch(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de red neuronal con PyTorch\n",
    "    \"\"\"\n",
    "    # Aplicar preprocesamiento\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Convertir a tensores\n",
    "    X_train_tensor = torch.FloatTensor(X_train_processed.toarray())\n",
    "    y_train_tensor = torch.FloatTensor(y_train.values).reshape(-1, 1)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_processed.toarray())\n",
    "    y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "    \n",
    "    # Crear conjuntos de datos y cargadores\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Inicializar modelo\n",
    "    input_size = X_train_processed.shape[1]\n",
    "    model = LapTimeNN(input_size)\n",
    "    \n",
    "    # Definir criterio y optimizador\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "        y_pred = y_pred_tensor.numpy().flatten()\n",
    "        \n",
    "    # Métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"PyTorch NN - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    return model, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(y_test, y_pred_xgb, y_pred_nn=None):\n",
    "    \"\"\"\n",
    "    Visualiza los resultados de los modelos\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot de dispersión para XGBoost\n",
    "    plt.subplot(1, 2 if y_pred_nn is not None else 1, 1)\n",
    "    plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel('Tiempo real (s)')\n",
    "    plt.ylabel('Tiempo predicho (s)')\n",
    "    plt.title('XGBoost: Predicciones vs Reales')\n",
    "    \n",
    "    # Si hay predicciones de red neuronal\n",
    "    if y_pred_nn is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(y_test, y_pred_nn, alpha=0.5)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "        plt.xlabel('Tiempo real (s)')\n",
    "        plt.ylabel('Tiempo predicho (s)')\n",
    "        plt.title('Neural Network: Predicciones vs Reales')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/week3/prediction_results.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(xgb_model, nn_model=None):\n",
    "    \"\"\"\n",
    "    Guarda los modelos entrenados\n",
    "    \"\"\"\n",
    "    # Crear carpeta si no existe\n",
    "    import os\n",
    "    os.makedirs('models/week3', exist_ok=True)\n",
    "    \n",
    "    # Guardar modelo XGBoost\n",
    "    joblib.dump(xgb_model, 'models/week3/xgboost_laptime.joblib')\n",
    "    \n",
    "    # Guardar modelo PyTorch si existe\n",
    "    if nn_model is not None:\n",
    "        torch.save(nn_model.state_dict(), 'models/week3/nn_laptime.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Cargar y preparar datos\n",
    "    print(\"Cargando datos...\")\n",
    "    data = load_and_prepare_data()\n",
    "    \n",
    "    # Análisis exploratorio básico\n",
    "    print(\"\\nResumen de datos:\")\n",
    "    print(data.describe())\n",
    "    \n",
    "    # Correlaciones\n",
    "    print(\"\\nMatriz de correlación:\")\n",
    "    numeric_data = data.select_dtypes(include=['int64', 'float64'])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.savefig('outputs/week3/correlation_matrix.png')\n",
    "    \n",
    "    # Preprocesar datos\n",
    "    print(\"\\nPreprocesando datos...\")\n",
    "    X_train, X_test, y_train, y_test, preprocessor = preprocess_data(data)\n",
    "    \n",
    "    # Entrenar modelo XGBoost\n",
    "    print(\"\\nEntrenando modelo XGBoost...\")\n",
    "    xgb_model, y_pred_xgb = train_xgboost(X_train, X_test, y_train, y_test, preprocessor)\n",
    "    \n",
    "    # Entrenar modelo PyTorch (opcional)\n",
    "    train_nn = input(\"¿Desea entrenar también un modelo de red neuronal? (s/n): \").lower() == 's'\n",
    "    if train_nn:\n",
    "        print(\"\\nEntrenando modelo de red neuronal...\")\n",
    "        nn_model, y_pred_nn = train_pytorch(X_train, X_test, y_train, y_test, preprocessor)\n",
    "    else:\n",
    "        nn_model, y_pred_nn = None, None\n",
    "    \n",
    "    # Visualizar resultados\n",
    "    print(\"\\nVisualizando resultados...\")\n",
    "    visualize_results(y_test, y_pred_xgb, y_pred_nn)\n",
    "    \n",
    "    # Guardar modelos\n",
    "    print(\"\\nGuardando modelos...\")\n",
    "    save_models(xgb_model, nn_model)\n",
    "    \n",
    "    print(\"\\n¡Proceso completado!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
