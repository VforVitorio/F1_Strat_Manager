{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for Extracting Radios \n",
    "\n",
    "This script is for extracting the team radios of the 2023 season.\n",
    "\n",
    "Races extracted:\n",
    "* Belgium.\n",
    "* Singapore.\n",
    "* Spain.\n",
    "* Monaco.\n",
    "* Brazil.\n",
    "* Netherlands.\n",
    "\n",
    "### Flag for knowing if I needed to add more data due to eliminating post-race radios\n",
    "\n",
    "I needed to add the last 3 GPs after eliminating post-race radios.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting meeting key\n",
    "https://api.openf1.org/v1/meetings?year=2023&country_name=Spain\n",
    "#### Getting session key\n",
    "GET https://api.openf1.org/v1/sessions?meeting_key=1218&session_name=Race\n",
    "#### Getting radios\n",
    "https://api.openf1.org/v1/team_radio?session_key=9158&driver_number=11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OpenF1 Team Radio Data Extraction Script - Multiple Grand Prix\n",
    "------------------------------------------------------------------\n",
    "Extracts all team radio data from the OpenF1 API for several GPs\n",
    "and saves them in Parquet format as well as audio files.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Use current_dir based on **file** or cwd (useful in notebooks)\n",
    "try:\n",
    "    current_dir = Path(__file__).parent\n",
    "except NameError:\n",
    "    current_dir = Path.cwd()\n",
    "\n",
    "# Navigate to project root from scripts/data_extraction\n",
    "# First, go up to scripts folder\n",
    "scripts_dir = current_dir.parent\n",
    "# Then go up again to reach project root\n",
    "project_root = scripts_dir.parent\n",
    "\n",
    "# Destination directory for the Parquet files (f1-strategy/data/raw)\n",
    "output_dir = project_root / \"f1-strategy\" / \"data\" / \"raw\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Base directory for the audio files\n",
    "audio_base_dir = project_root / \"f1-strategy\" / \"data\" / \"audio\"\n",
    "audio_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the session_keys and names of the GPs we want to extract\n",
    "gp_data = [\n",
    "    {\"name\": \"Spain\", \"session_key\": 9158, \"year\": 2023},\n",
    "    {\"name\": \"Singapore\", \"session_key\": 9165, \"year\": 2023},\n",
    "    {\"name\": \"Belgium\", \"session_key\": 9141, \"year\": 2023},\n",
    "    {\"name\": \"Monaco\", \"session_key\": 9094, \"year\": 2023},\n",
    "    {\"name\": \"Brazil\", \"session_key\": 9205, \"year\": 2023},  # Fixed typo in key name\n",
    "    {\"name\": \"Netherlands\", \"session_key\": 9149, \"year\": 2023},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_team_radio(session_key, gp_name):\n",
    "    \"\"\"\n",
    "    Extracts ALL team radio messages for a specific race,\n",
    "    without filtering by driver.\n",
    "    \"\"\"\n",
    "    # The driver_number parameter is omitted to retrieve all radio messages\n",
    "    url = f\"https://api.openf1.org/v1/team_radio?session_key={session_key}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        print(f\"✓ Found {len(data)} records for GP {gp_name}\")\n",
    "        df = pd.DataFrame(data)\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        \n",
    "        # Add a column with the GP name for identification\n",
    "        df['gp_name'] = gp_name\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for GP {gp_name}: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_radio_files(df, gp_name):\n",
    "    \"\"\"\n",
    "    Downloads audio files for a specific team radio DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"\\nDownloading audio files for the {gp_name} GP...\")\n",
    "\n",
    "    # Group by driver\n",
    "    grouped = df.groupby([\"driver_number\"])\n",
    "\n",
    "    total_downloads = 0\n",
    "    for driver_number, group in grouped:\n",
    "        folder_name = f\"driver_{driver_number}\"\n",
    "        driver_folder = audio_base_dir / folder_name\n",
    "        driver_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Download and save audio files\n",
    "        for i, row in group.iterrows():\n",
    "            url = row[\"recording_url\"]\n",
    "            if pd.isna(url):\n",
    "                continue\n",
    "\n",
    "            # Create a filename including the GP name\n",
    "            filename = f\"driver_{driver_number}_{gp_name.lower()}_radio_{i}.mp3\"\n",
    "            output_path = driver_folder / filename\n",
    "\n",
    "            # Check if the file already exists to avoid duplicate downloads\n",
    "            if output_path.exists():\n",
    "                #print(f\"File already exists: {output_path}\")\n",
    "                continue\n",
    "\n",
    "            # Download the file\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                response.raise_for_status()\n",
    "                with open(output_path, \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"Downloaded: {output_path}\")\n",
    "                total_downloads += 1\n",
    "\n",
    "                # Small delay to avoid overloading the server\n",
    "                time.sleep(0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "    return total_downloads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data and download audio files for all defined GPs\n",
    "all_dfs = []\n",
    "total_files_downloaded = 0\n",
    "\n",
    "for gp in gp_data:\n",
    "    print(f\"\\n--- Processing {gp['name']} GP {gp['year']} ---\")\n",
    "\n",
    "    # Extract team radio data\n",
    "    df_team_radio = fetch_team_radio(gp['session_key'], gp['name'])\n",
    "\n",
    "    if not df_team_radio.empty:\n",
    "        # Save as Parquet\n",
    "        parquet_path = output_dir / f\"{gp['name']}_{gp['year']}_openf1_team_radio.parquet\"\n",
    "        df_team_radio.to_parquet(parquet_path)\n",
    "        print(f\"Data saved to {parquet_path}\")\n",
    "\n",
    "        # Download audio files\n",
    "        files_downloaded = download_radio_files(df_team_radio, gp['name'])\n",
    "        total_files_downloaded += files_downloaded\n",
    "\n",
    "        # Add to the combined DataFrame\n",
    "        all_dfs.append(df_team_radio)\n",
    "    else:\n",
    "        print(f\"No data found for {gp['name']} GP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames into a single one\n",
    "if all_dfs:\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_path = output_dir / \"Combined_2023_openf1_team_radio.parquet\"\n",
    "    combined_df.to_parquet(combined_path)\n",
    "    print(f\"\\n✓ All combined data saved to {combined_path}\")\n",
    "\n",
    "    # Display final statistics\n",
    "    print(f\"\\n--- FINAL SUMMARY ---\")\n",
    "    print(f\"Total GPs processed: {len(all_dfs)} out of {len(gp_data)}\")\n",
    "    print(f\"Total team radio records: {len(combined_df)}\")\n",
    "    print(f\"Total audio files downloaded: {total_files_downloaded}\")\n",
    "\n",
    "    # Show communication count per driver\n",
    "    print(\"\\nDistribution of communications per driver:\")\n",
    "    driver_counts = combined_df['driver_number'].value_counts().sort_index()\n",
    "    for driver_num, count in driver_counts.items():\n",
    "        print(f\"  • Driver #{driver_num}: {count} communications\")\n",
    "else:\n",
    "    print(\"No data found for any GP. Check your connection or session_keys.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
