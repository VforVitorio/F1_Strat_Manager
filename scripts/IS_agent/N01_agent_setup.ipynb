{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experta: Theory Fundamentals of Production Systems and RETE Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Experta is a Python library based on Production Systems, also known as Expert Systems or Rule-Based Systems, wich is a fundamental paradigm in simbolic AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Expert Systems? \n",
    "\n",
    "An expert system is formed by 3 key components:\n",
    "\n",
    "1. **Facts base**: it stores the factual knowledge of the system. That is, what the system knows in a specific moment.\n",
    "\n",
    "2. **Rule Base**: contains the procedure knowledge as \"if-then\" rules.\n",
    "\n",
    "3. **Inference motor**: motor that determines whether apply one rule or another and when to apply it.\n",
    "\n",
    "The central idea is no model the thinking as a rule chaining process, simillar at how human experts would take a decission applying their knowledge to a specific subject.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETE Algorithm\n",
    "\n",
    "Experta´s core is RETE algorithm, designed in 1982 by Charles L.Forgy. This algorithm is crucal for knowing what Experta is doing and also knowing why it is efficient:\n",
    "\n",
    "- Its **function** is to optimize the coincidence of patterns between facts and rules. \n",
    "\n",
    "- It builds a node network that represent patterns. Then, it avoids reevaluating all the rules when the facts change.\n",
    "\n",
    "Therefore, RETE builds a \"discrimination net\" that acts as an efficient filter for determining which rules should be activated in response to changes made on the facts base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experta´s execution cycle\n",
    "\n",
    "1. **Match**: the motor identifies all the rules that can be activaded with the actual facts base.\n",
    "2. **Conflict Resolution**: if multiple rules coincide, the motor decides which one is executed first (using conflic resolution strategies).\n",
    "3. **Act**: it executes the action associated with the selected rule, that tipically modifies the facts base.\n",
    "4. **Cycle**: the process is repeated until there are no more rules to be activated.\n",
    "\n",
    "This cycle is knwon as \"cycle recognize-act\" or \"production cycle\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarative vs Imperative Programming\n",
    "\n",
    "Experta is a **Declarative Programming paradigm**, in contrast with traditional programming. Instead of defining HOW to make something step by step, Declarative Programming specifies WHICH conditions need to be acomplished. In Experta, the developer defines rules declaratively and the motor is the one that says when and how are they going to be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance for F1 Strategy\n",
    "\n",
    "Experta´s selection for the F1 strategy problem is theoretically justified due to this 5 points:\n",
    "\n",
    "1. **Codificable expert knowledge**: F1 strategies can be expressed naturally as conditional rules based on expert knowledge.\n",
    "2. **Incremental Reasoning**: during the race, information comes continously, such as radios, telemetry, track data or weather. RETE is efficient for updating conclussions based on new information.\n",
    "3. **Knowledge Explanation**: rules can be read and modified by humans, allowing adjusting strategies based on feedback.\n",
    "4. **Explainable Capacity**: unlike black box models like Neural Networks, a system based on rules can explain exactly which conditions made them make a decission.\n",
    "5. **Multiple Information Integration**: key for my project, as it brings me the capacity to merge structured information as data with semi-structured information like NLP radio analysis or my prediction models in the same logical framework.\n",
    "\n",
    "The implementation through Experta allows to capture strategic reasoning of F1 Teams, creating a system that emulates how they would take real-time decissions based on the actual avaliable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example of Decision Making with an Expert System\n",
    "\n",
    "I will illustrate a simple case: deciding whether an F1 car should pit based on tire degradation and weather conditions.\n",
    "\n",
    "### 1. Problem Definition\n",
    "We have basic rules to decide on a pit stop:\n",
    "\n",
    "- If tire degradation is greater than 60%, recommend a pit stop.\n",
    "- If it is raining and the car has dry tires, recommend a pit stop.\n",
    "- If the degradation is moderate (30-60%) and the driver reports grip issues, recommend a pit stop.\n",
    "\n",
    "### 2. Step-by-Step Process\n",
    "Here is what happens when we run Experta:\n",
    "\n",
    "#### 2.1 Initialization:\n",
    "- The rule engine `EstrategiaF1` is created.\n",
    "- The method `reset()` is called to prepare the engine.\n",
    "\n",
    "#### 2.2 Declaration of Facts:\n",
    "- We add that the tires have a degradation of 45% and are of the dry type.\n",
    "- We add that it is not raining.\n",
    "- We add that the driver reports grip issues.\n",
    "\n",
    "#### 2.3 Execution of the RETE Cycle:\n",
    "- The engine calls `run()`, starting the inference cycle.\n",
    "- RETE builds an activation network with the three defined rules.\n",
    "\n",
    "#### 2.4 Rule Evaluation:\n",
    "- **First rule (very_degraded_tires):** DOES NOT MATCH because degradation = 45% (less than 60%).\n",
    "- **Second rule (change_to_rain):** DOES NOT MATCH because raining = False.\n",
    "- **Third rule (moderate_grip_problems):** MATCHES because:\n",
    "  - degradation = 45% (is between 30% and 60%)\n",
    "  - the message contains \"problems\" and \"grip\"\n",
    "\n",
    "#### Rule Activation:\n",
    "- The rule `moderate_grip_problems` is activated.\n",
    "- Its action is executed, declaring a new fact: **Recommendation**.\n",
    "\n",
    "#### New Evaluation Cycle:\n",
    "- The engine evaluates whether there are new rules that match the newly added fact.\n",
    "- In this case, no additional rules are activated.\n",
    "- The engine terminates the execution.\n",
    "\n",
    "### Final Result:\n",
    "We obtain a recommendation:\n",
    "- **Action recommended:** pit\n",
    "- **Reason:** Grip issues reported with moderate degradation\n",
    "- **Urgency:** medium\n",
    "\n",
    "This is the essence of how the expert system processes the rules: it continuously evaluates the available facts against the rule conditions and executes the corresponding actions when matches occur. The RETE algorithm makes this process efficient by avoiding the need to re-evaluate all rules for every fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# Import the tire prediction module\n",
    "import sys\n",
    "import os\n",
    "# Add parent directory to path if needed\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition of Fact Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experta import Fact, Field, KnowledgeEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field object takes 5 possible arguments:\n",
    "\n",
    "1. Datatype(mandatory) specifies the expected data type. \n",
    "2. Default(optional) specifies a default value if none is given.\n",
    "3. Mandatory(optional) is a boolean to put if the Field is mandatory.\n",
    "4. Optional, contrary to Mandaroty.\n",
    "5. Test (function) allows defininf a function to validate the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Telemetry Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelemetryFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about car telemetry and performance\n",
    "    \"\"\"\n",
    "    lap_time = Field(float, mandatory= False)           # Current lap time\n",
    "    predicted_lap_time = Field(float, mandatory=False)  # Predicted lap time by the model\n",
    "    tire_age = Field(int, mandatory=False)              # Age of the current tire set in laps\n",
    "    compound_id = Field(int, mandatory=False)           # Tire type with ID\n",
    "    position = Field(int, mandatory= False)             # Current race position\n",
    "    driver_number = Field(int, mandatory=False)         # Driver number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Degradation Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DegradationFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about tire degradation including future predictions\n",
    "    \"\"\"\n",
    "    degradation_rate = Field(float, mandatory=False)           # Current seconds lost per lap\n",
    "    previous_rates = Field(list, mandatory=False)              # Historical degradation rates\n",
    "    fuel_adjusted_deg_percent = Field(float, mandatory=False)  # Percentage degradation adjusted for fuel\n",
    "    predicted_rates = Field(list, mandatory=False)             # Array of predicted future degradation rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gap Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about gaps to other cars\n",
    "    \"\"\"\n",
    "    driver_number = Field(int, mandatory=True)          # Driver this gap data is for\n",
    "    gap_ahead = Field(float, mandatory=False)           # Time to car ahead (seconds)\n",
    "    gap_behind = Field(float, mandatory=False)          # Time to car behind (seconds)\n",
    "    gap_ahead_trend = Field(float, mandatory=False)     # Change in gap ahead over last laps\n",
    "    gap_behind_trend = Field(float, mandatory=False)    # Change in gap behind over last laps\n",
    "    car_ahead = Field(int, mandatory=False)             # Driver number of car ahead\n",
    "    car_behind = Field(int, mandatory=False)            # Driver number of car behind\n",
    "    in_undercut_window = Field(bool, mandatory=False)   # Whether in undercut window (gap < 1.5s)\n",
    "    in_drs_window = Field(bool, mandatory=False)        # Whether in DRS window (gap < 1.0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Radio Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts from radio communications analysis\n",
    "    \"\"\"\n",
    "    sentiment = Field(str, mandatory= False)  # positive, negative, neutral\n",
    "    intent = Field(str, mandatory= False)     # WARNING, QUESTION, etc.\n",
    "    entities = Field(dict, mandatory= False)  # Detected entities categorized (SITUATION, INCIDENT, PIT_CALL, etc)\n",
    "    timestamp = Field(float, mandatory= False)# When the message was received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Race Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceStatusFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about current race status\n",
    "    \"\"\"\n",
    "    lap = Field(int, mandatory= True)               # Current lap\n",
    "    total_laps = Field(int, mandatory= True)        # Total race laps\n",
    "    race_phase = Field(str, mandatory= False)       # start, mid, end\n",
    "    track_status = Field(str, mandatory= False)     # clear, yellow, safety car, red flag\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Strategy Recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyRecommendation(Fact):\n",
    "    \"\"\"\n",
    "    Reccommendation produced by the Expert System\n",
    "    \"\"\"\n",
    "    action = Field(str, mandatory= True)                        # Specific action to take\n",
    "    confidence = Field(float, mandatory= True)                  # Confidende level (0-1)\n",
    "    explanation = Field(str, mandatory= True)                   # Natural Language Explanation\n",
    "    priority = Field(int, mandatory= False, default = 0)        # Priority level (higher = more urgent)\n",
    "    lap_issued = Field(int, mandatory= True)                    # Lap when reccomendation was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engine Definition with Rule Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1StrategyEngine(KnowledgeEngine):\n",
    "    \"\"\"\n",
    "    Formula 1 strategy expert system engine\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rules_fired = []  # Tracking the rules that have been activated\n",
    "    \n",
    "    def get_recommendations(self):\n",
    "        \"\"\"\n",
    "        Retrieve all current recommendations, sorted by priority and confidence\n",
    "        \"\"\"\n",
    "\n",
    "        recommendations = []\n",
    "        for fact in self.facts.values():\n",
    "            if isinstance(fact, StrategyRecommendation):\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        \"action\": fact[\"action\"],\n",
    "                        \"confidence\": fact[\"confidence\"],\n",
    "                        \"explanation\": fact[\"explanation\"],\n",
    "                        \"priority\": fact.get(\"priority\", 0),\n",
    "                        \"lap_issued\" : fact[\"lap_issued\"]\n",
    "                    }\n",
    "                )\n",
    "        return sorted(\n",
    "            recommendations,\n",
    "            key = lambda x: (x[\"priority\"], x[\"confidence\"]),\n",
    "            reverse= True\n",
    "        )\n",
    "    \n",
    "    def record_rule_fired(self, rule_name):\n",
    "        \"\"\"\n",
    "        Record when a rule is fired for explanation and debugging\n",
    "        \"\"\"\n",
    "\n",
    "        current_lap = None\n",
    "        for fact in self.facts.values():\n",
    "            if isinstance(fact, RaceStatusFact):\n",
    "                current_lap = fact.get(\"lap\")\n",
    "                break\n",
    "        \n",
    "        self.rules_fired.append(\n",
    "            {\n",
    "                \"rule\": rule_name,\n",
    "                \"lap\": current_lap,\n",
    "                \"timestamp\": pd.Timestamp.now()\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Transformation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Transforming tire predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza completamente la función transform_tire_predictions en utils/N01_agent_setup.py\n",
    "\n",
    "def transform_tire_predictions(predictions_df, driver_number):\n",
    "    \"\"\"\n",
    "    Transform the output from predict_tire_degradation into facts for the rule engine.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df (DataFrame): Output from predict_tire_degradation function\n",
    "        driver_number (int): The driver number to extract data for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with facts to declare\n",
    "    \"\"\"\n",
    "    # Filter data for the specific driver\n",
    "    driver_data = predictions_df[predictions_df['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        print(f\"Warning: No prediction data found for driver {driver_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent stint\n",
    "    latest_stint = driver_data['Stint'].max()\n",
    "    stint_data = driver_data[driver_data['Stint'] == latest_stint]\n",
    "    \n",
    "    # Group predictions by current tire age (we want the most recent window)\n",
    "    latest_age = stint_data['CurrentTyreAge'].max()\n",
    "    latest_data = stint_data[stint_data['CurrentTyreAge'] == latest_age]\n",
    "    \n",
    "    # Sort predictions by how far in the future they are\n",
    "    future_data = latest_data.sort_values('LapsAheadPred')\n",
    "    \n",
    "    # Extract future degradation rates\n",
    "    predicted_rates = future_data['PredictedDegradationRate'].tolist()\n",
    "    \n",
    "    # Get basic info about current state\n",
    "    current_info = future_data.iloc[0]\n",
    "    \n",
    "    # CORRECTION: Use the first predicted degradation rate as the current rate\n",
    "    # instead of using 0.0 as a placeholder\n",
    "    current_degradation_rate = predicted_rates[0] if predicted_rates else 0.0\n",
    "    print(f\"Using first predicted rate as current degradation: {current_degradation_rate}\")\n",
    "    \n",
    "    # Create degradation fact with current and predicted data\n",
    "    degradation_fact = DegradationFact(\n",
    "        degradation_rate=current_degradation_rate,  # Now using the actual predicted rate\n",
    "        predicted_rates=predicted_rates  # Array of future predictions\n",
    "    )\n",
    "\n",
    "    # Create corresponding telemetry fact\n",
    "    telemetry_fact = TelemetryFact(\n",
    "        tire_age=int(latest_age),\n",
    "        compound_id=int(current_info['CompoundID']),\n",
    "        driver_number=int(driver_number),\n",
    "        # Add position if available\n",
    "        position=int(current_info.get('Position', 0))\n",
    "    )\n",
    "    \n",
    "    # Add current lap time if available\n",
    "    if 'CurrentLapTime' in current_info:\n",
    "        telemetry_fact['lap_time'] = float(current_info['CurrentLapTime'])\n",
    "    \n",
    "    return {\n",
    "        'degradation': degradation_fact,\n",
    "        'telemetry': telemetry_fact\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tire_predictions(race_data, models_path, compound_thresholds=None):\n",
    "    \"\"\"\n",
    "    Load tire predictions from the prediction module.\n",
    "    \n",
    "    Args:\n",
    "        race_data (DataFrame): Race telemetry data\n",
    "        models_path (str): Path to the directory containing model files\n",
    "        compound_thresholds (dict): Dictionary mapping compound IDs to starting lap numbers\n",
    "                                  (e.g., {1: 6, 2: 12, 3: 25})\n",
    "                                  \n",
    "    Returns:\n",
    "        DataFrame: Tire degradation predictions\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Import the module\n",
    "    from ML_tyre_pred.ML_utils import N02_model_tire_predictions as tdp\n",
    "    \n",
    "    # Default thresholds based on F1 knowledge if none provided\n",
    "    if compound_thresholds is None:\n",
    "        compound_thresholds = {\n",
    "            1: 6,   # Soft tires: monitor from lap 6 onwards\n",
    "            2: 12,  # Medium tires: monitor from lap 12 onwards\n",
    "            3: 25   # Hard tires: monitor from lap 25 onwards\n",
    "        }\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = tdp.predict_tire_degradation(\n",
    "        race_data,\n",
    "        models_path,\n",
    "        compound_start_laps=compound_thresholds\n",
    "    )\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_current_degradation(telemetry_data, driver_number):\n",
    "    \"\"\"\n",
    "    Extract current degradation rate from telemetry data.\n",
    "    \n",
    "    Args:\n",
    "        telemetry_data (DataFrame): Processed telemetry data with DegradationRate\n",
    "        driver_number (int): Driver number to get data for\n",
    "        \n",
    "    Returns:\n",
    "        float: Current degradation rate or 0.0 if not available\n",
    "    \"\"\"\n",
    "    # Filter for the specific driver\n",
    "    driver_data = telemetry_data[telemetry_data['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get the most recent lap data\n",
    "    latest_data = driver_data.sort_values('TyreAge', ascending=False).iloc[0]\n",
    "    \n",
    "    # Return degradation rate if available\n",
    "    return float(latest_data.get('DegradationRate', 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Transforming Lap Times predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lap_time_predictions(predictions_df, driver_number):\n",
    "    \"\"\"\n",
    "    Transform the output from predict_lap_times into facts for the rule engine.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df (DataFrame): Output from predict_lap_times function\n",
    "        driver_number (int): The driver number to extract data for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with facts to declare\n",
    "    \"\"\"\n",
    "    # Filter data for the specific driver\n",
    "    driver_data = predictions_df[predictions_df['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        print(f\"Warning: No lap time prediction data found for driver {driver_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent lap data\n",
    "    latest_lap = driver_data.iloc[-1]\n",
    "    \n",
    "    # Check if this is a next lap prediction (future prediction)\n",
    "    is_future = latest_lap.get('IsNextLapPrediction', False)\n",
    "    \n",
    "    # Create telemetry fact with current and predicted lap times\n",
    "    telemetry_fact = TelemetryFact(\n",
    "        driver_number=int(driver_number),\n",
    "        # Current lap time if available\n",
    "        lap_time=float(latest_lap['LapTime']) if not pd.isna(latest_lap['LapTime']) else None,\n",
    "        # Future lap time prediction\n",
    "        predicted_lap_time=float(latest_lap['PredictedLapTime']),\n",
    "        # Include other available telemetry data\n",
    "        compound_id=int(latest_lap.get('CompoundID', 0)),\n",
    "        tire_age=int(latest_lap.get('TyreAge', 0)),\n",
    "        position=int(latest_lap.get('Position', 0))\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'telemetry': telemetry_fact\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lap_time_predictions(race_data, model_path=None):\n",
    "    \"\"\"\n",
    "    Load lap time predictions from the prediction module.\n",
    "    \n",
    "    Args:\n",
    "        race_data (DataFrame): Race telemetry data\n",
    "        model_path (str): Path to the model file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Lap time predictions\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Use a dynamic import to avoid issues if module structure changes\n",
    "    try:\n",
    "        # Try importing the module separately\n",
    "        from ML_tyre_pred.ML_utils.N00_model_lap_prediction import predict_lap_times\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = predict_lap_times(\n",
    "            race_data,\n",
    "            model_path=model_path,\n",
    "            include_next_lap=True\n",
    "        )\n",
    "        \n",
    "        return predictions\n",
    "    except ImportError:\n",
    "        print(\"Warning: Could not import lap prediction module.\")\n",
    "        print(\"Make sure 'lap_prediction_module.py' is in the specified path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting lap times: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Transforming Radio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_radio_analysis(radio_json_path):\n",
    "    \"\"\"\n",
    "    Transform NLP radio analysis into facts.\n",
    "    \n",
    "    Args:\n",
    "        radio_json_path (str): Path to the JSON file containing radio analysis\n",
    "        \n",
    "    Returns:\n",
    "        RadioFact: Fact with radio analysis information\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(radio_json_path, 'r') as file:\n",
    "        radio_data = json.load(file)\n",
    "    \n",
    "    # Extract the analysis section\n",
    "    analysis = radio_data['analysis']\n",
    "    \n",
    "    # Create the RadioFact\n",
    "    return RadioFact(\n",
    "        sentiment=analysis['sentiment'],\n",
    "        intent=analysis['intent'],\n",
    "        entities=analysis['entities'],\n",
    "        timestamp=pd.Timestamp.now().timestamp()\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_radio_message(message, is_audio=False):\n",
    "    \"\"\"\n",
    "    Process a radio message (text or audio) and get its analysis.\n",
    "    \n",
    "    Args:\n",
    "        message (str): Text message or path to audio file\n",
    "        is_audio (bool): Whether the input is an audio file\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the JSON file with the analysis\n",
    "    \"\"\"\n",
    "    # Import the radio processing module\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append(os.path.abspath('../'))\n",
    "    \n",
    "    try:\n",
    "        from NLP_radio_processing.NLP_utils import N06_model_merging as radio_nlp\n",
    "        \n",
    "        # If it's audio, first transcribe it\n",
    "        if is_audio:\n",
    "            print(f\"Transcribing audio from: {message}\")\n",
    "            message_text = radio_nlp.transcribe_audio(message)\n",
    "            print(f\"Transcription: '{message_text}'\")\n",
    "        else:\n",
    "            message_text = message\n",
    "        \n",
    "        # Analyze the message\n",
    "        print(f\"Analyzing message: '{message_text}'\")\n",
    "        json_path = radio_nlp.analyze_radio_message(message_text)\n",
    "        \n",
    "        return json_path\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Error: Could not import NLP module. Make sure it's in the correct path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing radio message: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_transform_radio(message, is_audio=False):\n",
    "    \"\"\"\n",
    "    Complete function to process a radio message and transform it into a fact.\n",
    "    \n",
    "    Args:\n",
    "        message (str): Text message or path to audio file\n",
    "        is_audio (bool): Whether the input is an audio file\n",
    "        \n",
    "    Returns:\n",
    "        RadioFact: Fact with structured radio analysis\n",
    "    \"\"\"\n",
    "    # Step 1: Process the message\n",
    "    json_path = process_radio_message(message, is_audio)\n",
    "    \n",
    "    if json_path is None:\n",
    "        print(\"Failed to process radio message.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Transform the analysis into a fact\n",
    "    return transform_radio_analysis(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Transforming gap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# PREPROCESSING FUNCTION: CALCULATE GAP CONSISTENCY\n",
    "# ------------------------------------------------------------------------------------\n",
    "def calculate_gap_consistency(gaps_df):\n",
    "    \"\"\"\n",
    "    Calculate how many consecutive laps a driver has been in the same gap window.\n",
    "    \n",
    "    This function adds two columns to the dataframe:\n",
    "    - consistent_gap_ahead_laps: Number of consecutive laps with gap_ahead in the same window\n",
    "    - consistent_gap_behind_laps: Number of consecutive laps with gap_behind in the same window\n",
    "    \n",
    "    Args:\n",
    "        gaps_df (DataFrame): DataFrame with gap data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: The same DataFrame with added consistency columns\n",
    "    \"\"\"\n",
    "    print(\"Calculating gap consistency across laps...\")\n",
    "    \n",
    "    # Define the gap windows we care about\n",
    "    def get_ahead_window(gap):\n",
    "        if gap < 2.0:\n",
    "            return \"undercut_window\"\n",
    "        elif 2.0 <= gap < 3.5:\n",
    "            return \"overcut_window\"\n",
    "        else:\n",
    "            return \"out_of_range\"\n",
    "    \n",
    "    def get_behind_window(gap):\n",
    "        if gap < 2.0:\n",
    "            return \"defensive_window\"\n",
    "        else:\n",
    "            return \"safe_window\"\n",
    "    \n",
    "    # Add window classification columns\n",
    "    gaps_df['ahead_window'] = gaps_df['GapToCarAhead'].apply(get_ahead_window)\n",
    "    gaps_df['behind_window'] = gaps_df['GapToCarBehind'].apply(get_behind_window)\n",
    "    \n",
    "    # Initialize consistency columns\n",
    "    gaps_df['consistent_gap_ahead_laps'] = 1\n",
    "    gaps_df['consistent_gap_behind_laps'] = 1\n",
    "    \n",
    "    # Process each driver separately\n",
    "    for driver in gaps_df['DriverNumber'].unique():\n",
    "        driver_data = gaps_df[gaps_df['DriverNumber'] == driver].sort_values('LapNumber')\n",
    "        \n",
    "        # Skip if less than 2 laps of data\n",
    "        if len(driver_data) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Process consistency of ahead gap\n",
    "        for i in range(1, len(driver_data)):\n",
    "            current_idx = driver_data.iloc[i].name\n",
    "            prev_idx = driver_data.iloc[i-1].name\n",
    "            \n",
    "            if driver_data.iloc[i]['ahead_window'] == driver_data.iloc[i-1]['ahead_window']:\n",
    "                gaps_df.loc[current_idx, 'consistent_gap_ahead_laps'] = gaps_df.loc[prev_idx, 'consistent_gap_ahead_laps'] + 1\n",
    "            \n",
    "            if driver_data.iloc[i]['behind_window'] == driver_data.iloc[i-1]['behind_window']:\n",
    "                gaps_df.loc[current_idx, 'consistent_gap_behind_laps'] = gaps_df.loc[prev_idx, 'consistent_gap_behind_laps'] + 1\n",
    "    \n",
    "    print(\"Gap consistency calculation complete!\")\n",
    "    return gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# UPDATE THE TRANSFORM FUNCTION TO INCLUDE CONSISTENCY\n",
    "# ------------------------------------------------------------------------------------\n",
    "def transform_gap_data_with_consistency(gaps_df, driver_number):\n",
    "    \"\"\"\n",
    "    Enhanced version of transform_gap_data that includes consistency metrics\n",
    "    \"\"\"\n",
    "    # Filter data for the specific driver\n",
    "    driver_data = gaps_df[gaps_df['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        print(f\"Warning: No gap data found for driver {driver_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent gap data\n",
    "    latest_data = driver_data.sort_values('LapNumber', ascending=False).iloc[0]\n",
    "    \n",
    "    # Handle car ahead number conversion safely\n",
    "    try:\n",
    "        car_ahead_val = latest_data.get('CarAheadNumber', 0)\n",
    "        # If it's \"Leader\" or another non-numeric string, use a placeholder value\n",
    "        if isinstance(car_ahead_val, str) and not car_ahead_val.isdigit():\n",
    "            car_ahead = -1  # Use -1 to represent the leader \n",
    "        else:\n",
    "            car_ahead = int(car_ahead_val) if not pd.isna(car_ahead_val) else -1\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Warning: Could not convert CarAheadNumber '{car_ahead_val}' to int. Using -1.\")\n",
    "        car_ahead = -1\n",
    "    \n",
    "    # Handle car behind number conversion safely\n",
    "    try:\n",
    "        car_behind_val = latest_data.get('CarBehindNumber', 0)\n",
    "        # If it's \"Tail\" or another non-numeric string, use a placeholder value\n",
    "        if isinstance(car_behind_val, str) and not car_behind_val.isdigit():\n",
    "            car_behind = -2  # Use -2 to represent the tail\n",
    "        else:\n",
    "            car_behind = int(car_behind_val) if not pd.isna(car_behind_val) else -2\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"Warning: Could not convert CarBehindNumber '{car_behind_val}' to int. Using -2.\")\n",
    "        car_behind = -2\n",
    "    \n",
    "    # Check if consistency columns exist, if not, we need to calculate them\n",
    "    if 'consistent_gap_ahead_laps' not in latest_data:\n",
    "        print(\"Warning: consistency metrics not found in data. Ensure calculate_gap_consistency was called.\")\n",
    "    \n",
    "    # Create gap fact with safe type conversions\n",
    "    gap_fact = GapFact(\n",
    "        driver_number=int(driver_number),\n",
    "        gap_ahead=float(latest_data.get('GapToCarAhead', 0.0)),\n",
    "        gap_behind=float(latest_data.get('GapToCarBehind', 0.0)),\n",
    "        car_ahead=car_ahead,\n",
    "        car_behind=car_behind,\n",
    "        gap_to_leader=float(latest_data.get('GapToLeader', 0.0)),\n",
    "        consistent_gap_ahead_laps=int(latest_data.get('consistent_gap_ahead_laps', 1)),\n",
    "        consistent_gap_behind_laps=int(latest_data.get('consistent_gap_behind_laps', 1)),\n",
    "        in_undercut_window=bool(latest_data.get('InUndercutWindow', False)),\n",
    "        in_drs_window=bool(latest_data.get('InDRSWindow', False))\n",
    "    )\n",
    "    \n",
    "    return gap_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gap_data(race_session, window_size=3):\n",
    "    \"\"\"\n",
    "    Load and process gap data from FastF1 session.\n",
    "    \n",
    "    Args:\n",
    "        race_session: FastF1 session object with loaded data\n",
    "        window_size (int): Number of laps to calculate trend over\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed gap data with relevant metrics\n",
    "    \"\"\"\n",
    "    # Make sure we have the necessary data\n",
    "    if not hasattr(race_session, 'laps'):\n",
    "        print(\"Error: Session does not have lap data loaded\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get all laps data\n",
    "    laps_df = race_session.laps\n",
    "    \n",
    "    # Initialize our result dataframe\n",
    "    gaps_data = []\n",
    "    \n",
    "    # Get unique drivers\n",
    "    drivers = laps_df['DriverNumber'].unique()\n",
    "    \n",
    "    # Process each lap for each driver\n",
    "    for lap_number in sorted(laps_df['LapNumber'].unique()):\n",
    "        # Get this lap's data for all drivers\n",
    "        lap_data = laps_df[laps_df['LapNumber'] == lap_number]\n",
    "        \n",
    "        # Sort by position to find cars ahead and behind\n",
    "        lap_data = lap_data.sort_values('Position')\n",
    "        \n",
    "        # For each driver, calculate gaps to cars ahead and behind\n",
    "        for i, driver_lap in lap_data.iterrows():\n",
    "            driver_number = driver_lap['DriverNumber']\n",
    "            position = driver_lap['Position']\n",
    "            \n",
    "            # Find car ahead\n",
    "            car_ahead_data = lap_data[lap_data['Position'] == position - 1]\n",
    "            car_behind_data = lap_data[lap_data['Position'] == position + 1]\n",
    "            \n",
    "            # Calculate gaps\n",
    "            gap_to_car_ahead = None\n",
    "            car_ahead_number = None\n",
    "            if not car_ahead_data.empty:\n",
    "                car_ahead_number = car_ahead_data.iloc[0]['DriverNumber']\n",
    "                # Calculate gap using time difference\n",
    "                # This is simplified - in real code you might need more complex calculation\n",
    "                gap_to_car_ahead = driver_lap['LapTime'] - car_ahead_data.iloc[0]['LapTime']\n",
    "            \n",
    "            gap_to_car_behind = None\n",
    "            car_behind_number = None\n",
    "            if not car_behind_data.empty:\n",
    "                car_behind_number = car_behind_data.iloc[0]['DriverNumber']\n",
    "                # Similar calculation for car behind\n",
    "                gap_to_car_behind = car_behind_data.iloc[0]['LapTime'] - driver_lap['LapTime']\n",
    "            \n",
    "            # Store this data point\n",
    "            gaps_data.append({\n",
    "                'DriverNumber': driver_number,\n",
    "                'LapNumber': lap_number,\n",
    "                'Position': position,\n",
    "                'CarAheadNumber': car_ahead_number,\n",
    "                'CarBehindNumber': car_behind_number,\n",
    "                'GapToCarAhead': gap_to_car_ahead,\n",
    "                'GapToCarBehind': gap_to_car_behind,\n",
    "                'InUndercutWindow': gap_to_car_ahead is not None and gap_to_car_ahead < 1.5,\n",
    "                'InDRSWindow': gap_to_car_ahead is not None and gap_to_car_ahead < 1.0\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    gaps_df = pd.DataFrame(gaps_data)\n",
    "    \n",
    "    # Calculate trends over the specified window\n",
    "    if not gaps_df.empty:\n",
    "        # Group by driver\n",
    "        for driver in drivers:\n",
    "            driver_data = gaps_df[gaps_df['DriverNumber'] == driver].sort_values('LapNumber')\n",
    "            \n",
    "            # Calculate rolling difference for gap ahead\n",
    "            if 'GapToCarAhead' in driver_data.columns:\n",
    "                gaps_df.loc[driver_data.index, 'GapToCarAheadTrend'] = \\\n",
    "                    driver_data['GapToCarAhead'].diff(periods=window_size)\n",
    "            \n",
    "            # Calculate rolling difference for gap behind\n",
    "            if 'GapToCarBehind' in driver_data.columns:\n",
    "                gaps_df.loc[driver_data.index, 'GapToCarBehindTrend'] = \\\n",
    "                    driver_data['GapToCarBehind'].diff(periods=window_size)\n",
    "    \n",
    "    return gaps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating Race Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_race_phase(current_lap, total_laps):\n",
    "    \"\"\"Calculate the current phase of the race.\"\"\"\n",
    "    percentage = (current_lap / total_laps) * 100\n",
    "    if percentage < 25:\n",
    "        return \"start\"\n",
    "    elif percentage > 75:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"mid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Engine Initialization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine initialized with 2 facts\n",
      "Initial facts: [InitialFact(), RaceStatusFact(lap=1, total_laps=60, race_phase='start', track_status='clear')]\n"
     ]
    }
   ],
   "source": [
    "# Create an engine instance\n",
    "engine = F1StrategyEngine()\n",
    "engine.reset()\n",
    "\n",
    "# Example declaring some initial facts\n",
    "engine.declare(RaceStatusFact(lap=1, total_laps=60, race_phase=\"start\", track_status=\"clear\"))\n",
    "\n",
    "# Print the engine state to verify initialization\n",
    "print(f\"Engine initialized with {len(engine.facts)} facts\")\n",
    "facts_list = [f for f in engine.facts.values()]\n",
    "print(f\"Initial facts: {facts_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TIRE DEGRADATION ANALYSIS ===\n",
      "Using first predicted rate as current degradation: 0.07\n",
      "Tire facts declared: {'degradation': DegradationFact(degradation_rate=0.07, predicted_rates=frozenlist([0.07, 0.09, 0.12])), 'telemetry': TelemetryFact(tire_age=4, compound_id=2, driver_number=44, position=1)}\n",
      "Engine now has 4 facts\n"
     ]
    }
   ],
   "source": [
    "# 1. TIRE DEGRADATION EXAMPLE\n",
    "# --------------------------\n",
    "print(\"\\n=== TIRE DEGRADATION ANALYSIS ===\")\n",
    "\n",
    "# Example of transforming model predictions into facts\n",
    "mock_degradation_data = pd.DataFrame({\n",
    "    'DriverNumber': [44, 44, 44],  # Same driver\n",
    "    'Stint': [1, 1, 1],  # Same stint\n",
    "    'CurrentTyreAge': [4, 4, 4],  # Same current tire age\n",
    "    'LapsAheadPred': [1, 2, 3],  # Predictions for 1, 2, and 3 laps ahead\n",
    "    'PredictedDegradationRate': [0.07, 0.09, 0.12],  # Increasing degradation\n",
    "    'CompoundID': [2, 2, 2],  # Medium tires\n",
    "    'Position': [1, 1, 1],  # Position\n",
    "    'FuelAdjustedDegPercent': [5.0, 6.0, 7.0]  # Optional\n",
    "})\n",
    "\n",
    "# Transform degradation data into facts\n",
    "tire_facts = transform_tire_predictions(mock_degradation_data, 44)\n",
    "if tire_facts:\n",
    "    engine.declare(tire_facts['degradation'])\n",
    "    engine.declare(tire_facts['telemetry'])\n",
    "    print(f\"Tire facts declared: {tire_facts}\")\n",
    "else:\n",
    "    print(\"Failed to create tire facts\")\n",
    "\n",
    "# Count facts after tire data\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LAP TIME PREDICTION ===\n",
      "Lap time facts declared: {'telemetry': TelemetryFact(driver_number=44, lap_time=80.3, predicted_lap_time=79.9, compound_id=2, tire_age=4, position=1)}\n",
      "Engine now has 5 facts\n"
     ]
    }
   ],
   "source": [
    "# 2. LAP TIME PREDICTION EXAMPLE\n",
    "# -----------------------------\n",
    "print(\"\\n=== LAP TIME PREDICTION ===\")\n",
    "\n",
    "# Example lap time data\n",
    "mock_lap_time_data = pd.DataFrame({\n",
    "    'DriverNumber': [44, 44],\n",
    "    'LapNumber': [3, 4],\n",
    "    'LapTime': [80.5, 80.3],\n",
    "    'PredictedLapTime': [80.1, 79.9],\n",
    "    'CompoundID': [2, 2],\n",
    "    'TyreAge': [3, 4],\n",
    "    'Position': [1, 1],\n",
    "    'IsNextLapPrediction': [False, False]\n",
    "})\n",
    "\n",
    "# Transform lap time predictions into facts\n",
    "lap_facts = transform_lap_time_predictions(mock_lap_time_data, 44)\n",
    "if lap_facts:\n",
    "    engine.declare(lap_facts['telemetry'])\n",
    "    print(f\"Lap time facts declared: {lap_facts}\")\n",
    "else:\n",
    "    print(\"Failed to create lap time facts\")\n",
    "\n",
    "# Count facts after lap time data\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RADIO ANALYSIS ===\n",
      "Radio fact declared: <f-5>\n"
     ]
    }
   ],
   "source": [
    "# 3. RADIO ANALYSIS EXAMPLE\n",
    "# -----------------------\n",
    "print(\"\\n=== RADIO ANALYSIS ===\")\n",
    "\n",
    "# Mock radio analysis result (simulating the JSON output)\n",
    "mock_radio_json = {\n",
    "    \"message\": \"Box this lap for softs, there's rain expected in 10 minutes\",\n",
    "    \"analysis\": {\n",
    "        \"sentiment\": \"neutral\",\n",
    "        \"intent\": \"ORDER\",\n",
    "        \"entities\": {\n",
    "            \"ACTION\": [],\n",
    "            \"SITUATION\": [\"rain expected\"],\n",
    "            \"INCIDENT\": [],\n",
    "            \"STRATEGY_INSTRUCTION\": [],\n",
    "            \"POSITION_CHANGE\": [],\n",
    "            \"PIT_CALL\": [\"Box this lap\"],\n",
    "            \"TRACK_CONDITION\": [],\n",
    "            \"TECHNICAL_ISSUE\": [],\n",
    "            \"WEATHER\": [\"rain\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save mock JSON to temporary file for processing\n",
    "import tempfile\n",
    "import json\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:\n",
    "    json.dump(mock_radio_json, tmp)\n",
    "    tmp_path = tmp.name\n",
    "\n",
    "# Transform radio analysis into fact\n",
    "radio_fact = transform_radio_analysis(tmp_path)\n",
    "if radio_fact:\n",
    "    engine.declare(radio_fact)\n",
    "    print(f\"Radio fact declared: {radio_fact}\")\n",
    "else:\n",
    "    print(\"Failed to create radio fact\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine now has 6 facts\n",
      "\n",
      "=== ALL ENGINE FACTS ===\n",
      "Fact 1: InitialFact - <f-0>\n",
      "Fact 2: RaceStatusFact - <f-1>\n",
      "Fact 3: DegradationFact - <f-2>\n",
      "Fact 4: TelemetryFact - <f-3>\n",
      "Fact 5: TelemetryFact - <f-4>\n",
      "Fact 6: RadioFact - <f-5>\n"
     ]
    }
   ],
   "source": [
    "# Final fact count\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")\n",
    "\n",
    "# Display all facts in engine\n",
    "print(\"\\n=== ALL ENGINE FACTS ===\")\n",
    "for i, fact in enumerate(engine.facts.values()):\n",
    "    print(f\"Fact {i+1}: {type(fact).__name__} - {fact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we've established the foundation for our F1 Strategy Expert System:\n",
    "\n",
    "1. **Theoretical Framework**: We've explored the fundamentals of production systems, the RETE algorithm, and why Experta is an excellent choice for modeling F1 strategy decisions.\n",
    "\n",
    "2. **Data Structure**: We've defined fact classes that will store our knowledge:\n",
    "   - `TelemetryFact`: For car performance data\n",
    "   - `DegradationFact`: For tire wear information\n",
    "   - `GapFact`: For tracking race positions\n",
    "   - `RadioFact`: For communication analysis\n",
    "   - `RaceStatusFact`: For race conditions\n",
    "   - `StrategyRecommendation`: For system output\n",
    "\n",
    "3. **Engine Setup**: We've created the `F1StrategyEngine` class that will manage rules and track recommendations.\n",
    "\n",
    "4. **Data Transformation**: We've implemented functions to convert:\n",
    "   - Tire degradation predictions into facts\n",
    "   - Lap time predictions into facts\n",
    "   - NLP radio analysis into facts\n",
    "\n",
    "5. **Initial Testing**: We've verified our setup using mock data examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps (Notebook N02)\n",
    "\n",
    "In the next notebook (``N02_degradation_time_rules.ipynb``), we will:\n",
    "\n",
    "1. **Analyze Real Data**: Examine tire degradation patterns from actual races to determine appropriate thresholds for our rules.\n",
    "\n",
    "2. **Implement Core Rules**: Create specific rules related to tire degradation:\n",
    "   - High degradation rate pit stop recommendation\n",
    "   - Stint extension for low degradation\n",
    "   - Early warning for increasing degradation\n",
    "   - Prediction-based degradation alerts\n",
    "\n",
    "3. **Visualize Degradation**: Create plots to understand degradation patterns across race laps and different drivers.\n",
    "\n",
    "4. **Test Rules**: Apply our rules to real race scenarios to validate their effectiveness.\n",
    "\n",
    "5. **Integrate with Model Predictions**: Connect our tire degradation ML models with the rule engine.\n",
    "\n",
    "The next notebook will transform our general framework into a practical decision support system for F1 pit stop strategies based on tire performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
