{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experta: Theory Fundamentals of Production Systems and RETE Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Experta is a Python library based on Production Systems, also known as Expert Systems or Rule-Based Systems, wich is a fundamental paradigm in simbolic AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Expert Systems? \n",
    "\n",
    "An expert system is formed by 3 key components:\n",
    "\n",
    "1. **Facts base**: it stores the factual knowledge of the system. That is, what the system knows in a specific moment.\n",
    "\n",
    "2. **Rule Base**: contains the procedure knowledge as \"if-then\" rules.\n",
    "\n",
    "3. **Inference motor**: motor that determines whether apply one rule or another and when to apply it.\n",
    "\n",
    "The central idea is no model the thinking as a rule chaining process, simillar at how human experts would take a decission applying their knowledge to a specific subject.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETE Algorithm\n",
    "\n",
    "Experta´s core is RETE algorithm, designed in 1982 by Charles L.Forgy. This algorithm is crucal for knowing what Experta is doing and also knowing why it is efficient:\n",
    "\n",
    "- Its **function** is to optimize the coincidence of patterns between facts and rules. \n",
    "\n",
    "- It builds a node network that represent patterns. Then, it avoids reevaluating all the rules when the facts change.\n",
    "\n",
    "Therefore, RETE builds a \"discrimination net\" that acts as an efficient filter for determining which rules should be activated in response to changes made on the facts base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experta´s execution cycle\n",
    "\n",
    "1. **Match**: the motor identifies all the rules that can be activaded with the actual facts base.\n",
    "2. **Conflict Resolution**: if multiple rules coincide, the motor decides which one is executed first (using conflic resolution strategies).\n",
    "3. **Act**: it executes the action associated with the selected rule, that tipically modifies the facts base.\n",
    "4. **Cycle**: the process is repeated until there are no more rules to be activated.\n",
    "\n",
    "This cycle is knwon as \"cycle recognize-act\" or \"production cycle\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarative vs Imperative Programming\n",
    "\n",
    "Experta is a **Declarative Programming paradigm**, in contrast with traditional programming. Instead of defining HOW to make something step by step, Declarative Programming specifies WHICH conditions need to be acomplished. In Experta, the developer defines rules declaratively and the motor is the one that says when and how are they going to be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance for F1 Strategy\n",
    "\n",
    "Experta´s selection for the F1 strategy problem is theoretically justified due to this 5 points:\n",
    "\n",
    "1. **Codificable expert knowledge**: F1 strategies can be expressed naturally as conditional rules based on expert knowledge.\n",
    "2. **Incremental Reasoning**: during the race, information comes continously, such as radios, telemetry, track data or weather. RETE is efficient for updating conclussions based on new information.\n",
    "3. **Knowledge Explanation**: rules can be read and modified by humans, allowing adjusting strategies based on feedback.\n",
    "4. **Explainable Capacity**: unlike black box models like Neural Networks, a system based on rules can explain exactly which conditions made them make a decission.\n",
    "5. **Multiple Information Integration**: key for my project, as it brings me the capacity to merge structured information as data with semi-structured information like NLP radio analysis or my prediction models in the same logical framework.\n",
    "\n",
    "The implementation through Experta allows to capture strategic reasoning of F1 Teams, creating a system that emulates how they would take real-time decissions based on the actual avaliable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example of Decision Making with an Expert System\n",
    "\n",
    "I will illustrate a simple case: deciding whether an F1 car should pit based on tire degradation and weather conditions.\n",
    "\n",
    "### 1. Problem Definition\n",
    "We have basic rules to decide on a pit stop:\n",
    "\n",
    "- If tire degradation is greater than 60%, recommend a pit stop.\n",
    "- If it is raining and the car has dry tires, recommend a pit stop.\n",
    "- If the degradation is moderate (30-60%) and the driver reports grip issues, recommend a pit stop.\n",
    "\n",
    "### 2. Step-by-Step Process\n",
    "Here is what happens when we run Experta:\n",
    "\n",
    "#### 2.1 Initialization:\n",
    "- The rule engine `EstrategiaF1` is created.\n",
    "- The method `reset()` is called to prepare the engine.\n",
    "\n",
    "#### 2.2 Declaration of Facts:\n",
    "- We add that the tires have a degradation of 45% and are of the dry type.\n",
    "- We add that it is not raining.\n",
    "- We add that the driver reports grip issues.\n",
    "\n",
    "#### 2.3 Execution of the RETE Cycle:\n",
    "- The engine calls `run()`, starting the inference cycle.\n",
    "- RETE builds an activation network with the three defined rules.\n",
    "\n",
    "#### 2.4 Rule Evaluation:\n",
    "- **First rule (very_degraded_tires):** DOES NOT MATCH because degradation = 45% (less than 60%).\n",
    "- **Second rule (change_to_rain):** DOES NOT MATCH because raining = False.\n",
    "- **Third rule (moderate_grip_problems):** MATCHES because:\n",
    "  - degradation = 45% (is between 30% and 60%)\n",
    "  - the message contains \"problems\" and \"grip\"\n",
    "\n",
    "#### Rule Activation:\n",
    "- The rule `moderate_grip_problems` is activated.\n",
    "- Its action is executed, declaring a new fact: **Recommendation**.\n",
    "\n",
    "#### New Evaluation Cycle:\n",
    "- The engine evaluates whether there are new rules that match the newly added fact.\n",
    "- In this case, no additional rules are activated.\n",
    "- The engine terminates the execution.\n",
    "\n",
    "### Final Result:\n",
    "We obtain a recommendation:\n",
    "- **Action recommended:** pit\n",
    "- **Reason:** Grip issues reported with moderate degradation\n",
    "- **Urgency:** medium\n",
    "\n",
    "This is the essence of how the expert system processes the rules: it continuously evaluates the available facts against the rule conditions and executes the corresponding actions when matches occur. The RETE algorithm makes this process efficient by avoiding the need to re-evaluate all rules for every fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "# Import the tire prediction module\n",
    "import sys\n",
    "import os\n",
    "# Add parent directory to path if needed\n",
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definition of Fact Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experta import Fact, Field, KnowledgeEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field object takes 5 possible arguments:\n",
    "\n",
    "1. Datatype(mandatory) specifies the expected data type. \n",
    "2. Default(optional) specifies a default value if none is given.\n",
    "3. Mandatory(optional) is a boolean to put if the Field is mandatory.\n",
    "4. Optional, contrary to Mandaroty.\n",
    "5. Test (function) allows defininf a function to validate the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Telemetry Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TelemetryFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about car telemetry and performance\n",
    "    \"\"\"\n",
    "    lap_time = Field(float, mandatory= False)           # Current lap time\n",
    "    predicted_lap_time = Field(float, mandatory=False)  # Predicted lap time by the model\n",
    "    tire_age = Field(int, mandatory=False)              # Age of the current tire set in laps\n",
    "    compound_id = Field(int, mandatory=False)           # Tire type with ID\n",
    "    position = Field(int, mandatory= False)             # Current race position\n",
    "    driver_number = Field(int, mandatory=False)         # Driver number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Degradation Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DegradationFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about tire degradation including future predictions\n",
    "    \"\"\"\n",
    "    degradation_rate = Field(float, mandatory=False)           # Current seconds lost per lap\n",
    "    previous_rates = Field(list, mandatory=False)              # Historical degradation rates\n",
    "    fuel_adjusted_deg_percent = Field(float, mandatory=False)  # Percentage degradation adjusted for fuel\n",
    "    predicted_rates = Field(list, mandatory=False)             # Array of predicted future degradation rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Gap Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GapFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about gaps to other cars\n",
    "    \"\"\"\n",
    "    gap_ahead = Field(float, mandatory= False)          # Time to car ahead (seconds)\n",
    "    gap_behind = Field(float, mandatory= False)         # Time to car behind (seconds)\n",
    "    gap_ahead_trend = Field(float, mandatory= False)    # Change in gap ahead over last laps\n",
    "    gap_behind_trend = Field(float, mandatory= False)   # Change in gap behind over last laps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Radio Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadioFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts from radio communications analysis\n",
    "    \"\"\"\n",
    "    sentiment = Field(str, mandatory= False)  # positive, negative, neutral\n",
    "    intent = Field(str, mandatory= False)     # WARNING, QUESTION, etc.\n",
    "    entities = Field(dict, mandatory= False)  # Detected entities categorized (SITUATION, INCIDENT, PIT_CALL, etc)\n",
    "    timestamp = Field(float, mandatory= False)# When the message was received"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Race Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaceStatusFact(Fact):\n",
    "    \"\"\"\n",
    "    Facts about current race status\n",
    "    \"\"\"\n",
    "    lap = Field(int, mandatory= True)               # Current lap\n",
    "    total_laps = Field(int, mandatory= True)        # Total race laps\n",
    "    race_phase = Field(str, mandatory= False)       # start, mid, end\n",
    "    track_status = Field(str, mandatory= False)     # clear, yellow, safety car, red flag\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Strategy Recomendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyRecommendation(Fact):\n",
    "    \"\"\"\n",
    "    Reccommendation produced by the Expert System\n",
    "    \"\"\"\n",
    "    action = Field(str, mandatory= True)                        # Specific action to take\n",
    "    confidence = Field(float, mandatory= True)                  # Confidende level (0-1)\n",
    "    explanation = Field(str, mandatory= True)                   # Natural Language Explanation\n",
    "    priority = Field(int, mandatory= False, default = 0)        # Priority level (higher = more urgent)\n",
    "    lap_issued = Field(int, mandatory= True)                    # Lap when reccomendation was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Engine Definition with Rule Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1StrategyEngine(KnowledgeEngine):\n",
    "    \"\"\"\n",
    "    Formula 1 strategy expert system engine\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rules_fired = []  # Tracking the rules that have been activated\n",
    "    \n",
    "    def get_recommendations(self):\n",
    "        \"\"\"\n",
    "        Retrieve all current recommendations, sorted by priority and confidence\n",
    "        \"\"\"\n",
    "\n",
    "        recommendations = []\n",
    "        for fact in self.facts.values():\n",
    "            if isinstance(fact, StrategyRecommendation):\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        \"action\": fact[\"action\"],\n",
    "                        \"confidence\": fact[\"confidence\"],\n",
    "                        \"explanation\": fact[\"explanation\"],\n",
    "                        \"priority\": fact.get(\"priority\", 0),\n",
    "                        \"lap_issued\" : fact[\"lap_issued\"]\n",
    "                    }\n",
    "                )\n",
    "        return sorted(\n",
    "            recommendations,\n",
    "            key = lambda x: (x[\"priority\"], x[\"confidence\"]),\n",
    "            reverse= True\n",
    "        )\n",
    "    \n",
    "    def record_rule_fired(self, rule_name):\n",
    "        \"\"\"\n",
    "        Record when a rule is fired for explanation and debugging\n",
    "        \"\"\"\n",
    "\n",
    "        current_lap = None\n",
    "        for fact in self.facts.values():\n",
    "            if isinstance(fact, RaceStatusFact):\n",
    "                current_lap = fact.get(\"lap\")\n",
    "                break\n",
    "        \n",
    "        self.rules_fired.append(\n",
    "            {\n",
    "                \"rule\": rule_name,\n",
    "                \"lap\": current_lap,\n",
    "                \"timestamp\": pd.Timestamp.now()\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Transformation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Transforming tire predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza completamente la función transform_tire_predictions en utils/N01_agent_setup.py\n",
    "\n",
    "def transform_tire_predictions(predictions_df, driver_number):\n",
    "    \"\"\"\n",
    "    Transform the output from predict_tire_degradation into facts for the rule engine.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df (DataFrame): Output from predict_tire_degradation function\n",
    "        driver_number (int): The driver number to extract data for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with facts to declare\n",
    "    \"\"\"\n",
    "    # Filter data for the specific driver\n",
    "    driver_data = predictions_df[predictions_df['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        print(f\"Warning: No prediction data found for driver {driver_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent stint\n",
    "    latest_stint = driver_data['Stint'].max()\n",
    "    stint_data = driver_data[driver_data['Stint'] == latest_stint]\n",
    "    \n",
    "    # Group predictions by current tire age (we want the most recent window)\n",
    "    latest_age = stint_data['CurrentTyreAge'].max()\n",
    "    latest_data = stint_data[stint_data['CurrentTyreAge'] == latest_age]\n",
    "    \n",
    "    # Sort predictions by how far in the future they are\n",
    "    future_data = latest_data.sort_values('LapsAheadPred')\n",
    "    \n",
    "    # Extract future degradation rates\n",
    "    predicted_rates = future_data['PredictedDegradationRate'].tolist()\n",
    "    \n",
    "    # Get basic info about current state\n",
    "    current_info = future_data.iloc[0]\n",
    "    \n",
    "    # CORRECTION: Use the first predicted degradation rate as the current rate\n",
    "    # instead of using 0.0 as a placeholder\n",
    "    current_degradation_rate = predicted_rates[0] if predicted_rates else 0.0\n",
    "    print(f\"Using first predicted rate as current degradation: {current_degradation_rate}\")\n",
    "    \n",
    "    # Create degradation fact with current and predicted data\n",
    "    degradation_fact = DegradationFact(\n",
    "        degradation_rate=current_degradation_rate,  # Now using the actual predicted rate\n",
    "        predicted_rates=predicted_rates  # Array of future predictions\n",
    "    )\n",
    "\n",
    "    # Create corresponding telemetry fact\n",
    "    telemetry_fact = TelemetryFact(\n",
    "        tire_age=int(latest_age),\n",
    "        compound_id=int(current_info['CompoundID']),\n",
    "        driver_number=int(driver_number),\n",
    "        # Add position if available\n",
    "        position=int(current_info.get('Position', 0))\n",
    "    )\n",
    "    \n",
    "    # Add current lap time if available\n",
    "    if 'CurrentLapTime' in current_info:\n",
    "        telemetry_fact['lap_time'] = float(current_info['CurrentLapTime'])\n",
    "    \n",
    "    return {\n",
    "        'degradation': degradation_fact,\n",
    "        'telemetry': telemetry_fact\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tire_predictions(race_data, models_path, compound_thresholds=None):\n",
    "    \"\"\"\n",
    "    Load tire predictions from the prediction module.\n",
    "    \n",
    "    Args:\n",
    "        race_data (DataFrame): Race telemetry data\n",
    "        models_path (str): Path to the directory containing model files\n",
    "        compound_thresholds (dict): Dictionary mapping compound IDs to starting lap numbers\n",
    "                                  (e.g., {1: 6, 2: 12, 3: 25})\n",
    "                                  \n",
    "    Returns:\n",
    "        DataFrame: Tire degradation predictions\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Import the module\n",
    "    from ML_tyre_pred.ML_utils import N02_model_tire_predictions as tdp\n",
    "    \n",
    "    # Default thresholds based on F1 knowledge if none provided\n",
    "    if compound_thresholds is None:\n",
    "        compound_thresholds = {\n",
    "            1: 6,   # Soft tires: monitor from lap 6 onwards\n",
    "            2: 12,  # Medium tires: monitor from lap 12 onwards\n",
    "            3: 25   # Hard tires: monitor from lap 25 onwards\n",
    "        }\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = tdp.predict_tire_degradation(\n",
    "        race_data,\n",
    "        models_path,\n",
    "        compound_start_laps=compound_thresholds\n",
    "    )\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_current_degradation(telemetry_data, driver_number):\n",
    "    \"\"\"\n",
    "    Extract current degradation rate from telemetry data.\n",
    "    \n",
    "    Args:\n",
    "        telemetry_data (DataFrame): Processed telemetry data with DegradationRate\n",
    "        driver_number (int): Driver number to get data for\n",
    "        \n",
    "    Returns:\n",
    "        float: Current degradation rate or 0.0 if not available\n",
    "    \"\"\"\n",
    "    # Filter for the specific driver\n",
    "    driver_data = telemetry_data[telemetry_data['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        return 0.0\n",
    "    \n",
    "    # Get the most recent lap data\n",
    "    latest_data = driver_data.sort_values('TyreAge', ascending=False).iloc[0]\n",
    "    \n",
    "    # Return degradation rate if available\n",
    "    return float(latest_data.get('DegradationRate', 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Transforming Lap Times predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lap_time_predictions(predictions_df, driver_number):\n",
    "    \"\"\"\n",
    "    Transform the output from predict_lap_times into facts for the rule engine.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df (DataFrame): Output from predict_lap_times function\n",
    "        driver_number (int): The driver number to extract data for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with facts to declare\n",
    "    \"\"\"\n",
    "    # Filter data for the specific driver\n",
    "    driver_data = predictions_df[predictions_df['DriverNumber'] == driver_number]\n",
    "    \n",
    "    if driver_data.empty:\n",
    "        print(f\"Warning: No lap time prediction data found for driver {driver_number}\")\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent lap data\n",
    "    latest_lap = driver_data.iloc[-1]\n",
    "    \n",
    "    # Check if this is a next lap prediction (future prediction)\n",
    "    is_future = latest_lap.get('IsNextLapPrediction', False)\n",
    "    \n",
    "    # Create telemetry fact with current and predicted lap times\n",
    "    telemetry_fact = TelemetryFact(\n",
    "        driver_number=int(driver_number),\n",
    "        # Current lap time if available\n",
    "        lap_time=float(latest_lap['LapTime']) if not pd.isna(latest_lap['LapTime']) else None,\n",
    "        # Future lap time prediction\n",
    "        predicted_lap_time=float(latest_lap['PredictedLapTime']),\n",
    "        # Include other available telemetry data\n",
    "        compound_id=int(latest_lap.get('CompoundID', 0)),\n",
    "        tire_age=int(latest_lap.get('TyreAge', 0)),\n",
    "        position=int(latest_lap.get('Position', 0))\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'telemetry': telemetry_fact\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lap_time_predictions(race_data, model_path=None):\n",
    "    \"\"\"\n",
    "    Load lap time predictions from the prediction module.\n",
    "    \n",
    "    Args:\n",
    "        race_data (DataFrame): Race telemetry data\n",
    "        model_path (str): Path to the model file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Lap time predictions\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    # Use a dynamic import to avoid issues if module structure changes\n",
    "    try:\n",
    "        # Try importing the module separately\n",
    "        from ML_tyre_pred.ML_utils.N00_model_lap_prediction import predict_lap_times\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = predict_lap_times(\n",
    "            race_data,\n",
    "            model_path=model_path,\n",
    "            include_next_lap=True\n",
    "        )\n",
    "        \n",
    "        return predictions\n",
    "    except ImportError:\n",
    "        print(\"Warning: Could not import lap prediction module.\")\n",
    "        print(\"Make sure 'lap_prediction_module.py' is in the specified path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting lap times: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Transforming Radio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_radio_analysis(radio_json_path):\n",
    "    \"\"\"\n",
    "    Transform NLP radio analysis into facts.\n",
    "    \n",
    "    Args:\n",
    "        radio_json_path (str): Path to the JSON file containing radio analysis\n",
    "        \n",
    "    Returns:\n",
    "        RadioFact: Fact with radio analysis information\n",
    "    \"\"\"\n",
    "    # Load the JSON file\n",
    "    with open(radio_json_path, 'r') as file:\n",
    "        radio_data = json.load(file)\n",
    "    \n",
    "    # Extract the analysis section\n",
    "    analysis = radio_data['analysis']\n",
    "    \n",
    "    # Create the RadioFact\n",
    "    return RadioFact(\n",
    "        sentiment=analysis['sentiment'],\n",
    "        intent=analysis['intent'],\n",
    "        entities=analysis['entities'],\n",
    "        timestamp=pd.Timestamp.now().timestamp()\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_radio_message(message, is_audio=False):\n",
    "    \"\"\"\n",
    "    Process a radio message (text or audio) and get its analysis.\n",
    "    \n",
    "    Args:\n",
    "        message (str): Text message or path to audio file\n",
    "        is_audio (bool): Whether the input is an audio file\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the JSON file with the analysis\n",
    "    \"\"\"\n",
    "    # Import the radio processing module\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.append(os.path.abspath('../'))\n",
    "    \n",
    "    try:\n",
    "        from NLP_radio_processing.NLP_utils import N06_model_merging as radio_nlp\n",
    "        \n",
    "        # If it's audio, first transcribe it\n",
    "        if is_audio:\n",
    "            print(f\"Transcribing audio from: {message}\")\n",
    "            message_text = radio_nlp.transcribe_audio(message)\n",
    "            print(f\"Transcription: '{message_text}'\")\n",
    "        else:\n",
    "            message_text = message\n",
    "        \n",
    "        # Analyze the message\n",
    "        print(f\"Analyzing message: '{message_text}'\")\n",
    "        json_path = radio_nlp.analyze_radio_message(message_text)\n",
    "        \n",
    "        return json_path\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Error: Could not import NLP module. Make sure it's in the correct path.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing radio message: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_transform_radio(message, is_audio=False):\n",
    "    \"\"\"\n",
    "    Complete function to process a radio message and transform it into a fact.\n",
    "    \n",
    "    Args:\n",
    "        message (str): Text message or path to audio file\n",
    "        is_audio (bool): Whether the input is an audio file\n",
    "        \n",
    "    Returns:\n",
    "        RadioFact: Fact with structured radio analysis\n",
    "    \"\"\"\n",
    "    # Step 1: Process the message\n",
    "    json_path = process_radio_message(message, is_audio)\n",
    "    \n",
    "    if json_path is None:\n",
    "        print(\"Failed to process radio message.\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Transform the analysis into a fact\n",
    "    return transform_radio_analysis(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculating Race Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_race_phase(current_lap, total_laps):\n",
    "    \"\"\"Calculate the current phase of the race.\"\"\"\n",
    "    percentage = (current_lap / total_laps) * 100\n",
    "    if percentage < 25:\n",
    "        return \"start\"\n",
    "    elif percentage > 75:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"mid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Engine Initialization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine instance\n",
    "engine = F1StrategyEngine()\n",
    "engine.reset()\n",
    "\n",
    "# Example declaring some initial facts\n",
    "engine.declare(RaceStatusFact(lap=1, total_laps=60, race_phase=\"start\", track_status=\"clear\"))\n",
    "\n",
    "# Print the engine state to verify initialization\n",
    "print(f\"Engine initialized with {len(engine.facts)} facts\")\n",
    "facts_list = [f for f in engine.facts.values()]\n",
    "print(f\"Initial facts: {facts_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. TIRE DEGRADATION EXAMPLE\n",
    "# --------------------------\n",
    "print(\"\\n=== TIRE DEGRADATION ANALYSIS ===\")\n",
    "\n",
    "# Example of transforming model predictions into facts\n",
    "mock_degradation_data = pd.DataFrame({\n",
    "    'DriverNumber': [44, 44, 44],  # Same driver\n",
    "    'Stint': [1, 1, 1],  # Same stint\n",
    "    'CurrentTyreAge': [4, 4, 4],  # Same current tire age\n",
    "    'LapsAheadPred': [1, 2, 3],  # Predictions for 1, 2, and 3 laps ahead\n",
    "    'PredictedDegradationRate': [0.07, 0.09, 0.12],  # Increasing degradation\n",
    "    'CompoundID': [2, 2, 2],  # Medium tires\n",
    "    'Position': [1, 1, 1],  # Position\n",
    "    'FuelAdjustedDegPercent': [5.0, 6.0, 7.0]  # Optional\n",
    "})\n",
    "\n",
    "# Transform degradation data into facts\n",
    "tire_facts = transform_tire_predictions(mock_degradation_data, 44)\n",
    "if tire_facts:\n",
    "    engine.declare(tire_facts['degradation'])\n",
    "    engine.declare(tire_facts['telemetry'])\n",
    "    print(f\"Tire facts declared: {tire_facts}\")\n",
    "else:\n",
    "    print(\"Failed to create tire facts\")\n",
    "\n",
    "# Count facts after tire data\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LAP TIME PREDICTION EXAMPLE\n",
    "# -----------------------------\n",
    "print(\"\\n=== LAP TIME PREDICTION ===\")\n",
    "\n",
    "# Example lap time data\n",
    "mock_lap_time_data = pd.DataFrame({\n",
    "    'DriverNumber': [44, 44],\n",
    "    'LapNumber': [3, 4],\n",
    "    'LapTime': [80.5, 80.3],\n",
    "    'PredictedLapTime': [80.1, 79.9],\n",
    "    'CompoundID': [2, 2],\n",
    "    'TyreAge': [3, 4],\n",
    "    'Position': [1, 1],\n",
    "    'IsNextLapPrediction': [False, False]\n",
    "})\n",
    "\n",
    "# Transform lap time predictions into facts\n",
    "lap_facts = transform_lap_time_predictions(mock_lap_time_data, 44)\n",
    "if lap_facts:\n",
    "    engine.declare(lap_facts['telemetry'])\n",
    "    print(f\"Lap time facts declared: {lap_facts}\")\n",
    "else:\n",
    "    print(\"Failed to create lap time facts\")\n",
    "\n",
    "# Count facts after lap time data\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. RADIO ANALYSIS EXAMPLE\n",
    "# -----------------------\n",
    "print(\"\\n=== RADIO ANALYSIS ===\")\n",
    "\n",
    "# Mock radio analysis result (simulating the JSON output)\n",
    "mock_radio_json = {\n",
    "    \"message\": \"Box this lap for softs, there's rain expected in 10 minutes\",\n",
    "    \"analysis\": {\n",
    "        \"sentiment\": \"neutral\",\n",
    "        \"intent\": \"ORDER\",\n",
    "        \"entities\": {\n",
    "            \"ACTION\": [],\n",
    "            \"SITUATION\": [\"rain expected\"],\n",
    "            \"INCIDENT\": [],\n",
    "            \"STRATEGY_INSTRUCTION\": [],\n",
    "            \"POSITION_CHANGE\": [],\n",
    "            \"PIT_CALL\": [\"Box this lap\"],\n",
    "            \"TRACK_CONDITION\": [],\n",
    "            \"TECHNICAL_ISSUE\": [],\n",
    "            \"WEATHER\": [\"rain\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save mock JSON to temporary file for processing\n",
    "import tempfile\n",
    "import json\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:\n",
    "    json.dump(mock_radio_json, tmp)\n",
    "    tmp_path = tmp.name\n",
    "\n",
    "# Transform radio analysis into fact\n",
    "radio_fact = transform_radio_analysis(tmp_path)\n",
    "if radio_fact:\n",
    "    engine.declare(radio_fact)\n",
    "    print(f\"Radio fact declared: {radio_fact}\")\n",
    "else:\n",
    "    print(\"Failed to create radio fact\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final fact count\n",
    "print(f\"Engine now has {len(engine.facts)} facts\")\n",
    "\n",
    "# Display all facts in engine\n",
    "print(\"\\n=== ALL ENGINE FACTS ===\")\n",
    "for i, fact in enumerate(engine.facts.values()):\n",
    "    print(f\"Fact {i+1}: {type(fact).__name__} - {fact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this notebook, we've established the foundation for our F1 Strategy Expert System:\n",
    "\n",
    "1. **Theoretical Framework**: We've explored the fundamentals of production systems, the RETE algorithm, and why Experta is an excellent choice for modeling F1 strategy decisions.\n",
    "\n",
    "2. **Data Structure**: We've defined fact classes that will store our knowledge:\n",
    "   - `TelemetryFact`: For car performance data\n",
    "   - `DegradationFact`: For tire wear information\n",
    "   - `GapFact`: For tracking race positions\n",
    "   - `RadioFact`: For communication analysis\n",
    "   - `RaceStatusFact`: For race conditions\n",
    "   - `StrategyRecommendation`: For system output\n",
    "\n",
    "3. **Engine Setup**: We've created the `F1StrategyEngine` class that will manage rules and track recommendations.\n",
    "\n",
    "4. **Data Transformation**: We've implemented functions to convert:\n",
    "   - Tire degradation predictions into facts\n",
    "   - Lap time predictions into facts\n",
    "   - NLP radio analysis into facts\n",
    "\n",
    "5. **Initial Testing**: We've verified our setup using mock data examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps (Notebook N02)\n",
    "\n",
    "In the next notebook (``N02_degradation_time_rules.ipynb``), we will:\n",
    "\n",
    "1. **Analyze Real Data**: Examine tire degradation patterns from actual races to determine appropriate thresholds for our rules.\n",
    "\n",
    "2. **Implement Core Rules**: Create specific rules related to tire degradation:\n",
    "   - High degradation rate pit stop recommendation\n",
    "   - Stint extension for low degradation\n",
    "   - Early warning for increasing degradation\n",
    "   - Prediction-based degradation alerts\n",
    "\n",
    "3. **Visualize Degradation**: Create plots to understand degradation patterns across race laps and different drivers.\n",
    "\n",
    "4. **Test Rules**: Apply our rules to real race scenarios to validate their effectiveness.\n",
    "\n",
    "5. **Integrate with Model Predictions**: Connect our tire degradation ML models with the rule engine.\n",
    "\n",
    "The next notebook will transform our general framework into a practical decision support system for F1 pit stop strategies based on tire performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
