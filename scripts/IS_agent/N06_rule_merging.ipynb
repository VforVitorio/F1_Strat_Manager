{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413ebcbe",
   "metadata": {},
   "source": [
    "# Rule merging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d3ae6d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2dd966",
   "metadata": {},
   "source": [
    "## 1. Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64e0abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine initialized with 2 facts\n",
      "Initial facts: [InitialFact(), RaceStatusFact(lap=1, total_laps=60, race_phase='start', track_status='clear')]\n",
      "\n",
      "=== TIRE DEGRADATION ANALYSIS ===\n",
      "Using first predicted rate as current degradation: 0.07\n",
      "Tire facts declared: {'degradation': DegradationFact(degradation_rate=0.07, predicted_rates=frozenlist([0.07, 0.09, 0.12])), 'telemetry': TelemetryFact(tire_age=4, compound_id=2, driver_number=44, position=1)}\n",
      "Engine now has 4 facts\n",
      "\n",
      "=== LAP TIME PREDICTION ===\n",
      "Lap time facts declared: {'telemetry': TelemetryFact(driver_number=44, lap_time=80.3, predicted_lap_time=79.9, compound_id=2, tire_age=4, position=1)}\n",
      "Engine now has 5 facts\n",
      "\n",
      "=== RADIO ANALYSIS ===\n",
      "Radio fact declared: <f-5>\n",
      "Engine now has 6 facts\n",
      "\n",
      "=== ALL ENGINE FACTS ===\n",
      "Fact 1: InitialFact - <f-0>\n",
      "Fact 2: RaceStatusFact - <f-1>\n",
      "Fact 3: DegradationFact - <f-2>\n",
      "Fact 4: TelemetryFact - <f-3>\n",
      "Fact 5: TelemetryFact - <f-4>\n",
      "Fact 6: RadioFact - <f-5>\n",
      "Successfully loaded data from ../../outputs/week5/tire_degradation_fuel_adjusted.csv\n",
      "Loaded degradation data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Stint",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpeedI1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpeedI2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpeedFL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpeedST",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Position",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "LapsSincePitStop",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DRSUsed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TeamID",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "CompoundID",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "TyreAge",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "FuelLoad",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DriverNumber",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "FuelAdjustedLapTime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FuelAdjustedDegPercent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "DegradationRate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RaceLap",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PreviousRates",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "50aba573-790b-4a3a-8424-eff46abffb18",
       "rows": [
        [
         "0",
         "1.0",
         "256.0",
         "261.0",
         "276.0",
         "275.0",
         "1",
         "1.0",
         "0",
         "9",
         "2",
         "1",
         "0.9848",
         "1",
         "83.935",
         "0.0",
         "0.0",
         "1.0",
         "[0.0]"
        ],
        [
         "16",
         "1.0",
         "252.0",
         "257.0",
         "276.0",
         "295.0",
         "1",
         "2.0",
         "0",
         "9",
         "2",
         "2",
         "0.9697",
         "1",
         "80.45700000000001",
         "-4.143682611544641",
         "-3.941624999999988",
         "2.0",
         "[0.0, -3.941624999999988]"
        ],
        [
         "20",
         "1.0",
         "249.0",
         "256.0",
         "276.0",
         "297.0",
         "1",
         "3.0",
         "0",
         "9",
         "2",
         "3",
         "0.9545",
         "1",
         "80.609",
         "-3.9625900994817553",
         "0.2320916666666619",
         "3.0",
         "[0.0, -3.941624999999988, 0.2320916666666619]"
        ],
        [
         "48",
         "1.0",
         "255.0",
         "256.0",
         "276.0",
         "300.0",
         "1",
         "4.0",
         "0",
         "9",
         "2",
         "4",
         "0.9394",
         "1",
         "80.51100000000001",
         "-4.079347113838083",
         "0.0735921568627446",
         "4.0",
         "[-3.941624999999988, 0.2320916666666619, 0.0735921568627446]"
        ],
        [
         "50",
         "1.0",
         "254.0",
         "256.0",
         "277.0",
         "301.0",
         "1",
         "5.0",
         "0",
         "9",
         "2",
         "5",
         "0.9242",
         "1",
         "80.503",
         "-4.088878298683508",
         "0.0073529411764639",
         "5.0",
         "[0.2320916666666619, 0.0735921568627446, 0.0073529411764639]"
        ]
       ],
       "shape": {
        "columns": 18,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stint</th>\n",
       "      <th>SpeedI1</th>\n",
       "      <th>SpeedI2</th>\n",
       "      <th>SpeedFL</th>\n",
       "      <th>SpeedST</th>\n",
       "      <th>Position</th>\n",
       "      <th>LapsSincePitStop</th>\n",
       "      <th>DRSUsed</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>CompoundID</th>\n",
       "      <th>TyreAge</th>\n",
       "      <th>FuelLoad</th>\n",
       "      <th>DriverNumber</th>\n",
       "      <th>FuelAdjustedLapTime</th>\n",
       "      <th>FuelAdjustedDegPercent</th>\n",
       "      <th>DegradationRate</th>\n",
       "      <th>RaceLap</th>\n",
       "      <th>PreviousRates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>1</td>\n",
       "      <td>83.935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>1</td>\n",
       "      <td>80.457</td>\n",
       "      <td>-4.143683</td>\n",
       "      <td>-3.941625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[0.0, -3.941624999999988]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>1</td>\n",
       "      <td>80.609</td>\n",
       "      <td>-3.962590</td>\n",
       "      <td>0.232092</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[0.0, -3.941624999999988, 0.2320916666666619]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9394</td>\n",
       "      <td>1</td>\n",
       "      <td>80.511</td>\n",
       "      <td>-4.079347</td>\n",
       "      <td>0.073592</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[-3.941624999999988, 0.2320916666666619, 0.073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9242</td>\n",
       "      <td>1</td>\n",
       "      <td>80.503</td>\n",
       "      <td>-4.088878</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[0.2320916666666619, 0.0735921568627446, 0.007...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stint  SpeedI1  SpeedI2  SpeedFL  SpeedST  Position  LapsSincePitStop  \\\n",
       "0     1.0    256.0    261.0    276.0    275.0         1               1.0   \n",
       "16    1.0    252.0    257.0    276.0    295.0         1               2.0   \n",
       "20    1.0    249.0    256.0    276.0    297.0         1               3.0   \n",
       "48    1.0    255.0    256.0    276.0    300.0         1               4.0   \n",
       "50    1.0    254.0    256.0    277.0    301.0         1               5.0   \n",
       "\n",
       "    DRSUsed  TeamID  CompoundID  TyreAge  FuelLoad  DriverNumber  \\\n",
       "0         0       9           2        1    0.9848             1   \n",
       "16        0       9           2        2    0.9697             1   \n",
       "20        0       9           2        3    0.9545             1   \n",
       "48        0       9           2        4    0.9394             1   \n",
       "50        0       9           2        5    0.9242             1   \n",
       "\n",
       "    FuelAdjustedLapTime  FuelAdjustedDegPercent  DegradationRate  RaceLap  \\\n",
       "0                83.935                0.000000         0.000000      1.0   \n",
       "16               80.457               -4.143683        -3.941625      2.0   \n",
       "20               80.609               -3.962590         0.232092      3.0   \n",
       "48               80.511               -4.079347         0.073592      4.0   \n",
       "50               80.503               -4.088878         0.007353      5.0   \n",
       "\n",
       "                                        PreviousRates  \n",
       "0                                               [0.0]  \n",
       "16                          [0.0, -3.941624999999988]  \n",
       "20      [0.0, -3.941624999999988, 0.2320916666666619]  \n",
       "48  [-3.941624999999988, 0.2320916666666619, 0.073...  \n",
       "50  [0.2320916666666619, 0.0735921568627446, 0.007...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported lap prediction module\n",
      "Libraries and fact classes loaded successfully.\n",
      "All components imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from utils.N01_agent_setup import (\n",
    "    # Fact classes for our rule engine\n",
    "    TelemetryFact,\n",
    "    DegradationFact,\n",
    "    GapFact,\n",
    "    RadioFact,\n",
    "    RaceStatusFact,\n",
    "    StrategyRecommendation,\n",
    "    F1StrategyEngine,\n",
    "    \n",
    "    # Utility functions for data transformation\n",
    "    transform_tire_predictions,\n",
    "    load_tire_predictions,\n",
    "    transform_lap_time_predictions,\n",
    "    load_lap_time_predictions,\n",
    "    transform_radio_analysis,\n",
    "    process_radio_message,\n",
    "    transform_gap_data_with_consistency,\n",
    "    load_gap_data,\n",
    "    calculate_gap_consistency\n",
    ")\n",
    "\n",
    "# Import the rule engines from each domain\n",
    "# Tire degradation rules\n",
    "from utils.N02_degradation_time_rules import F1DegradationRules\n",
    "\n",
    "# Lap time prediction rules\n",
    "from utils.N03_lap_time_rules import F1LapTimeRules\n",
    "\n",
    "# Radio communication analysis rules\n",
    "from utils.N04_nlp_rules import F1RadioRules  \n",
    "\n",
    "# Gap analysis rules\n",
    "from utils.N05_gap_rules import F1GapRules\n",
    "\n",
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Import Experta components\n",
    "from experta import Rule, NOT, OR, AND, AS, MATCH, TEST, EXISTS\n",
    "from experta import DefFacts, Fact, Field, KnowledgeEngine\n",
    "\n",
    "# Add parent directory to path to access modules\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "print(\"All components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae2469",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733c4315",
   "metadata": {},
   "source": [
    "## 2. Main Engine Class\n",
    "\n",
    "This class inherits from all the enignes defined for each topic, and also a conflic resolution capability to avoid contradictory strategies being fired at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc51350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1CompleteStrategyEngine(F1DegradationRules, F1LapTimeRules, F1RadioRules, F1GapRules):\n",
    "    \"\"\"\n",
    "    Unified strategy engine that integrates all rule systems:\n",
    "    - Tire degradation rules \n",
    "    - Lap time prediction rules\n",
    "    - Radio communication analysis rules\n",
    "    - Gap analysis rules\n",
    "    \n",
    "    This class inherits from all specialized rule engines to combine their rules\n",
    "    and adds conflict resolution capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the integrated engine\"\"\"\n",
    "        # Call the parent constructor\n",
    "        super().__init__()\n",
    "        # Track which rule systems have fired rules\n",
    "        self.active_systems = {\n",
    "            'degradation': False,\n",
    "            'lap_time': False,\n",
    "            'radio': False,\n",
    "            'gap': False\n",
    "        }\n",
    "    \n",
    "    def get_recommendations(self):\n",
    "        \"\"\"\n",
    "        Get all recommendations from the rule engine with enhanced conflict resolution.\n",
    "        \n",
    "        Returns:\n",
    "            list: Sorted list of recommendations with conflicts resolved\n",
    "        \"\"\"\n",
    "        # Get the base recommendations from parent method\n",
    "        all_recommendations = super().get_recommendations()\n",
    "        \n",
    "        # If we have very few recommendations, no need for complex conflict resolution\n",
    "        if len(all_recommendations) <= 2:\n",
    "            return all_recommendations\n",
    "        \n",
    "        # Group recommendations by driver\n",
    "        driver_recommendations = {}\n",
    "        for rec in all_recommendations:\n",
    "            driver = rec.get('DriverNumber', 0)  # Default to 0 if driver is not specified\n",
    "            if driver not in driver_recommendations:\n",
    "                driver_recommendations[driver] = []\n",
    "            driver_recommendations[driver].append(rec)\n",
    "        \n",
    "        # Process each driver's recommendations for conflicts\n",
    "        resolved_recommendations = []\n",
    "        for driver, recs in driver_recommendations.items():\n",
    "            # Only need conflict resolution if multiple recommendations\n",
    "            if len(recs) > 1:\n",
    "                resolved = self._resolve_conflicts(recs)\n",
    "                resolved_recommendations.extend(resolved)\n",
    "            else:\n",
    "                # Single recommendation, no conflicts to resolve\n",
    "                resolved_recommendations.extend(recs)\n",
    "        \n",
    "        # Sort by priority and confidence\n",
    "        return sorted(\n",
    "            resolved_recommendations,\n",
    "            key=lambda x: (x.get('priority', 0), x.get('confidence', 0)),\n",
    "            reverse=True\n",
    "        )\n",
    "    \n",
    "    def _resolve_conflicts(self, recommendations):\n",
    "        \"\"\"\n",
    "        Resolve conflicts between recommendations for the same driver.\n",
    "        \n",
    "        This method looks for contradictory recommendations and resolves them\n",
    "        based on priority, confidence, and the nature of the conflict.\n",
    "        \n",
    "        Args:\n",
    "            recommendations: List of recommendations for a single driver\n",
    "            \n",
    "        Returns:\n",
    "            list: Resolved list of recommendations\n",
    "        \"\"\"\n",
    "        # Group recommendations by action type\n",
    "        action_groups = {}\n",
    "        for rec in recommendations:\n",
    "            action = rec['action']\n",
    "            if action not in action_groups:\n",
    "                action_groups[action] = []\n",
    "            action_groups[action].append(rec)\n",
    "        \n",
    "        # Define conflicting action pairs\n",
    "        conflicting_pairs = [\n",
    "            # Can't extend stint and pit at the same time\n",
    "            ('extend_stint', 'pit_stop'),\n",
    "            ('extend_stint', 'prioritize_pit'),\n",
    "            ('extend_stint', 'defensive_pit'),\n",
    "            ('extend_stint', 'consider_pit'),\n",
    "            \n",
    "            # No need for preparation if immediate pit is recommended\n",
    "            ('prepare_pit', 'pit_stop'),\n",
    "            ('prepare_pit', 'prioritize_pit'),\n",
    "            \n",
    "            # Can't do undercut and overcut at the same time\n",
    "            ('perform_undercut', 'perform_overcut')\n",
    "        ]\n",
    "        \n",
    "        # Check for each conflict pair\n",
    "        resolved = []\n",
    "        excluded_recommendations = set()\n",
    "        \n",
    "        for action1, action2 in conflicting_pairs:\n",
    "            if action1 in action_groups and action2 in action_groups:\n",
    "                # We have a conflict!\n",
    "                group1 = action_groups[action1]\n",
    "                group2 = action_groups[action2]\n",
    "                \n",
    "                # Get the highest priority/confidence recommendation from each group\n",
    "                best1 = max(group1, key=lambda x: (x.get('priority', 0), x.get('confidence', 0)))\n",
    "                best2 = max(group2, key=lambda x: (x.get('priority', 0), x.get('confidence', 0)))\n",
    "                \n",
    "                # Compare and keep only the better one\n",
    "                if (best1.get('priority', 0), best1.get('confidence', 0)) >= (best2.get('priority', 0), best2.get('confidence', 0)):\n",
    "                    # best1 wins, exclude all from group2\n",
    "                    excluded_recommendations.update(id(r) for r in group2)\n",
    "                else:\n",
    "                    # best2 wins, exclude all from group1\n",
    "                    excluded_recommendations.update(id(r) for r in group1)\n",
    "        \n",
    "        # Add non-excluded recommendations\n",
    "        for rec in recommendations:\n",
    "            if id(rec) not in excluded_recommendations:\n",
    "                resolved.append(rec)\n",
    "        \n",
    "        # Enhance the winning recommendations with context from conflicting ones\n",
    "        if len(resolved) < len(recommendations):\n",
    "            # We had conflicts and resolved them\n",
    "            for rec in resolved:\n",
    "                rec['explanation'] += \" (Selected as optimal strategy after resolving conflicts)\"\n",
    "        \n",
    "        return resolved\n",
    "    \n",
    "    def record_rule_fired(self, rule_name):\n",
    "        \"\"\"\n",
    "        Record which rule fired and track which rule system it belongs to.\n",
    "        \n",
    "        Args:\n",
    "            rule_name: Name of the rule that fired\n",
    "        \"\"\"\n",
    "        # Standard recording from parent class\n",
    "        super().record_rule_fired(rule_name)\n",
    "        \n",
    "        # Also track which system the rule belongs to\n",
    "        if rule_name.startswith(('high_degradation', 'stint_extension', 'early_degradation')):\n",
    "            self.active_systems['degradation'] = True\n",
    "        elif rule_name.startswith(('optimal_performance', 'performance_cliff', 'post_traffic')):\n",
    "            self.active_systems['lap_time'] = True\n",
    "        elif rule_name.startswith(('grip_issue', 'weather_information', 'incident_reaction')):\n",
    "            self.active_systems['radio'] = True\n",
    "        elif rule_name.startswith(('undercut_opportunity', 'defensive_pit', 'strategic_overcut')):\n",
    "            self.active_systems['gap'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7198dd",
   "metadata": {},
   "source": [
    "### 2.1 Testing class initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully created the integrated engine!\n",
      "✅ Engine reset successful!\n",
      "\n",
      "Method Resolution Order:\n",
      "  - F1CompleteStrategyEngine\n",
      "  - F1DegradationRules\n",
      "  - F1LapTimeRules\n",
      "  - F1RadioRules\n",
      "  - F1GapRules\n",
      "  - F1StrategyEngine\n",
      "  - KnowledgeEngine\n",
      "  - object\n",
      "\n",
      "Active rule systems: {'degradation': False, 'lap_time': False, 'radio': False, 'gap': False}\n"
     ]
    }
   ],
   "source": [
    "# Test that our integrated engine initializes correctly\n",
    "try:\n",
    "    engine = F1CompleteStrategyEngine()\n",
    "    print(\"✅ Successfully created the integrated engine!\")\n",
    "    \n",
    "    # Use reset to initialize the engine's working memory\n",
    "    engine.reset()\n",
    "    print(\"✅ Engine reset successful!\")\n",
    "    \n",
    "    # Check MRO (Method Resolution Order) to confirm correct inheritance\n",
    "    print(\"\\nMethod Resolution Order:\")\n",
    "    for cls in F1CompleteStrategyEngine.__mro__:\n",
    "        print(f\"  - {cls.__name__}\")\n",
    "    \n",
    "    # Print info about active systems\n",
    "    print(\"\\nActive rule systems:\", engine.active_systems)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c6a525",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad66c7a",
   "metadata": {},
   "source": [
    "## 3. Transformation Function for integrating all the facts\n",
    "\n",
    "### `prepare_integrated_facts`: Transforming data into engine facts\n",
    "\n",
    "This function serves as the crucial bridge that converts various data types into facts that our rule engine can process. It handles the complex task of integrating diverse sources of information into a coherent set of facts.\n",
    "\n",
    "### Inputs:\n",
    "- **Multiple data sources** (lap times, tire data, gaps, radio communications)\n",
    "- **Contextual information** (driver number, current lap)\n",
    "\n",
    "### Processing by data type:\n",
    "\n",
    "1. **Tire degradation data**:\n",
    "   - Transforms predictions into `DegradationFact` objects\n",
    "   - Extracts metrics like degradation rate and future predictions\n",
    "   - Captures basic telemetry information (tire age, compound)\n",
    "\n",
    "2. **Lap time data**:\n",
    "   - Processes lap time predictions by creating or updating `TelemetryFact`\n",
    "   - **Key intelligence**: If telemetry information already exists, it only updates relevant fields without overwriting other data\n",
    "\n",
    "3. **Gap data between cars**:\n",
    "   - Ensures consistency calculations exist (how many laps a gap has remained similar)\n",
    "   - Creates `GapFact` objects with information about cars ahead/behind and trends\n",
    "\n",
    "4. **Radio analysis**:\n",
    "   - Processes radio messages in JSON format\n",
    "   - Creates `RadioFact` objects with sentiment analysis, intentions and detected entities\n",
    "\n",
    "5. **Race status**:\n",
    "   - Automatically calculates race phase (start/middle/end)\n",
    "   - Creates a `RaceStatusFact` with this contextual information\n",
    "\n",
    "### Output:\n",
    "A structured dictionary with all facts organized by category, ready to be declared in the rule engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae99954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_integrated_facts(\n",
    "    lap_data=None,            # Lap time data\n",
    "    tire_predictions=None,    # Tire degradation predictions\n",
    "    gap_data=None,            # Gaps between cars\n",
    "    radio_analysis=None,      # Radio communication analysis\n",
    "    driver_number=None,       # Specific driver number\n",
    "    current_lap=None,         # Current lap number\n",
    "    total_laps=None           # Total race laps\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare a complete set of facts for the integrated strategy engine.\n",
    "    \n",
    "    This function takes various data inputs and transforms them into facts\n",
    "    that can be used by our rule engine. It handles cases where some data\n",
    "    might not be available.\n",
    "    \n",
    "    Args:\n",
    "        lap_data: DataFrame with lap time data\n",
    "        tire_predictions: DataFrame with tire degradation predictions\n",
    "        gap_data: DataFrame with gap data\n",
    "        radio_analysis: JSON or dict with radio analysis\n",
    "        driver_number: Specific driver number to focus on\n",
    "        current_lap: Current lap number\n",
    "        total_laps: Total race laps\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of facts categorized by type\n",
    "    \"\"\"\n",
    "    facts = {}\n",
    "    \n",
    "    print(f\"Preparing facts for driver {driver_number}, lap {current_lap}\")\n",
    "    \n",
    "    # 1. Process tire degradation data if available\n",
    "    if tire_predictions is not None and driver_number is not None:\n",
    "        try:\n",
    "            tire_facts = transform_tire_predictions(tire_predictions, driver_number)\n",
    "            if tire_facts:\n",
    "                facts['degradation'] = tire_facts.get('degradation')\n",
    "                # Only add telemetry if not already present\n",
    "                if 'telemetry' not in facts:\n",
    "                    facts['telemetry'] = tire_facts.get('telemetry')\n",
    "                print(f\"✅ Tire degradation facts prepared\")\n",
    "            else:\n",
    "                print(f\"⚠️ No tire facts generated for driver {driver_number}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing tire data: {str(e)}\")\n",
    "    \n",
    "    # 2. Process lap time data if available\n",
    "    if lap_data is not None and driver_number is not None:\n",
    "        try:\n",
    "            lap_facts = transform_lap_time_predictions(lap_data, driver_number)\n",
    "            if lap_facts:\n",
    "                # Merge with existing telemetry if present, otherwise create new\n",
    "                if 'telemetry' in facts and facts['telemetry'] is not None:\n",
    "                    # Update existing telemetry with lap time info\n",
    "                    if 'lap_time' in lap_facts['telemetry']:\n",
    "                        facts['telemetry']['lap_time'] = lap_facts['telemetry']['lap_time']\n",
    "                    if 'predicted_lap_time' in lap_facts['telemetry']:\n",
    "                        facts['telemetry']['predicted_lap_time'] = lap_facts['telemetry']['predicted_lap_time']\n",
    "                else:\n",
    "                    facts['telemetry'] = lap_facts.get('telemetry')\n",
    "                print(f\"✅ Lap time facts prepared\")\n",
    "            else:\n",
    "                print(f\"⚠️ No lap time facts generated for driver {driver_number}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing lap time data: {str(e)}\")\n",
    "    \n",
    "    # 3. Process gap data if available\n",
    "    if gap_data is not None and driver_number is not None:\n",
    "        try:\n",
    "            # First ensure gap data has consistency calculations\n",
    "            if 'consistent_gap_ahead_laps' not in gap_data.columns:\n",
    "                gap_data = calculate_gap_consistency(gap_data)\n",
    "            \n",
    "            # Transform the gap data into facts\n",
    "            gap_fact = transform_gap_data_with_consistency(gap_data, driver_number)\n",
    "            if gap_fact:\n",
    "                facts['gap'] = gap_fact\n",
    "                print(f\"✅ Gap facts prepared\")\n",
    "            else:\n",
    "                print(f\"⚠️ No gap facts generated for driver {driver_number}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing gap data: {str(e)}\")\n",
    "    \n",
    "    # 4. Process radio analysis if available\n",
    "    if radio_analysis is not None:\n",
    "        try:\n",
    "            # If radio_analysis is a path to a JSON file\n",
    "            if isinstance(radio_analysis, str) and radio_analysis.endswith('.json'):\n",
    "                radio_fact = transform_radio_analysis(radio_analysis)\n",
    "            # If it's already a parsed dictionary\n",
    "            elif isinstance(radio_analysis, dict):\n",
    "                # Create a temporary JSON file\n",
    "                import tempfile\n",
    "                import json\n",
    "                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:\n",
    "                    json.dump(radio_analysis, tmp)\n",
    "                    tmp_path = tmp.name\n",
    "                radio_fact = transform_radio_analysis(tmp_path)\n",
    "                # Clean up temp file\n",
    "                try:\n",
    "                    os.remove(tmp_path)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            if radio_fact:\n",
    "                facts['radio'] = radio_fact\n",
    "                print(f\"✅ Radio analysis facts prepared\")\n",
    "            else:\n",
    "                print(f\"⚠️ No radio facts generated\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing radio data: {str(e)}\")\n",
    "    \n",
    "    # 5. Create race status fact if lap info is available\n",
    "    if current_lap is not None and total_laps is not None:\n",
    "        try:\n",
    "            from utils.N01_agent_setup import calculate_race_phase\n",
    "            race_phase = calculate_race_phase(current_lap, total_laps)\n",
    "            facts['race_status'] = RaceStatusFact(\n",
    "                lap=int(current_lap),\n",
    "                total_laps=int(total_laps),\n",
    "                race_phase=race_phase,\n",
    "                track_status=\"clear\"  # Default to clear if no info\n",
    "            )\n",
    "            print(f\"✅ Race status fact prepared (lap {current_lap}, phase: {race_phase})\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating race status fact: {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    fact_types = [k for k, v in facts.items() if v is not None]\n",
    "    print(f\"Prepared {len(fact_types)} fact types: {fact_types}\")\n",
    "    \n",
    "    return facts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750f368",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0ba82e",
   "metadata": {},
   "source": [
    "## 4. Load and prepare main function\n",
    "### `load_all_race_data`: Loading and preparing data from sources\n",
    "\n",
    "This function handles the entire initial process of obtaining and preparing data before transformation:\n",
    "\n",
    "### Inputs:\n",
    "- **Paths to different sources** of data (CSV files, models, etc.)\n",
    "\n",
    "### Process:\n",
    "\n",
    "1. **Loading lap time data**:\n",
    "   - Reads the main CSV with lap information\n",
    "   - **Advanced functionality**: If model path is provided, automatically generates:\n",
    "     - Tire degradation predictions\n",
    "     - Future lap time predictions\n",
    "\n",
    "2. **Loading gap data**:\n",
    "   - Reads the CSV with analysis of gaps between cars\n",
    "   - Automates the calculation of consistency metrics (how long a gap remains stable)\n",
    "\n",
    "3. **Loading radio analysis**:\n",
    "   - Handles both directories (multiple messages) and individual files\n",
    "   - Reads and structures NLP analyses of communications\n",
    "\n",
    "### Special features:\n",
    "- **Robust error handling**: Each component has its own try-except block\n",
    "- **Automatic prediction generation**: Uses existing ML models to enrich basic data\n",
    "- **Detailed feedback**: Provides clear information about which data was loaded and which failed\n",
    "\n",
    "### Output:\n",
    "A complete dictionary with all loaded and preprocessed data, ready for transformation into facts.\n",
    "\n",
    "The combination of these two functions fully automates the flow from raw data to inference-ready facts, allowing the integrated engine to generate recommendations based on multiple sources of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4616298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_race_data(\n",
    "    lap_data_path=None,\n",
    "    gap_data_path=None,\n",
    "    radio_path=None,\n",
    "    models_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Load and prepare all race data from various sources.\n",
    "    \n",
    "    This function handles loading various data types needed for\n",
    "    strategy analysis from files or other sources.\n",
    "    \n",
    "    Args:\n",
    "        lap_data_path: Path to CSV with lap and telemetry data\n",
    "        gap_data_path: Path to CSV with processed gap data\n",
    "        radio_path: Path to directory with radio analysis JSONs\n",
    "        models_path: Path to prediction models directory\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing all loaded data\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    # 1. Load lap time data if available\n",
    "    if lap_data_path and os.path.exists(lap_data_path):\n",
    "        try:\n",
    "            lap_data = pd.read_csv(lap_data_path)\n",
    "            data['lap_data'] = lap_data\n",
    "            print(f\"✅ Loaded lap data: {len(lap_data)} rows\")\n",
    "            \n",
    "            # If models path is provided, generate tire predictions\n",
    "            if models_path and os.path.exists(models_path):\n",
    "                try:\n",
    "                    tire_predictions = load_tire_predictions(lap_data, models_path)\n",
    "                    if tire_predictions is not None:\n",
    "                        data['tire_predictions'] = tire_predictions\n",
    "                        print(f\"✅ Generated tire predictions: {len(tire_predictions)} rows\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error generating tire predictions: {str(e)}\")\n",
    "            \n",
    "            # Also try to load lap time predictions\n",
    "            try:\n",
    "                lap_predictions = load_lap_time_predictions(lap_data, models_path)\n",
    "                if lap_predictions is not None:\n",
    "                    data['lap_predictions'] = lap_predictions\n",
    "                    print(f\"✅ Generated lap time predictions: {len(lap_predictions)} rows\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error generating lap time predictions: {str(e)}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading lap data: {str(e)}\")\n",
    "    \n",
    "    # 2. Load gap data if available\n",
    "    if gap_data_path and os.path.exists(gap_data_path):\n",
    "        try:\n",
    "            gap_data = pd.read_csv(gap_data_path)\n",
    "            # Ensure consistency metrics are calculated\n",
    "            if 'consistent_gap_ahead_laps' not in gap_data.columns:\n",
    "                gap_data = calculate_gap_consistency(gap_data)\n",
    "            data['gap_data'] = gap_data\n",
    "            print(f\"✅ Loaded gap data: {len(gap_data)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading gap data: {str(e)}\")\n",
    "    \n",
    "    # 3. Load radio analysis if available\n",
    "    if radio_path and os.path.exists(radio_path):\n",
    "        # Check if it's a directory or a single file\n",
    "        if os.path.isdir(radio_path):\n",
    "            radio_files = [f for f in os.listdir(radio_path) if f.endswith('.json')]\n",
    "            data['radio_analyses'] = []\n",
    "            for file in radio_files:\n",
    "                file_path = os.path.join(radio_path, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        radio_analysis = json.load(f)\n",
    "                    data['radio_analyses'].append({\n",
    "                        'path': file_path,\n",
    "                        'data': radio_analysis\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error loading radio file {file}: {str(e)}\")\n",
    "            print(f\"✅ Loaded {len(data['radio_analyses'])} radio analyses\")\n",
    "        elif radio_path.endswith('.json'):\n",
    "            try:\n",
    "                with open(radio_path, 'r') as f:\n",
    "                    radio_analysis = json.load(f)\n",
    "                data['radio_analyses'] = [{\n",
    "                    'path': radio_path,\n",
    "                    'data': radio_analysis\n",
    "                }]\n",
    "                print(f\"✅ Loaded single radio analysis\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error loading radio file: {str(e)}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nLoaded data summary:\")\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"- {key}: {len(value)} items\")\n",
    "        elif isinstance(value, pd.DataFrame):\n",
    "            print(f\"- {key}: {len(value)} rows, {len(value.columns)} columns\")\n",
    "        else:\n",
    "            print(f\"- {key}: {type(value)}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfadc13f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35f22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.N03_lap_time_rules import test_with_realistic_approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3e30f",
   "metadata": {},
   "source": [
    "## 5. Complete end-to-end pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bbda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_integrated_strategy_recommendations(\n",
    "    race_data,\n",
    "    driver_numbers=None,\n",
    "    specific_lap=None,\n",
    "    models_path=None,\n",
    "    enable_radio=True,\n",
    "    enable_gaps=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete end-to-end pipeline for generating strategic recommendations using\n",
    "    the integrated rule engine with all data sources.\n",
    "    \n",
    "    This function handles the entire process:\n",
    "    1. Preparing facts from race data\n",
    "    2. Initializing the integrated engine\n",
    "    3. Generating recommendations for each driver\n",
    "    \n",
    "    Args:\n",
    "        race_data: Dictionary with all race data (lap_data, tire_predictions, gap_data, radio_analyses)\n",
    "        driver_numbers: List of driver numbers to analyze (None = analyze all)\n",
    "        specific_lap: Specific lap to analyze (None = use latest lap per driver)\n",
    "        models_path: Path to prediction models directory\n",
    "        enable_radio: Whether to use radio communication analysis\n",
    "        enable_gaps: Whether to use gap analysis\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all recommendations from all analyzed drivers\n",
    "    \"\"\"\n",
    "    # Track execution time\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting integrated strategy analysis at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    # Extract components from race_data\n",
    "    lap_data = race_data.get('lap_data')\n",
    "    tire_predictions = race_data.get('tire_predictions')\n",
    "    gap_data = race_data.get('gap_data')\n",
    "    radio_analyses = race_data.get('radio_analyses', [])\n",
    "     # Check and fix missing LapNumber column\n",
    "    if 'LapNumber' not in lap_data.columns:\n",
    "        print(\"Creating LapNumber column based on Stint and TyreAge...\")\n",
    "        \n",
    "        # Check if we have the necessary columns\n",
    "        if 'Stint' in lap_data.columns and 'TyreAge' in lap_data.columns:\n",
    "            # Calculate the maximum TyreAge for each stint to get stint lengths\n",
    "            max_age_by_stint = lap_data.groupby(['DriverNumber', 'Stint'])['TyreAge'].max().reset_index()\n",
    "            max_age_by_stint = max_age_by_stint.rename(columns={'TyreAge': 'StintLength'})\n",
    "            \n",
    "            # Create cumulative stint lengths for each driver\n",
    "            stint_lengths = {}\n",
    "            for driver in lap_data['DriverNumber'].unique():\n",
    "                driver_stints = max_age_by_stint[max_age_by_stint['DriverNumber'] == driver]\n",
    "                \n",
    "                # Calculate cumulative lengths\n",
    "                cumulative_lengths = [0]  # Start with 0 for the first stint\n",
    "                for i in range(len(driver_stints) - 1):\n",
    "                    cumulative_lengths.append(\n",
    "                        cumulative_lengths[-1] + driver_stints.iloc[i]['StintLength']\n",
    "                    )\n",
    "                \n",
    "                # Store in dictionary\n",
    "                stint_lengths[driver] = {\n",
    "                    stint: length for stint, length in zip(\n",
    "                        driver_stints['Stint'], cumulative_lengths\n",
    "                    )\n",
    "                }\n",
    "            \n",
    "            # Function to calculate race lap\n",
    "            def calculate_lap_number(row):\n",
    "                driver = row['DriverNumber']\n",
    "                stint = row['Stint']\n",
    "                tyre_age = row['TyreAge']\n",
    "                \n",
    "                # Get the starting lap for this stint\n",
    "                start_lap = stint_lengths.get(driver, {}).get(stint, 0)\n",
    "                \n",
    "                # Add current TyreAge to get race lap\n",
    "                return start_lap + tyre_age\n",
    "            \n",
    "            # Apply function to calculate LapNumber\n",
    "            lap_data['LapNumber'] = lap_data.apply(calculate_lap_number, axis=1)\n",
    "        \n",
    "        elif 'TyreAge' in lap_data.columns:\n",
    "            # Simplified approach if we only have TyreAge\n",
    "            print(\"Using TyreAge as LapNumber (assuming single stint)\")\n",
    "            lap_data['LapNumber'] = lap_data['TyreAge']\n",
    "        \n",
    "        else:\n",
    "            # Fallback: create sequential numbers per driver\n",
    "            print(\"Creating sequential lap numbers per driver\")\n",
    "            lap_data['LapNumber'] = lap_data.groupby('DriverNumber').cumcount() + 1\n",
    "    # Ensure we have the basic required data\n",
    "    if lap_data is None:\n",
    "        raise ValueError(\"Lap data is required for strategy analysis\")\n",
    "    \n",
    "    # Get total race laps\n",
    "    total_laps = lap_data['LapNumber'].max() if 'LapNumber' in lap_data.columns else 50\n",
    "    print(f\"Total race laps detected: {total_laps}\")\n",
    "    \n",
    "    # Determine drivers to analyze\n",
    "    if driver_numbers is None:\n",
    "        driver_numbers = lap_data['DriverNumber'].unique()\n",
    "    \n",
    "    print(f\"Will analyze {len(driver_numbers)} drivers: {driver_numbers}\")\n",
    "    \n",
    "    # Initialize container for all recommendations\n",
    "    all_recommendations = []\n",
    "    \n",
    "    # Process each driver\n",
    "    for driver_number in driver_numbers:\n",
    "        driver_start_time = time.time()\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ANALYZING DRIVER {driver_number}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Filter lap data for this driver\n",
    "        driver_lap_data = lap_data[lap_data['DriverNumber'] == driver_number]\n",
    "        if driver_lap_data.empty:\n",
    "            print(f\"No lap data for driver {driver_number}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Determine which lap to analyze\n",
    "        if specific_lap is not None:\n",
    "            # Use the specified lap if available\n",
    "            lap_to_analyze = specific_lap\n",
    "            if lap_to_analyze not in driver_lap_data['LapNumber'].values:\n",
    "                print(f\"Specified lap {lap_to_analyze} not found for driver {driver_number}\")\n",
    "                closest_lap = driver_lap_data['LapNumber'].astype(int).values\n",
    "                closest_lap = closest_lap[np.abs(closest_lap - lap_to_analyze).argmin()]\n",
    "                print(f\"Using closest available lap: {closest_lap}\")\n",
    "                lap_to_analyze = closest_lap\n",
    "        else:\n",
    "            # Use the latest lap available\n",
    "            lap_to_analyze = driver_lap_data['LapNumber'].max()\n",
    "        \n",
    "        print(f\"Analyzing lap {lap_to_analyze} for driver {driver_number}\")\n",
    "        \n",
    "        # Find position for this driver at this lap\n",
    "        try:\n",
    "            driver_position = driver_lap_data[driver_lap_data['LapNumber'] == lap_to_analyze]['Position'].iloc[0]\n",
    "            print(f\"Driver position: P{int(driver_position)}\")\n",
    "        except:\n",
    "            driver_position = 0\n",
    "            print(\"Could not determine driver position\")\n",
    "        \n",
    "        # Get driver name if available\n",
    "        try:\n",
    "            if 'Driver' in driver_lap_data.columns:\n",
    "                driver_name = driver_lap_data['Driver'].iloc[0]\n",
    "            elif gap_data is not None and 'Driver' in gap_data.columns:\n",
    "                driver_name = gap_data[gap_data['DriverNumber'] == driver_number]['Driver'].iloc[0]\n",
    "            else:\n",
    "                driver_name = f\"Driver-{driver_number}\"\n",
    "            print(f\"Driver name: {driver_name}\")\n",
    "        except:\n",
    "            driver_name = f\"Driver-{driver_number}\"\n",
    "        \n",
    "        # Get team if available\n",
    "        try:\n",
    "            if 'Team' in driver_lap_data.columns:\n",
    "                team = driver_lap_data['Team'].iloc[0]\n",
    "            elif gap_data is not None and 'Team' in gap_data.columns:\n",
    "                team = gap_data[gap_data['DriverNumber'] == driver_number]['Team'].iloc[0]\n",
    "            else:\n",
    "                team = \"Unknown\"\n",
    "            print(f\"Team: {team}\")\n",
    "        except:\n",
    "            team = \"Unknown\"\n",
    "        \n",
    "        # Prepare filtered data for the specific lap we're analyzing\n",
    "        lap_filtered_data = driver_lap_data[driver_lap_data['LapNumber'] == lap_to_analyze].copy()\n",
    "        \n",
    "        # For gaps, find the gap data for this lap\n",
    "        gap_filtered_data = None\n",
    "        if gap_data is not None and enable_gaps:\n",
    "            gap_filtered_data = gap_data[\n",
    "                (gap_data['DriverNumber'] == driver_number) & \n",
    "                (gap_data['LapNumber'] == lap_to_analyze)\n",
    "            ].copy()\n",
    "            if gap_filtered_data.empty:\n",
    "                print(f\"No gap data for driver {driver_number} at lap {lap_to_analyze}\")\n",
    "                gap_filtered_data = None\n",
    "        \n",
    "        # For radio, find the most recent radio message\n",
    "        radio_filtered = None\n",
    "        if radio_analyses and enable_radio:\n",
    "            # This is simplified - in reality, we would need to match radio timestamps\n",
    "            # with lap times to determine the most relevant radio message\n",
    "            radio_filtered = radio_analyses[0]['data'] if radio_analyses else None\n",
    "            if radio_filtered:\n",
    "                print(f\"Using radio message: '{radio_filtered.get('message', 'Unknown message')}'\")\n",
    "        \n",
    "        # Prepare all facts for the engine\n",
    "        facts = prepare_integrated_facts(\n",
    "            lap_data=lap_filtered_data,\n",
    "            tire_predictions=tire_predictions,\n",
    "            gap_data=gap_filtered_data,\n",
    "            radio_analysis=radio_filtered,\n",
    "            driver_number=driver_number,\n",
    "            current_lap=lap_to_analyze,\n",
    "            total_laps=total_laps\n",
    "        )\n",
    "        \n",
    "        # Check if we have enough facts to run the engine\n",
    "        if len(facts) <= 1:  # Only race_status is not enough\n",
    "            print(f\"Insufficient facts for driver {driver_number}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Initialize the integrated engine\n",
    "        engine = F1CompleteStrategyEngine()\n",
    "        engine.reset()\n",
    "        \n",
    "        # Declare all facts to the engine\n",
    "        print(\"\\nDeclaring facts to the engine...\")\n",
    "        for fact_type, fact in facts.items():\n",
    "             if fact is not None:\n",
    "                print(f\"Declaring {fact_type}: {fact}\")\n",
    "                engine.declare(fact)\n",
    "                print(f\"  ✓ Declared {fact_type} fact\")\n",
    "        \n",
    "        # Run the engine\n",
    "        print(\"\\nRunning integrated strategy engine...\")\n",
    "        engine.run()\n",
    "        \n",
    "        # Get recommendations\n",
    "        recommendations = engine.get_recommendations()\n",
    "        print(f\"\\nGenerated {len(recommendations)} recommendations\")\n",
    "        \n",
    "        # Add driver-specific metadata to recommendations\n",
    "        for rec in recommendations:\n",
    "            rec['DriverNumber'] = driver_number\n",
    "            rec['DriverName'] = driver_name\n",
    "            rec['LapNumber'] = lap_to_analyze\n",
    "            rec['Position'] = driver_position\n",
    "            rec['Team'] = team\n",
    "            # Add which systems were active\n",
    "            for system, active in engine.active_systems.items():\n",
    "                rec[f'System_{system}'] = active\n",
    "        \n",
    "        # Add to overall results\n",
    "        all_recommendations.extend(recommendations)\n",
    "        \n",
    "        # Print summary of which rule systems were active\n",
    "        print(\"\\nActive rule systems:\")\n",
    "        for system, active in engine.active_systems.items():\n",
    "            status = \"✓ ACTIVE\" if active else \"✗ INACTIVE\"\n",
    "            print(f\"  - {system.upper()}: {status}\")\n",
    "        \n",
    "        # Calculate and print execution time for this driver\n",
    "        driver_time = time.time() - driver_start_time\n",
    "        print(f\"\\nAnalysis for driver {driver_number} completed in {driver_time:.2f} seconds\")\n",
    "    \n",
    "    # Process results\n",
    "    if all_recommendations:\n",
    "        # Convert to DataFrame\n",
    "        results_df = pd.DataFrame(all_recommendations)\n",
    "        \n",
    "        # Sort by priority and confidence\n",
    "        results_df = results_df.sort_values(\n",
    "            ['DriverNumber', 'priority', 'confidence'],\n",
    "            ascending=[True, False, False]\n",
    "        )\n",
    "        \n",
    "        # Calculate execution time\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nStrategy analysis completed in {total_time:.2f} seconds\")\n",
    "        print(f\"Generated {len(results_df)} recommendations for {len(driver_numbers)} drivers\")\n",
    "        \n",
    "        return results_df\n",
    "    else:\n",
    "        print(\"No recommendations were generated\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741c6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_strategy_analysis(\n",
    "    lap_data_path,\n",
    "    gap_data_path=None,\n",
    "    radio_path=None,\n",
    "    models_path=None,\n",
    "    driver_numbers=None,\n",
    "    specific_lap=None,\n",
    "    save_results=True,\n",
    "    output_path='strategy_recommendations.csv'\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete one-step function to load data and generate strategy recommendations.\n",
    "    \n",
    "    This is the main function that users would call directly to perform a full\n",
    "    strategy analysis from data files.\n",
    "    \n",
    "    Args:\n",
    "        lap_data_path: Path to CSV with lap and telemetry data\n",
    "        gap_data_path: Path to CSV with processed gap data\n",
    "        radio_path: Path to directory or file with radio analysis\n",
    "        models_path: Path to prediction models directory\n",
    "        driver_numbers: List of driver numbers to analyze (None = all drivers)\n",
    "        specific_lap: Specific lap to analyze (None = latest lap)\n",
    "        save_results: Whether to save results to CSV\n",
    "        output_path: Path to save results CSV\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all recommendations\n",
    "    \"\"\"\n",
    "    print(f\"Starting complete strategy analysis at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Step 1: Load all race data\n",
    "    print(\"\\n1. LOADING RACE DATA\")\n",
    "    print(\"----------------------\")\n",
    "    race_data = load_all_race_data(\n",
    "        lap_data_path=lap_data_path,\n",
    "        gap_data_path=gap_data_path,\n",
    "        radio_path=radio_path,\n",
    "        models_path=models_path\n",
    "    )\n",
    "    \n",
    "    # Step 2: Generate strategy recommendations\n",
    "    print(\"\\n2. GENERATING STRATEGY RECOMMENDATIONS\")\n",
    "    print(\"--------------------------------------\")\n",
    "    recommendations = generate_integrated_strategy_recommendations(\n",
    "        race_data=race_data,\n",
    "        driver_numbers=driver_numbers,\n",
    "        specific_lap=specific_lap,\n",
    "        models_path=models_path,\n",
    "        enable_radio=(radio_path is not None),\n",
    "        enable_gaps=(gap_data_path is not None)\n",
    "    )\n",
    "    \n",
    "    # Step 3: Save results if requested\n",
    "    if save_results and not recommendations.empty:\n",
    "        print(\"\\n3. SAVING RESULTS\")\n",
    "        print(\"----------------\")\n",
    "        try:\n",
    "            recommendations.to_csv(output_path, index=False)\n",
    "            print(f\"Results saved to: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {str(e)}\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ae6d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb198ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing complete strategy pipeline...\n",
      "Starting complete strategy analysis at 2025-04-18 18:00:59\n",
      "\n",
      "1. LOADING RACE DATA\n",
      "----------------------\n",
      "✅ Loaded lap data: 1180 rows\n",
      "Data loaded and validated: 1180 rows, 15 columns\n",
      "Processing Medium tires (ID: 2)...\n",
      "Processing Hard tires (ID: 3)...\n",
      "  No laps with new tires for Hard, using TyreAge=2.0 as baseline\n",
      "Processing Soft tires (ID: 1)...\n",
      "  No laps with new tires for Soft, using TyreAge=2.0 as baseline\n",
      "Degradation metrics successfully calculated\n",
      "Processed data format: 16 features\n",
      "Created 339 sequences of 5 laps each\n",
      "Sequences by compound: {1: 158, 2: 147, 3: 34}\n",
      "Using device: cuda\n",
      "Global model loaded from: ../../outputs/week5/models/tire_degradation_tcn.pth\n",
      "Specialized model for compound 1 loaded\n",
      "Specialized model for compound 2 loaded\n",
      "Specialized model for compound 3 loaded\n",
      "Models loaded: 1 global model and 3 specialized models\n",
      "Prepared tensor for model: shape=torch.Size([339, 5, 16])\n",
      "Generated ensemble predictions for 339 sequences\n",
      "Formatted results: 1017 predictions for 20 drivers\n",
      "✅ Generated tire predictions: 1017 rows\n",
      "Error loading model: [Errno 13] Permission denied: '../../outputs/week5/models/'\n",
      "Failed to load model. Aborting prediction.\n",
      "✅ Loaded single radio analysis\n",
      "\n",
      "Loaded data summary:\n",
      "- lap_data: 1180 rows, 15 columns\n",
      "- tire_predictions: 1017 rows, 9 columns\n",
      "- radio_analyses: 1 items\n",
      "\n",
      "2. GENERATING STRATEGY RECOMMENDATIONS\n",
      "--------------------------------------\n",
      "Starting integrated strategy analysis at 18:01:00\n",
      "Creating LapNumber column based on Stint and TyreAge...\n",
      "Total race laps detected: 90.0\n",
      "Will analyze 20 drivers: [ 1 44 63 11 55 18 14 31 24 10 16 22 81 21 27 23  4 20 77  2]\n",
      "\n",
      "==================================================\n",
      "ANALYZING DRIVER 1\n",
      "==================================================\n",
      "Analyzing lap 20 for driver 1\n",
      "Driver position: P1\n",
      "Driver name: Driver-1\n",
      "Team: Unknown\n",
      "Using radio message: 'Warning: rain starting at turn 4, track is getting wet'\n",
      "Preparing facts for driver 1, lap 20\n",
      "Using first predicted rate as current degradation: 1.4210000038146973\n",
      "✅ Tire degradation facts prepared\n",
      "❌ Error processing lap time data: 'PredictedLapTime'\n",
      "✅ Radio analysis facts prepared\n",
      "✅ Race status fact prepared (lap 20, phase: start)\n",
      "Prepared 4 fact types: ['degradation', 'telemetry', 'radio', 'race_status']\n",
      "\n",
      "Declaring facts to the engine...\n",
      "Declaring degradation: <Undeclared Fact> DegradationFact(degradation_rate=1.4210000038146973, predicted_rates=frozenlist([1.4210000038146973, -1.7300000190734863, 10.071000099182129]))\n",
      "  ✓ Declared degradation fact\n",
      "Declaring telemetry: <Undeclared Fact> TelemetryFact(tire_age=26, compound_id=2, driver_number=1, position=0, lap_time=85.218)\n",
      "  ✓ Declared telemetry fact\n",
      "Declaring radio: <Undeclared Fact> RadioFact(sentiment='neutral', intent='INFORMATION', entities=<frozendict {'WEATHER': frozenlist(['rain starting',]), 'TRACK_CONDITION': frozenlist(['track is getting wet',])}>, timestamp=1744999260.22133)\n",
      "  ✓ Declared radio fact\n",
      "Declaring race_status: <Undeclared Fact> RaceStatusFact(lap=20, total_laps=90, race_phase='start', track_status='clear')\n",
      "  ✓ Declared race_status fact\n",
      "\n",
      "Running integrated strategy engine...\n",
      "Error during execution: can only concatenate tuple (not \"list\") to tuple\n"
     ]
    }
   ],
   "source": [
    "# Test the complete pipeline with available data\n",
    "try:\n",
    "    # Define paths to your data files\n",
    "    # Adjust these paths to match your actual file locations\n",
    "    lap_data_path = '../../outputs/week3/lap_prediction_data.csv'\n",
    "    gap_data_path = '../../outputs/week5/gaps_spain_2023_data.csv'  # If available\n",
    "    radio_path = \"../../outputs/week4/json/radio_analysis_20250417_191807.json\"\n",
    "    models_path = '../../outputs/week5/models/'  # Path to prediction models\n",
    "    \n",
    "    # Optional parameters\n",
    "    driver_numbers = None  # Example: Analyze only Verstappen (#1) and Hamilton (#44)\n",
    "    specific_lap = 20  # Analyze a specific lap, or None for latest\n",
    "    \n",
    "    # Run the complete analysis\n",
    "    print(f\"Testing complete strategy pipeline...\")\n",
    "    results = run_complete_strategy_analysis(\n",
    "        lap_data_path=lap_data_path,\n",
    "        gap_data_path=gap_data_path,\n",
    "        radio_path=radio_path,\n",
    "        models_path=models_path,\n",
    "        driver_numbers=driver_numbers,\n",
    "        specific_lap=specific_lap,\n",
    "        save_results=True,\n",
    "        output_path='../../outputs/integrated_recommendations.csv'\n",
    "    )\n",
    "    \n",
    "    # Display results summary\n",
    "    if not results.empty:\n",
    "        print(\"\\nResults summary:\")\n",
    "        print(f\"- Total recommendations: {len(results)}\")\n",
    "        print(f\"- Drivers analyzed: {results['DriverNumber'].nunique()}\")\n",
    "        print(f\"- Recommendation types: {results['action'].unique()}\")\n",
    "        \n",
    "        # Show a sample of the recommendations\n",
    "        print(\"\\nSample recommendations:\")\n",
    "        display(results.head())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {str(e)}\")\n",
    "    print(\"Please adjust the file paths to match your actual file locations\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
