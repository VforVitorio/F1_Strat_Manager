{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Message Understanding: Dual Model Approach\n",
    "\n",
    "**Advanced Text Understanding for F1 Strategy**\n",
    "\n",
    "For our F1 strategic decision system, we need to extract structured information from radio messages to feed our logic agent. Building on our successful sentiment analysis model, we'll implement a comprehensive approach to understand both the intent and specific entities in team radio communications.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Intent Classification with RoBERTa\n",
    "\n",
    "We'll fine-tune a RoBERTa model (similar to our sentiment analysis model) to classify radio messages into specific intent categories:\n",
    "\n",
    "- **Order:** Direct instructions to the driver (\"Box this lap\", \"Push now\")\n",
    "- **Information:** Factual updates about race conditions (\"Hamilton is 2 seconds behind\")\n",
    "- **Question:** Queries requiring driver input (\"How are the tyres feeling?\")\n",
    "- **Warning:** Alerts about potential issues (\"Watch your fuel consumption\")\n",
    "- **Strategy:** Long-term planning elements (\"We're looking at Plan B\")\n",
    "- **Problem**: messages that ensures actual problems (\"My left wing is broken\")\n",
    "\n",
    "This classification will help our logic agent understand the purpose of each communication and respond appropriately.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Custom NER with SpaCy for F1-Specific Entities\n",
    "\n",
    "We'll train a specialized SpaCy model to identify key racing entities in the text:\n",
    "\n",
    "- **DRIVER:** References to specific drivers\n",
    "- **TEAM:** Team names and references\n",
    "- **TYRES:** Tyre compounds and conditions (soft, medium, hard, intermediate, wet)\n",
    "- **LAPNUM:** References to specific laps\n",
    "- **TIME_GAP:** Time differences mentioned in seconds\n",
    "- **STRATEGY:** Strategy terms (undercut, overcut, Plan A/B)\n",
    "- **TRACK_STATUS:** Track conditions (DRS, safety car, VSC)\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Radio Understanding Pipeline\n",
    "\n",
    "By combining these new models with our existing sentiment analysis:\n",
    "\n",
    "$Radio Message â†’ [Sentiment Analysis] â†’ [Intent Classification] â†’ [Entity Extraction] â†’ Structured Data$\n",
    "\n",
    "\n",
    "The final output should be comprehensive structured data like:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"message\": \"Box this lap for softs, Hamilton is catching up\",\n",
    "  \"analysis\": {\n",
    "    \"sentiment\": \"neutral\",\n",
    "    \"intent\": \"order\",\n",
    "    \"entities\": {\n",
    "      \"action\": \"box\",\n",
    "      \"lap\": \"current\",\n",
    "      \"tyres\": \"soft\",\n",
    "      \"driver_ref\": \"Hamilton\",\n",
    "      \"situation\": \"catching up\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "````\n",
    "This rich, structured information will enable my logic agent to make sophisticated race strategy decisions based on radio communications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. But first, I need to relabel the data.\n",
    "\n",
    "My data is not labeled for making intention recognition. Therefore, the first thing I need to do is label again the data in a different csv for the intention categories.\n",
    "\n",
    "Therefore, my first approach will be the following:\n",
    "\n",
    "## Step 1: Define Intent Categories\n",
    "First, we need to establish clear definitions for each intent category:\n",
    "\n",
    "1. **ORDER**: Direct instructions requiring action from the driver\n",
    "\n",
    "    Examples: \"Box this lap\", \"Push now\", \"Stay out\"\n",
    "\n",
    "\n",
    "2. **INFORMATION**: Factual updates about race conditions\n",
    "\n",
    "    Examples: \"Hamilton is 2 seconds behind\", \"Lap time 1:34.5\", \"You're P4\"\n",
    "\n",
    "\n",
    "3. **QUESTION**: Queries requiring driver input\n",
    "\n",
    "    Examples: \"How are the tyres feeling?\", \"Do you want to pit this lap?\", \"Are you happy with the balance?\"\n",
    "\n",
    "\n",
    "4. **WARNING**: Alerts about potential issues or cautions\n",
    "\n",
    "    Examples: \"Watch your fuel consumption\", \"Yellow flag in sector 2\", \"VSC deployed\"\n",
    "\n",
    "\n",
    "5. **STRATEGY**: Long-term planning elements or discussions\n",
    "\n",
    "    Examples: \"We're looking at Plan B\", \"Target plus 5 on tyre management\", \"Consider an undercut\"\n",
    "\n",
    "6. **PROBLEM**: driver-reported issues:\n",
    "\n",
    "    Examples: \"Losing grip on the rear\", \"My tires are dead\".\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Manual Labeling Interface\n",
    "\n",
    "I will make with Jupyet widgets a simple interface that helps me label the data. For this task, IÂ´ll use `radio_filtered.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['driver', 'radio_message', 'sentiment']\n",
      "Total messages to label: 529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550b14a5852e49259974b7de1c386d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntText(value=0, description='Current:', layout=Layout(display='none')), Output(), HBox(childreâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets, Layout\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load the full radio messages dataset\n",
    "df = pd.read_csv('../../outputs/week4/radio_clean/radio_filtered.csv')\n",
    "\n",
    "# Check the columns to see which one contains the radio messages\n",
    "print(\"Columns in the dataset:\", df.columns.tolist())\n",
    "\n",
    "# Assuming there's a column containing the radio messages, we'll use that\n",
    "message_column = 'radio_message'  # Adjust this based on the actual column name\n",
    "\n",
    "# Use the entire dataset instead of a sample\n",
    "intent_df = pd.DataFrame({\n",
    "    'message': df[message_column].values,\n",
    "    'intent': [\"\"] * len(df)\n",
    "})\n",
    "\n",
    "# Reset the index to make sure we have 0-based sequential indices\n",
    "intent_df = intent_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Total messages to label: {len(intent_df)}\")\n",
    "\n",
    "# Define the intent categories including the PROBLEM category\n",
    "intent_categories = [\"ORDER\", \"INFORMATION\", \"QUESTION\", \"WARNING\", \"STRATEGY\", \"PROBLEM\"]\n",
    "\n",
    "# Create a stateful counter for tracking which message we're on\n",
    "current_index = widgets.IntText(value=0, description='Current:', layout=Layout(display='none'))\n",
    "\n",
    "# Output widget for displaying the labeling interface\n",
    "output = widgets.Output()\n",
    "\n",
    "################################ WARNING: ONLY UNCOMMENT FOR LABELING THE DATA ######################################\n",
    "# # Function to save the dataframe\n",
    "# def save_dataframe():\n",
    "#     # Only save rows that have been labeled\n",
    "#     labeled_df = intent_df[intent_df['intent'] != \"\"]\n",
    "#     labeled_df.to_csv('../../outputs/week4/radio_clean/intent_labeled_data.csv', index=False)\n",
    "#     with output:\n",
    "#         print(f\"Dataset saved! {len(labeled_df)} labeled messages.\")\n",
    "        \n",
    "#         if len(labeled_df) > 0:\n",
    "#             # Show distribution of intents\n",
    "#             plt.figure(figsize=(10, 6))\n",
    "#             sns.countplot(y='intent', data=labeled_df)\n",
    "#             plt.title('Distribution of Intent Categories')\n",
    "#             plt.tight_layout()\n",
    "#             plt.show()\n",
    "######################################################################################################################\n",
    "# Function to display the current message\n",
    "def display_current_message():\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        if current_index.value >= len(intent_df):\n",
    "            current_index.value = len(intent_df) - 1\n",
    "            \n",
    "        if current_index.value < 0:\n",
    "            current_index.value = 0\n",
    "            \n",
    "        idx = current_index.value\n",
    "        print(f\"Message {idx+1}/{len(intent_df)}:\")\n",
    "        print(f\"\\\"{intent_df.iloc[idx]['message']}\\\"\")\n",
    "        \n",
    "        # Show current label if any\n",
    "        current_intent = intent_df.iloc[idx]['intent']\n",
    "        if current_intent:\n",
    "            print(f\"\\nCurrent label: {current_intent}\")\n",
    "        \n",
    "        # Display intent category descriptions for reference\n",
    "        print(\"\\nIntent Categories:\")\n",
    "        print(\"ORDER: Direct instructions requiring action (Box this lap, Push now)\")\n",
    "        print(\"INFORMATION: Factual updates (Hamilton is 2 seconds behind)\")\n",
    "        print(\"QUESTION: Queries requiring driver input (How are the tyres feeling?)\")\n",
    "        print(\"WARNING: Alerts about external issues (Yellow flag in sector 2)\")\n",
    "        print(\"STRATEGY: Long-term planning elements (We're looking at Plan B)\")\n",
    "        print(\"PROBLEM: Driver-reported issues (Losing grip on the rear)\")\n",
    "        \n",
    "        # Count labeled messages\n",
    "        labeled_count = (intent_df['intent'] != \"\").sum()\n",
    "        print(f\"\\nProgress: {labeled_count}/{len(intent_df)} messages labeled ({labeled_count/len(intent_df)*100:.1f}%)\")\n",
    "\n",
    "# Function to handle intent button clicks\n",
    "def on_intent_button_clicked(b, intent=None):\n",
    "    idx = current_index.value\n",
    "    intent_df.at[idx, 'intent'] = intent\n",
    "    # Automatically move to next message after labeling\n",
    "    current_index.value += 1\n",
    "    display_current_message()\n",
    "\n",
    "# Navigation button handlers\n",
    "def on_prev_clicked(b):\n",
    "    current_index.value -= 1\n",
    "    display_current_message()\n",
    "    \n",
    "def on_next_clicked(b):\n",
    "    current_index.value += 1\n",
    "    display_current_message()\n",
    "\n",
    "# Create buttons for each intent category\n",
    "intent_buttons = []\n",
    "for intent in intent_categories:\n",
    "    button = widgets.Button(\n",
    "        description=intent,\n",
    "        button_style='', \n",
    "        layout=Layout(width='150px', height='40px')\n",
    "    )\n",
    "    \n",
    "    button.on_click(lambda b, intent=intent: on_intent_button_clicked(b, intent))\n",
    "    intent_buttons.append(button)\n",
    "\n",
    "# Create navigation buttons\n",
    "prev_button = widgets.Button(\n",
    "    description='Â« Previous',\n",
    "    button_style='info',\n",
    "    layout=Layout(width='120px', height='40px')\n",
    ")\n",
    "prev_button.on_click(on_prev_clicked)\n",
    "\n",
    "next_button = widgets.Button(\n",
    "    description='Next Â»',\n",
    "    button_style='info',\n",
    "    layout=Layout(width='120px', height='40px')\n",
    ")\n",
    "next_button.on_click(on_next_clicked)\n",
    "\n",
    "# Create save button\n",
    "save_button = widgets.Button(\n",
    "    description='ðŸ’¾ Save Progress',\n",
    "    button_style='success',\n",
    "    layout=Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "######################### WARNING: ONLY UNCOMMENT FOR SAVING NEW LABELED DATA ###############################\n",
    "# save_button.on_click(lambda b: save_dataframe())\n",
    "#############################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Create button rows\n",
    "intent_row1 = widgets.HBox(intent_buttons[:3], layout=Layout(justify_content='center'))\n",
    "intent_row2 = widgets.HBox(intent_buttons[3:], layout=Layout(justify_content='center'))\n",
    "nav_row = widgets.HBox([prev_button, save_button, next_button], layout=Layout(justify_content='center'))\n",
    "\n",
    "# Assemble the UI\n",
    "vbox = widgets.VBox([\n",
    "    current_index,\n",
    "    output,\n",
    "    intent_row1,\n",
    "    intent_row2,\n",
    "    nav_row\n",
    "])\n",
    "\n",
    "# Initialize the display\n",
    "display(vbox)\n",
    "display_current_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Training an intent classifier\n",
    "\n",
    "Next steps are:\n",
    "\n",
    "1. *Splitting `intent_labeled_data.csv` into train/validation/test sets*.\n",
    "\n",
    "2. *Tokenize the dataset, adjusting the maximum tokens*\n",
    "\n",
    "3. *Download a pre-trained RoBERTa model and apply fine-tuning*.\n",
    "\n",
    "4. Try some runs, see how the performance improves and save the best model.\n",
    "\n",
    "The workflow here is quite similar to the one of `N03_bert_sentiment.ipynb`, but now predicting 6 classes instead of only 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the dataset and applying mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (529, 2)\n",
      "\n",
      "First few rows:\n",
      "\\Intent distribution:\n",
      "intent\n",
      "INFORMATION    211\n",
      "PROBLEM        109\n",
      "ORDER          107\n",
      "STRATEGY        35\n",
      "WARNING         34\n",
      "QUESTION        33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../outputs/week4/radio_clean/intent_labeled_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "\n",
    "\n",
    "print(\"\\Intent distribution:\")\n",
    "print(df['intent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message       intent\n",
      "0  So don't forget Max, use your head please. Are...        ORDER\n",
      "1  Okay Max, we're expecting rain in about 9 or 1...     QUESTION\n",
      "2  You might find this lap that you meet a little...  INFORMATION\n",
      "3  Just another two or three minutes to get throu...  INFORMATION\n",
      "4   So settle into standard race management now Max.        ORDER\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numeric labels based on intent values\n",
    "intent_mapping = {\n",
    "    'INFORMATION': 0, \n",
    "    'PROBLEM': 1, \n",
    "    'ORDER': 2,\n",
    "    'STRATEGY': 3,\n",
    "    'WARNING': 4,\n",
    "    'QUESTION': 5,\n",
    "}\n",
    "\n",
    "\n",
    "df['label'] = df['intent'].map(intent_mapping)\n",
    "\n",
    "# Check if we need to handle any missing mappings\n",
    "if df['label'].isna().sum() > 0:\n",
    "    print(f\"\\nWarning: {df['label'].isna().sum()} rows couldn't be mapped. Unique values in 'intent':\")\n",
    "    print(df['intent'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Splitting the data\n",
    "\n",
    "`Same text as N03_bert_sentiment.ipynb`\n",
    "\n",
    "IÂ´ll follow the same splits techniques during the project, making a training, validation and test dataset. \n",
    "\n",
    "* *Train* will be 70% of the dataset.\n",
    "* *Validation*: will be 15% of the dataset.\n",
    "* *Test*: will be 15% of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading RoBERTa\n",
    "\n",
    "For this case, I will use **roberta-large**, a bigger and more powerful model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9dbdc926fd446998df8fd0f76c0e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\miniconda3\\envs\\f1_strat_manager\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\victo\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac88bef41cae425e8f13f13e51e6a172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae5e76118904a9a97522f26db9e5b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac94d01d93b64c95990fa7ce1874ea13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718d5d55420442bd8a38d11a847e36c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bf81597b124a12a1c8c25757bf5ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-large\"  \n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=6,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Create the train/validation/test split\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['message'].values, \n",
    "    df['label'].values, \n",
    "    test_size=0.3,  # 30% for val+test\n",
    "    random_state=42, \n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,  # 50% of the 30% (so 15% of total)\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 370 samples\n",
      "Validation set: 79 samples\n",
      "Test set: 80 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set: {len(train_texts)} samples\")\n",
    "print(f\"Validation set: {len(val_texts)} samples\")\n",
    "print(f\"Test set: {len(test_texts)} samples\")\n",
    "# display(train_texts)\n",
    "# display(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tokenizing: this part is also the same as the one in the N03 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Analyzing message lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per message: 26.5\n",
      "Maximum tokens in a message: 326\n",
      "97% of messages have 79.5 tokens or fewer\n"
     ]
    }
   ],
   "source": [
    "# Cell 4.5: Analyze message lengths to set appropriate max_length\n",
    "def get_token_counts(texts):\n",
    "    # Count tokens in each message\n",
    "    token_counts = [len(tokenizer.encode(text)) for text in texts]\n",
    "    return token_counts\n",
    "\n",
    "token_counts = get_token_counts(df['message'].values)\n",
    "\n",
    "# Calculate statistics\n",
    "avg_tokens = sum(token_counts) / len(token_counts)\n",
    "max_tokens = max(token_counts)\n",
    "p97_tokens = np.percentile(token_counts, 97)  # 97th percentile\n",
    "\n",
    "print(f\"Average tokens per message: {avg_tokens:.1f}\")\n",
    "print(f\"Maximum tokens in a message: {max_tokens}\")\n",
    "print(f\"97% of messages have {p97_tokens:.1f} tokens or fewer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Visualizing distributionof messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting max_length to 128\n"
     ]
    }
   ],
   "source": [
    "# Visualize distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(token_counts, bins=20)\n",
    "plt.axvline(x=p97_tokens, color='r', linestyle='--', label='97th percentile')\n",
    "plt.xlabel('Number of tokens')\n",
    "plt.ylabel('Count of messages')\n",
    "plt.title('Distribution of token counts in F1 radio messages')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Set max_length based on analysis\n",
    "max_length = int(min(128, 2 * p97_tokens))  # Conservative value based on 97th percentile\n",
    "print(f\"Setting max_length to {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Tokenizing and making the encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Tokenize the data directly\n",
    "max_length = 128\n",
    "#batch_size = 16\n",
    "batch_size = 4\n",
    "# Tokenize training data\n",
    "train_encodings = tokenizer(\n",
    "    list(train_texts),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=max_length,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Tokenize validation data\n",
    "val_encodings = tokenizer(\n",
    "    list(val_texts),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=max_length,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Tokenize test data\n",
    "test_encodings = tokenizer(\n",
    "    list(test_texts),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=max_length,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tokens for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_15468\\439425289.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_15468\\439425289.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_labels = torch.tensor(val_labels)\n",
      "C:\\Users\\victo\\AppData\\Local\\Temp\\ipykernel_15468\\439425289.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = torch.tensor(test_labels)\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'],\n",
    "    train_encodings['attention_mask'],\n",
    "    train_labels\n",
    ")\n",
    "\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'],\n",
    "    val_encodings['attention_mask'],\n",
    "    val_labels\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'],\n",
    "    test_encodings['attention_mask'],\n",
    "    test_labels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataLoaders with batch size: 4\n",
      "Each batch contains: 4 samples\n",
      "Input shape: torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f\"Created DataLoaders with batch size: {batch_size}\")\n",
    "print(f\"Each batch contains: {next(iter(train_dataloader))[0].shape[0]} samples\")\n",
    "print(f\"Input shape: {next(iter(train_dataloader))[0].shape}\")\n",
    "\n",
    "from torch.amp import GradScaler, autocast\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setting up training process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    \"\"\"\n",
    "    Computes accuracy by comparing predictions with labels.\n",
    "    \n",
    "    Args:\n",
    "        preds: Model prediction matrix (logits)\n",
    "        labels: Vector of true labels\n",
    "    \n",
    "    Returns:\n",
    "        float: Percentage of correct predictions\n",
    "    \"\"\"\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    \"\"\"\n",
    "    Formats elapsed time into a readable format.\n",
    "    \n",
    "    Args:\n",
    "        elapsed: Time in seconds\n",
    "        \n",
    "    Returns:\n",
    "        str: Time formatted as HH:MM:SS\n",
    "    \"\"\"\n",
    "    return str(datetime.timedelta(seconds=int(round(elapsed))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for training statistics\n",
    "training_stats = []\n",
    "best_val_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\miniconda3\\envs\\f1_strat_manager\\lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "learning_rate = 1e-5  # A bet less for a bigger model\n",
    "weight_decay = 0.01\n",
    "warmup_steps = int(0.1 * len(train_dataloader) * epochs)  # 10% steps for warmup\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=learning_rate,\n",
    "                  eps=1e-8,\n",
    "                  weight_decay=weight_decay)\n",
    "\n",
    "# Set up the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                          num_warmup_steps=warmup_steps,\n",
    "                                          num_training_steps=total_steps)\n",
    "# Gradient accumulation for simulating bigger batch_size\n",
    "gradient_accumulation_steps = 4  \n",
    "# This simulates an effective batch_size of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "Class 0 (INFORMATION): 0.4167\n",
      "Class 1 (PROBLEM): 0.8114\n",
      "Class 2 (ORDER): 0.8222\n",
      "Class 3 (STRATEGY): 2.5694\n",
      "Class 4 (WARNING): 2.5694\n",
      "Class 5 (QUESTION): 2.6812\n"
     ]
    }
   ],
   "source": [
    "# Calculating the 6 class weights\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "\n",
    "unique_labels = np.unique(train_labels.numpy())\n",
    "class_weights = compute_class_weight('balanced', classes=unique_labels, y=train_labels.numpy())\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for i, weight in enumerate(class_weights):\n",
    "    intent_name = list(intent_mapping.keys())[list(intent_mapping.values()).index(i)]\n",
    "    print(f\"Class {i} ({intent_name}): {weight:.4f}\")\n",
    "\n",
    "# Loss function with weights\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/12\n",
      "  Training loss: 1.8010\n",
      "  Training time: 0:00:10\n",
      "  Validation accuracy: 0.4208\n",
      "  Validation loss: 1.7626\n",
      "  Saved new best model with accuracy: 0.4208\n",
      "\n",
      "Epoch 2/12\n"
     ]
    }
   ],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch_i + 1}/{epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Reset gradients at the beginning of each epoch\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack batch and move to device\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "    \n",
    "        # Forward pass with mixed precision - corrected\n",
    "        with autocast(device_type='cuda'):  # Specify 'cuda' as device_type\n",
    "            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass with mixed precision\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Update total loss\n",
    "        total_train_loss += loss.item() * gradient_accumulation_steps\n",
    "        \n",
    "        # Update weights every gradient_accumulation_steps\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            # Update parameters\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"  Training loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Training time: {format_time(time.time() - t0)}\")\n",
    "    \n",
    "    # Validation with mixed precision as well\n",
    "    model.eval()\n",
    "    val_accuracy = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_attention_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, b_labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += flat_accuracy(logits.cpu().numpy(), b_labels.cpu().numpy())\n",
    "    \n",
    "    avg_val_accuracy = val_accuracy / len(val_dataloader)\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    \n",
    "    print(f\"  Validation accuracy: {avg_val_accuracy:.4f}\")\n",
    "    print(f\"  Validation loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = avg_val_accuracy\n",
    "        torch.save(model.state_dict(), '../../outputs/week4/models/best_roberta_large_intent_model.pt')\n",
    "        print(f\"  Saved new best model with accuracy: {best_val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " INFORMATION       0.70      0.52      0.59        31\n",
      "     PROBLEM       0.50      0.56      0.53        16\n",
      "       ORDER       0.56      0.56      0.56        16\n",
      "    STRATEGY       0.33      0.33      0.33         6\n",
      "     WARNING       0.33      0.60      0.43         5\n",
      "    QUESTION       0.57      0.80      0.67         5\n",
      "\n",
      "    accuracy                           0.54        79\n",
      "   macro avg       0.50      0.56      0.52        79\n",
      "weighted avg       0.57      0.54      0.55        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Al final del entrenamiento, agrega este cÃ³digo\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Recolectar todas las predicciones y etiquetas\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        all_preds.extend(np.argmax(logits.cpu().numpy(), axis=1))\n",
    "        all_labels.extend(b_labels.cpu().numpy())\n",
    "\n",
    "# Crear informe de clasificaciÃ³n\n",
    "intent_names = list(intent_mapping.keys())\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=intent_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "val_accuracy = 0\n",
    "val_loss = 0\n",
    "\n",
    "# En la parte de validaciÃ³n:\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with autocast(device_type='cuda'):  # Especificar 'cuda' como device_type\n",
    "            outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        val_accuracy += flat_accuracy(logits.cpu().numpy(), b_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages\n",
    "avg_val_accuracy = val_accuracy / len(val_dataloader)\n",
    "avg_val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "print(f\"  Validation accuracy: {avg_val_accuracy:.4f}\")\n",
    "print(f\"  Validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Store stats\n",
    "training_stats.append({\n",
    "    'epoch': epoch_i + 1,\n",
    "    'train_loss': avg_train_loss,\n",
    "    'val_loss': avg_val_loss,\n",
    "    'val_accuracy': avg_val_accuracy\n",
    "})\n",
    "\n",
    "\n",
    "#################### NOTE: ONLY UNCOMMENT AND RUN IF BETTER METRICS ARE MET #########################\n",
    "# Save best model\n",
    "if avg_val_accuracy > best_val_accuracy:\n",
    "    best_val_accuracy = avg_val_accuracy\n",
    "    torch.save(model.state_dict(), '../../outputs/week4/models/best_roberta_intention_model.pt')\n",
    "    print(f\"  Saved new best model with accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Training complete! Total time: {format_time(time.time() - total_t0)}\")\n",
    "print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# In validation loop:\n",
    "predictions = np.argmax(logits.cpu().numpy(), axis=1)\n",
    "labels = b_labels.cpu().numpy()\n",
    "f1 = f1_score(labels, predictions, average='weighted')\n",
    "print(f\"  F1 score (weighted): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After validation:\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        all_preds.extend(np.argmax(logits.cpu().numpy(), axis=1))\n",
    "        all_labels.extend(b_labels.cpu().numpy())\n",
    "\n",
    "# Get intent names for labels\n",
    "intent_names = list(intent_mapping.keys())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=intent_names,\n",
    "            yticklabels=intent_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Intent Classification')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report with proper class names\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=intent_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
