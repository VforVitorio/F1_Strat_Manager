{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Transcrtiption using Whisper\n",
    "\n",
    "This notebook will implement the necessary code for making the transcription of all our team message radios.\n",
    "\n",
    "\n",
    "First, I need to **import the modules** and **verifying cuda is detecting my GPU**:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import whisper\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting my Whisper model\n",
    "\n",
    "For selecting the Whisper model, I have to take into account the VRAM of my Graphic card. It has 8gb of VRAM, therefore, I´ll use the **Whisper Medium Model**. Below there is a table with all the models available for Whisper:\n",
    "\n",
    "| Model     | Size (GB) | Parameters | VRAM Required |\n",
    "|----------|----------|------------|--------------|\n",
    "| tiny     | ~0.07 GB | 39M        | ~1 GB       |\n",
    "| base     | ~0.14 GB | 74M        | ~1.5 GB     |\n",
    "| small    | ~0.46 GB | 244M       | ~2.5 GB     |\n",
    "| medium   | ~1.5 GB  | 769M       | ~5 GB       |\n",
    "| large-v1 | ~2.9 GB  | 1550M      | ~10 GB      |\n",
    "| large-v2 | ~2.9 GB  | 1550M      | ~12 GB      |\n",
    "\n",
    "However, for not overloading the graphic card, I´ll use **float point 16 of torch** instead of fp32. It may have less performance, but it is still a good option and I can save resources with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading audio files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(audio_dir = \"../../f1-strategy/data/audio\"):\n",
    "    \"\"\"\n",
    "    Load all audio files from the directory structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_dir : str\n",
    "        Path to the main audio directory that contains driver subdirectories\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries containing audio file paths and metadata\n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "\n",
    "\n",
    "    # Find all driver directories. For this, we use driver_* for matching every directory\n",
    "\n",
    "    driver_dirs = glob.glob(os.path.join(audio_dir, 'driver_*'))\n",
    "\n",
    "    for driver_dir in driver_dirs:\n",
    "        # Extract the driver number out of the directory name\n",
    "\n",
    "        driver_num = os.path.basename(driver_dir).replace('driver_(', '').replace(',)', '')\n",
    "        # Find all audio files in this driver directory.\n",
    "        # For now, only mp3 is in our directory. \n",
    "        # However, we add all those extensions if the directory changes in the future\n",
    "        files = glob.glob(os.path.join(driver_dir, '*.mp3')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.wav')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.m4a')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.ogg'))\n",
    "        \n",
    "        for file_path in files:\n",
    "            # Get the filename without the extension\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            # Add to the list of audio files\n",
    "            audio_files.append(\n",
    "                {\n",
    "                    \"driver\": driver_num,\n",
    "                    \"file_path\": file_path,\n",
    "                    \"filename\": filename\n",
    "                }\n",
    "            )\n",
    "    print(f\"Found {len(audio_files)} audio files across {len(driver_dir)} driver directories\")\n",
    "\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I´ll store all this audio files in a variable for transcribing them with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 audio files across 41 driver directories\n",
      "\n",
      "First 5 audio files\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_39.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_40.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_60.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_62.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_63.mp3\n"
     ]
    }
   ],
   "source": [
    "# EXECUTION CELL\n",
    "\n",
    "audio_files = load_audio_files()\n",
    "\n",
    "# Display the first few files with a simple verifying\n",
    "if audio_files:\n",
    "    print(\"\\nFirst 5 audio files\")\n",
    "    for file in audio_files[:5]:\n",
    "        print(f\"Driver: {file['driver']}, File: {file['filename']}\")\n",
    "else:\n",
    "    print(\"No audio files found. Check the path or add more debugging messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribring the audios with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_files(audio_files, model_name=\"medium\", output_csv=\"../outputs/week4/radios_raw.csv\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio files using Whisper and save one entry per file.\n",
    "    \"\"\"\n",
    "    # Load Whisper model\n",
    "    print(f\"Loading Whisper {model_name} model...\")\n",
    "    model = whisper.load_model(model_name)\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Process each audio file\n",
    "    print(f\"Transcribing {len(audio_files)} audio files...\")\n",
    "    for i, audio_file in enumerate(audio_files):\n",
    "        try:\n",
    "            print(f\"Processing file {i+1}/{len(audio_files)}: {audio_file['filename']}\")\n",
    "            \n",
    "            # Normalize file path\n",
    "            file_path = os.path.normpath(audio_file['file_path'])\n",
    "            \n",
    "            # Load audio file\n",
    "            audio, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "            \n",
    "            # Get audio duration\n",
    "            duration = librosa.get_duration(y=audio, sr=sr)\n",
    "            \n",
    "            # Perform transcription \n",
    "            result = model.transcribe(audio, task=\"transcribe\", language=\"en\", fp16=torch.cuda.is_available())\n",
    "            \n",
    "            # Combine all segments into a single text\n",
    "            full_text = \" \".join([segment[\"text\"].strip() for segment in result[\"segments\"]])\n",
    "            \n",
    "            # Add a single entry for the entire file\n",
    "            results.append({\n",
    "                'driver': audio_file['driver'],\n",
    "                'filename': audio_file['filename'],\n",
    "                'file_path': file_path,\n",
    "                'text': full_text,\n",
    "                'duration': duration\n",
    "            })\n",
    "                \n",
    "            # Print the transcription\n",
    "            print(f\"Full transcription: {full_text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file['filename']}: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(df)} transcriptions to {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick test with the tiny model to see everything is working fine\n",
    "\n",
    "Now is commented because everything worked as expected. A radio_test csv was correctly made in week 4 folder with the full transcription of our radios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create output directory if it doesn't exist\n",
    "# os.makedirs(\"../../outputs/week4\", exist_ok=True)\n",
    "\n",
    "# # Test with just a few files first to ensure everything works\n",
    "# if audio_files:\n",
    "#     test_files = audio_files[:2]  # Just take the first 2 files for a quick test\n",
    "#     print(f\"Testing transcription with {len(test_files)} files...\")\n",
    "#     test_df = transcribe_audio_files(\n",
    "#         test_files, \n",
    "#         model_name=\"tiny\",  # Use the tiny model for quick testing\n",
    "#         output_csv=\"../../outputs/week4/radios_test.csv\"\n",
    "#     )\n",
    "    \n",
    "#     # Show the results\n",
    "#     print(\"\\nTranscription test results:\")\n",
    "#     print(test_df.head())\n",
    "# else:\n",
    "#     print(\"No audio files available for transcription\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribing all the audios\n",
    "\n",
    "Now I will tarnscribe all the audios using the Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking GPU availability...\n",
      "✅ GPU available: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CUDA version: 12.4\n"
     ]
    }
   ],
   "source": [
    "# Check again if the GPU is being used. It can take a long time,\n",
    "#  so I need to be sure that the gpu is being used,\n",
    "\n",
    "# It should be detected with one of the first cells of the code, but debugging does not harm\n",
    "print(\"Checking GPU availability...\")\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"✅ GPU available: {gpu_name}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    use_gpu = True\n",
    "else:\n",
    "    print(\"❌ No GPU detected. Using CPU (will be much slower)\")\n",
    "    use_gpu = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing all audio files with medium model...\n",
      "Loading Whisper medium model...\n"
     ]
    }
   ],
   "source": [
    "# Only run this cell when knowing everythig is fine\n",
    "print(\"Transcribing all audio files with medium model...\")\n",
    "full_df = transcribe_audio_files(\n",
    "    audio_files,\n",
    "    model_name=\"medium\",  # Using medium model for better quality\n",
    "    output_csv=\"../../outputs/week4/radios_raw.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\nFull transcription complete!\")\n",
    "print(f\"Total segments: {len(full_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
