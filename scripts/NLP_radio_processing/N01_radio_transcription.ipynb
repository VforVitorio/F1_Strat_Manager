{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radio Transcrtiption using Whisper\n",
    "\n",
    "This notebook will implement the necessary code for making the transcription of all our team message radios.\n",
    "\n",
    "\n",
    "First, I need to **import the modules** and **verifying cuda is detecting my GPU**:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import whisper\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading audio files\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(audio_dir = \"../../f1-strategy/data/audio\"):\n",
    "    \"\"\"\n",
    "    Load all audio files from the directory structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    audio_dir : str\n",
    "        Path to the main audio directory that contains driver subdirectories\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of dictionaries containing audio file paths and metadata\n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "\n",
    "\n",
    "    # Find all driver directories. For this, we use driver_* for matching every directory\n",
    "\n",
    "    driver_dirs = glob.glob(os.path.join(audio_dir, 'driver_*'))\n",
    "\n",
    "    for driver_dir in driver_dirs:\n",
    "        # Extract the driver number out of the directory name\n",
    "\n",
    "        driver_num = os.path.basename(driver_dir).replace('driver_(', '').replace(',)', '')\n",
    "        # Find all audio files in this driver directory.\n",
    "        # For now, only mp3 is in our directory. \n",
    "        # However, we add all those extensions if the directory changes in the future\n",
    "        files = glob.glob(os.path.join(driver_dir, '*.mp3')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.wav')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.m4a')) + \\\n",
    "                glob.glob(os.path.join(driver_dir, '*.ogg'))\n",
    "        \n",
    "        for file_path in files:\n",
    "            # Get the filename without the extension\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            # Add to the list of audio files\n",
    "            audio_files.append(\n",
    "                {\n",
    "                    \"driver\": driver_num,\n",
    "                    \"file_path\": file_path,\n",
    "                    \"filename\": filename\n",
    "                }\n",
    "            )\n",
    "    print(f\"Found {len(audio_files)} audio files across {len(driver_dir)} driver directories\")\n",
    "\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, IÂ´ll store all this audio files in a variable for transcribing them with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 audio files across 41 driver directories\n",
      "\n",
      "First 5 audio files\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_39.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_40.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_60.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_62.mp3\n",
      "Driver: 1, File: driver_(1,)_belgium_radio_63.mp3\n"
     ]
    }
   ],
   "source": [
    "# EXECUTION CELL\n",
    "\n",
    "audio_files = load_audio_files()\n",
    "\n",
    "# Display the first few files with a simple verifying\n",
    "if audio_files:\n",
    "    print(\"\\nFirst 5 audio files\")\n",
    "    for file in audio_files[:5]:\n",
    "        print(f\"Driver: {file['driver']}, File: {file['filename']}\")\n",
    "else:\n",
    "    print(\"No audio files found. Check the path or add more debugging messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribring the audios with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_files(audio_files, model_name=\"medium\", output_csv=\"../outputs/week4/radios_raw.csv\"):\n",
    "    \"\"\"\n",
    "    Transcribe audio files using Whisper and save one entry per file.\n",
    "    \"\"\"\n",
    "    # Load Whisper model\n",
    "    print(f\"Loading Whisper {model_name} model...\")\n",
    "    model = whisper.load_model(model_name)\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Process each audio file\n",
    "    print(f\"Transcribing {len(audio_files)} audio files...\")\n",
    "    for i, audio_file in enumerate(audio_files):\n",
    "        try:\n",
    "            print(f\"Processing file {i+1}/{len(audio_files)}: {audio_file['filename']}\")\n",
    "            \n",
    "            # Normalize file path\n",
    "            file_path = os.path.normpath(audio_file['file_path'])\n",
    "            \n",
    "            # Load audio file\n",
    "            audio, sr = librosa.load(file_path, sr=16000, mono=True)\n",
    "            \n",
    "            # Get audio duration\n",
    "            duration = librosa.get_duration(y=audio, sr=sr)\n",
    "            \n",
    "            # Perform transcription \n",
    "            result = model.transcribe(audio, task=\"transcribe\", language=\"en\", fp16=torch.cuda.is_available())\n",
    "            \n",
    "            # Combine all segments into a single text\n",
    "            full_text = \" \".join([segment[\"text\"].strip() for segment in result[\"segments\"]])\n",
    "            \n",
    "            # Add a single entry for the entire file\n",
    "            results.append({\n",
    "                'driver': audio_file['driver'],\n",
    "                'filename': audio_file['filename'],\n",
    "                'file_path': file_path,\n",
    "                'text': full_text,\n",
    "                'duration': duration\n",
    "            })\n",
    "                \n",
    "            # Print the transcription\n",
    "            print(f\"Full transcription: {full_text}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file['filename']}: {str(e)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    print(f\"Saved {len(df)} transcriptions to {output_csv}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick test with the tiny model to see everything is working fine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing transcription with 2 files...\n",
      "Loading Whisper tiny model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\miniconda3\\envs\\f1_strat_manager\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing 2 audio files...\n",
      "Processing file 1/2: driver_(1,)_belgium_radio_39.mp3\n",
      "Full transcription: So don't forget about Sisihe please. Are we both doing a lot? You just follow my instruction. Cute. Don't want to know what's going on to it. Max, please follow my instruction and trust it. Thank you.\n",
      "Processing file 2/2: driver_(1,)_belgium_radio_40.mp3\n",
      "Full transcription: Okay, back to our 20th grade, about 9 or 10 minutes. What do you thought? Can you get there or should we box? We need to box this last. To cover the land. I can't see the weather, we don't.\n",
      "Saved 2 transcriptions to ../../outputs/week4/radios_test.csv\n",
      "\n",
      "Transcription test results:\n",
      "  driver                          filename  \\\n",
      "0      1  driver_(1,)_belgium_radio_39.mp3   \n",
      "1      1  driver_(1,)_belgium_radio_40.mp3   \n",
      "\n",
      "                                           file_path  \\\n",
      "0  ..\\..\\f1-strategy\\data\\audio\\driver_(1,)\\drive...   \n",
      "1  ..\\..\\f1-strategy\\data\\audio\\driver_(1,)\\drive...   \n",
      "\n",
      "                                                text  duration  \n",
      "0  So don't forget about Sisihe please. Are we bo...    15.168  \n",
      "1  Okay, back to our 20th grade, about 9 or 10 mi...    15.576  \n"
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(\"../../outputs/week4\", exist_ok=True)\n",
    "\n",
    "# Test with just a few files first to ensure everything works\n",
    "if audio_files:\n",
    "    test_files = audio_files[:2]  # Just take the first 2 files for a quick test\n",
    "    print(f\"Testing transcription with {len(test_files)} files...\")\n",
    "    test_df = transcribe_audio_files(\n",
    "        test_files, \n",
    "        model_name=\"tiny\",  # Use the tiny model for quick testing\n",
    "        output_csv=\"../../outputs/week4/radios_test.csv\"\n",
    "    )\n",
    "    \n",
    "    # Show the results\n",
    "    print(\"\\nTranscription test results:\")\n",
    "    print(test_df.head())\n",
    "else:\n",
    "    print(\"No audio files available for transcription\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once you've verified the test works correctly\n",
    "\n",
    "# Uncomment the following lines to process all files\n",
    "# print(\"Transcribing all audio files with medium model...\")\n",
    "# full_df = transcribe_audio_files(\n",
    "#     audio_files,\n",
    "#     model_name=\"medium\",  # Using medium model for better quality\n",
    "#     output_csv=\"../outputs/week4/radios_raw.csv\"\n",
    "# )\n",
    "# \n",
    "# print(\"\\nFull transcription complete!\")\n",
    "# print(f\"Total segments: {len(full_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
