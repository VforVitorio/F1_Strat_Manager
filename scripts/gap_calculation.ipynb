{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: Gap Calculation using YOLO net and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import time as pytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-3): 4 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(384, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(576, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1152, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-1): 2 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(576, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(192, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the Anti-Alpine optimized model\n",
    "model = YOLO(\"../f1-strategy/weights/model_anti_alpine.pt\")\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size and scale configuration\n",
    "FRAME_WIDTH = 1280  # Higher resolution for better detail\n",
    "CAR_LENGTH_METERS = 5.63  # Real car length in meters\n",
    "\n",
    "# FOR GAPS: use a lower global threshold to maximize detections\n",
    "GAP_DETECTION_THRESHOLD = 0.25  # Low threshold to detect all possible cars\n",
    "\n",
    "# Specific colors for each F1 team (BGR format for OpenCV)\n",
    "class_colors = {\n",
    "    'Ferrari': (0, 0, 255),         # Red (BGR)\n",
    "    'Mercedes': (200, 200, 200),    # Silver (BGR)\n",
    "    'Red Bull': (139, 0, 0),        # Dark Blue (BGR)\n",
    "    'McLaren': (0, 165, 255),       # Orange (BGR)\n",
    "    'Aston Martin': (0, 128, 0),    # Green (BGR)\n",
    "    'Alpine': (128, 0, 0),          # Blue (BGR)\n",
    "    'Williams': (205, 0, 0),        # Light Blue (BGR)\n",
    "    'Haas': (255, 255, 255),        # White (BGR)\n",
    "    'Kick Sauber': (255, 255, 0),   # Cyan (BGR)\n",
    "    'Racing Bulls': (0, 0, 255),    # Red (BGR)\n",
    "    'background': (128, 128, 128),  # Gray (BGR)\n",
    "    'unknown': (0, 255, 255)        # Yellow for cars without secure classification\n",
    "}\n",
    "\n",
    "# Thresholds to show classification (not for filtering detections)\n",
    "class_thresholds = {\n",
    "    'Williams': 0.90,     # Very high for Williams\n",
    "    'Alpine': 0.90,       # Extremely high for Alpine\n",
    "    'McLaren': 0.30,      # Low for McLaren\n",
    "    'Red Bull': 0.85,     # High for Red Bull\n",
    "    'Ferrari': 0.40,      # Normal\n",
    "    'Mercedes': 0.50,     # Medium-high\n",
    "    'Haas': 0.40,         # Normal\n",
    "    'Kick Sauber': 0.40,  # Normal\n",
    "    'Racing Bulls': 0.40, # Normal\n",
    "    'Aston Martin': 0.40, # Normal\n",
    "    'background': 0.50    # High for background\n",
    "}\n",
    "\n",
    "# Detection history for stabilization\n",
    "last_detections = {}\n",
    "track_history = {}\n",
    "id_counter = 0\n",
    "class_history = {}\n",
    "\n",
    "def calculate_gap(box1, box2, class1, class2):\n",
    "    \"\"\"Calculates the distance between centers using car width for scale\"\"\"\n",
    "    # Box centers\n",
    "    cx1, cy1 = (box1[0] + box1[2])/2, (box1[1] + box1[3])/2\n",
    "    cx2, cy2 = (box2[0] + box2[2])/2, (box2[1] + box2[3])/2\n",
    "    \n",
    "    # Distance in pixels\n",
    "    pixel_distance = np.hypot(cx2 - cx1, cy2 - cy1)\n",
    "    \n",
    "    # Scale based on average width of detected cars\n",
    "    avg_width = ((box1[2] - box1[0]) + (box2[2] - box2[0])) / 2\n",
    "    scale = CAR_LENGTH_METERS / avg_width if avg_width != 0 else 0\n",
    "    \n",
    "    # Calculate gap time at 300km/h (83.33 m/s)\n",
    "    speed_mps = 83.33  # Meters per second at 300km/h\n",
    "    gap_time = (pixel_distance * scale) / speed_mps\n",
    "    \n",
    "    return {\n",
    "        'distance': pixel_distance * scale,  # Distance in meters\n",
    "        'time': gap_time,                   # Time in seconds at 300km/h\n",
    "        'car1': class1,                     # Team of first car\n",
    "        'car2': class2                      # Team of second car\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_yolo(video_path, output_path=None):\n",
    "    global last_detections, track_history, id_counter, class_history, GAP_DETECTION_THRESHOLD\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get original video dimensions\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    current_frame = 0\n",
    "    \n",
    "    # Calculate new height maintaining aspect ratio\n",
    "    target_height = int(FRAME_WIDTH * original_height / original_width)\n",
    "    \n",
    "    out = None\n",
    "    if output_path:\n",
    "        # Change codec from 'mp4v' to 'XVID' which is more reliable\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (FRAME_WIDTH, target_height))\n",
    "        if not out.isOpened():\n",
    "            print(f\"Error: Could not create output video file at {output_path}\")\n",
    "            print(\"Continuing without saving output...\")\n",
    "            output_path = None\n",
    "    \n",
    "    # Variables for calculating real FPS\n",
    "    frame_count = 0\n",
    "    start_time = pytime.time()\n",
    "    current_fps = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        current_frame += 1\n",
    "        \n",
    "        # Resize maintaining aspect ratio\n",
    "        frame_resized = cv2.resize(frame, (FRAME_WIDTH, target_height))\n",
    "        original_frame = frame_resized.copy()\n",
    "        \n",
    "        # Run YOLOv8 detection with low threshold to maximize detections\n",
    "        results = model.predict(\n",
    "            source=frame_resized, \n",
    "            conf=GAP_DETECTION_THRESHOLD,  # Low threshold to detect all possible cars\n",
    "            iou=0.45,   # Standard IoU\n",
    "            max_det=20, # Maximum detections\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        # Current detections\n",
    "        current_detections = {}\n",
    "        \n",
    "        # Process detection results\n",
    "        if results.boxes and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            confs = results.boxes.conf.cpu().numpy()\n",
    "            class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # Create detection list with all information\n",
    "            detections = []\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                conf = float(confs[i])\n",
    "                class_id = int(class_ids[i])\n",
    "                cls_name = model.names[class_id]\n",
    "                \n",
    "                # Determine whether to show team classification based on threshold\n",
    "                # Note: we still detect the car but might not show its team\n",
    "                classified = conf >= class_thresholds.get(cls_name, 0.40)\n",
    "                \n",
    "                # KEY: For gaps, we detect all cars even if we're not sure of the team\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                # Assign unique ID or retrieve existing ID\n",
    "                object_id = None\n",
    "                for old_id, old_info in last_detections.items():\n",
    "                    old_cx, old_cy = old_info['center']\n",
    "                    old_cls = old_info['class']\n",
    "                    \n",
    "                    # Distance between centers\n",
    "                    dist = np.sqrt((center_x - old_cx)**2 + (center_y - old_cy)**2)\n",
    "                    \n",
    "                    # If it's close, it could be the same object\n",
    "                    if dist < 100:\n",
    "                        object_id = old_id\n",
    "                        \n",
    "                        # If previous class was valid and new one is uncertain, keep the previous one\n",
    "                        if old_info['classified'] and not classified:\n",
    "                            cls_name = old_cls\n",
    "                            classified = True\n",
    "                        \n",
    "                        # Stabilize classification with history for problematic classes\n",
    "                        if classified and old_cls != cls_name and (cls_name == 'Williams' or cls_name == 'Alpine'):\n",
    "                            if old_info['classified']:\n",
    "                                cls_name = old_cls\n",
    "                        break\n",
    "                \n",
    "                # If no match found, assign new ID\n",
    "                if object_id is None:\n",
    "                    object_id = id_counter\n",
    "                    id_counter += 1\n",
    "                    track_history[object_id] = []\n",
    "                    class_history[object_id] = []\n",
    "                \n",
    "                # Update history\n",
    "                if object_id in class_history:\n",
    "                    # Only add to history if we're sure of the class\n",
    "                    if classified:\n",
    "                        class_history[object_id].append(cls_name)\n",
    "                        # Limit history to 5 classes\n",
    "                        if len(class_history[object_id]) > 5:\n",
    "                            class_history[object_id].pop(0)\n",
    "                    \n",
    "                    # Use the most common class from history for stability\n",
    "                    if len(class_history[object_id]) >= 3:\n",
    "                        counts = Counter(class_history[object_id])\n",
    "                        if counts:  # Make sure it's not empty\n",
    "                            most_common = counts.most_common(1)[0][0]\n",
    "                            cls_name = most_common\n",
    "                            classified = True\n",
    "                \n",
    "                # Save current detection\n",
    "                current_detections[object_id] = {\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'conf': conf,\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'center': (center_x, center_y),\n",
    "                    'area': area,\n",
    "                    'y_bottom': y2  # For sorting by vertical position\n",
    "                }\n",
    "                \n",
    "                # Add to detection list for gap calculation\n",
    "                detections.append({\n",
    "                    'id': object_id,\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'conf': conf,\n",
    "                    'y_bottom': y2\n",
    "                })\n",
    "            \n",
    "            # Sort by vertical position (cars more below first - closer)\n",
    "            detections = sorted(detections, key=lambda x: x['y_bottom'], reverse=True)\n",
    "            \n",
    "            # Draw boxes and gaps\n",
    "            for i, det in enumerate(detections):\n",
    "                x1, y1, x2, y2 = det['box']\n",
    "                cls_name = det['class']\n",
    "                conf = det['conf']\n",
    "                classified = det['classified']\n",
    "                \n",
    "                # Get specific color for the team\n",
    "                if classified:\n",
    "                    color = class_colors.get(cls_name, (0, 255, 0))\n",
    "                else:\n",
    "                    color = class_colors['unknown']  # Yellow for cars without secure classification\n",
    "                \n",
    "                # Draw box with team color\n",
    "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Label with class and confidence\n",
    "                if classified:\n",
    "                    label = f\"{cls_name}: {conf:.2f}\"\n",
    "                else:\n",
    "                    label = f\"F1 Car: {conf:.2f}\"\n",
    "                \n",
    "                t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                cv2.rectangle(frame_resized, (x1, y1-t_size[1]-3), (x1+t_size[0], y1), color, -1)\n",
    "                cv2.putText(frame_resized, label, (x1, y1-3), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Only if there's a next car\n",
    "                if i < len(detections)-1:\n",
    "                    next_det = detections[i+1]\n",
    "                    gap_info = calculate_gap(\n",
    "                        det['box'], next_det['box'], \n",
    "                        det['class'] if det['classified'] else \"F1 Car\", \n",
    "                        next_det['class'] if next_det['classified'] else \"F1 Car\"\n",
    "                    )\n",
    "                    \n",
    "                    # Connection points\n",
    "                    cx1, cy1 = int((x1+x2)/2), int(y1)  # Use top of the car\n",
    "                    nx1, ny1, nx2, ny2 = next_det['box']\n",
    "                    cx2, cy2 = int((nx1+nx2)/2), int(ny2)  # Use bottom of the next car\n",
    "                    \n",
    "                    # Diagonal line between cars\n",
    "                    cv2.line(frame_resized, (cx1, cy1), (cx2, cy2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Text at midpoint with more information\n",
    "                    mid_x, mid_y = (cx1+cx2)//2, (cy1+cy2)//2\n",
    "                    \n",
    "                    # Distance and gap time\n",
    "                    dist_text = f\"{gap_info['distance']:.1f}m\"\n",
    "                    time_text = f\"{gap_info['time']:.2f}s\"\n",
    "                    \n",
    "                    # Background for text\n",
    "                    dist_size = cv2.getTextSize(dist_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    time_size = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    \n",
    "                    # Draw semi-transparent background\n",
    "                    overlay = frame_resized.copy()\n",
    "                    cv2.rectangle(overlay, \n",
    "                                 (mid_x - 5, mid_y - 50), \n",
    "                                 (mid_x + max(dist_size[0], time_size[0]) + 10, mid_y + 10),\n",
    "                                 (0, 0, 0), -1)\n",
    "                    cv2.addWeighted(overlay, 0.6, frame_resized, 0.4, 0, frame_resized)\n",
    "                    \n",
    "                    # Draw texts\n",
    "                    cv2.putText(frame_resized, dist_text, (mid_x, mid_y - 25),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                    cv2.putText(frame_resized, time_text, (mid_x, mid_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Update last_detections for next iteration\n",
    "        last_detections = current_detections\n",
    "        \n",
    "        # Calculate FPS\n",
    "        if frame_count % 10 == 0:\n",
    "            current_time = pytime.time()\n",
    "            current_fps = 10.0 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "        \n",
    "        # Show FPS and model information\n",
    "        cv2.putText(frame_resized, f\"FPS: {current_fps:.1f}\", (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame_resized, \"F1 Gap Detection\", (FRAME_WIDTH - 300, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show detection mode and progress\n",
    "        detection_mode = f\"Detection Threshold: {GAP_DETECTION_THRESHOLD:.2f}\"\n",
    "        cv2.putText(frame_resized, detection_mode, (20, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show video progress\n",
    "        progress_text = f\"Frame: {current_frame}/{total_frames} ({current_frame/total_frames*100:.1f}%)\"\n",
    "        cv2.putText(frame_resized, progress_text, (FRAME_WIDTH - 400, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Save processed frame if requested\n",
    "        if output_path:\n",
    "            out.write(frame_resized)\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow(\"F1 Gap Detection\", frame_resized)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('+'):  # Increase threshold\n",
    "            GAP_DETECTION_THRESHOLD = min(GAP_DETECTION_THRESHOLD + 0.05, 0.95)\n",
    "            print(f\"Detection threshold increased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('-'):  # Decrease threshold\n",
    "            GAP_DETECTION_THRESHOLD = max(GAP_DETECTION_THRESHOLD - 0.05, 0.05)\n",
    "            print(f\"Detection threshold decreased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('d'):  # Skip forward 10 seconds\n",
    "            skip_frames = int(fps * 10)  # 10 seconds * fps = number of frames to skip\n",
    "            new_frame_pos = min(current_frame + skip_frames, total_frames - 1)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame_pos)\n",
    "            current_frame = new_frame_pos - 1  # Will be incremented in the next cycle\n",
    "            # Temporarily reset tracking\n",
    "            last_detections = {}\n",
    "            print(f\"Skipped forward 10 seconds to frame {new_frame_pos}\")\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped forward 10 seconds to frame 623\n",
      "Skipped forward 10 seconds to frame 1131\n",
      "Skipped forward 10 seconds to frame 1631\n",
      "Skipped forward 10 seconds to frame 2131\n"
     ]
    }
   ],
   "source": [
    "# Run with your video\n",
    "def main():\n",
    "    #video_path = \"../f1-strategy/data/videos/best_overtakes_2023.mp4.f399.mp4\"\n",
    "    #video_path = \"../f1-strategy/data/videos/spain_2023_race.mp4.f399.mp4\"\n",
    "    \n",
    "    video_path = \"../f1-strategy/data/videos/belgium_gp.f399.mp4\"\n",
    "    output_path = \"../f1-strategy/data/videos/gap_detection_output.mp4\"\n",
    "    process_video_with_yolo(video_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controls\n",
    "\n",
    "'q': out\n",
    "'+': more detection threshold\n",
    "'-': less detection threshold\n",
    "'d': 10 seconds ahead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gap Extraction "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
