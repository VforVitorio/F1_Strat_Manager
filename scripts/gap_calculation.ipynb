{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision: Gap Calculation using YOLO net and OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped forward 10 seconds to frame 570\n",
      "Skipped forward 10 seconds to frame 1124\n",
      "Skipped forward 10 seconds to frame 1655\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from collections import Counter\n",
    "import time as pytime\n",
    "\n",
    "# Utilizar GPU si está disponible\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Cargar el modelo Anti-Alpine optimizado\n",
    "model = YOLO(\"../f1-strategy/weights/model_anti_alpine.pt\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Configuración de tamaño y escala\n",
    "FRAME_WIDTH = 1280  # Mayor resolución para mejor detalle\n",
    "CAR_LENGTH_METERS = 5.63  # Longitud real del coche en metros\n",
    "\n",
    "# PARA GAPS: usar un umbral global más bajo para maximizar detecciones\n",
    "GAP_DETECTION_THRESHOLD = 0.25  # Umbral bajo para detectar todos los coches posibles\n",
    "\n",
    "# Colores específicos para cada equipo de F1 (formato BGR para OpenCV)\n",
    "class_colors = {\n",
    "    'Ferrari': (0, 0, 255),         # Rojo (BGR)\n",
    "    'Mercedes': (200, 200, 200),    # Plateado (BGR)\n",
    "    'Red Bull': (139, 0, 0),        # Azul oscuro (BGR)\n",
    "    'McLaren': (0, 165, 255),       # Naranja (BGR)\n",
    "    'Aston Martin': (0, 128, 0),    # Verde (BGR)\n",
    "    'Alpine': (128, 0, 0),          # Azul (BGR)\n",
    "    'Williams': (205, 0, 0),        # Azul claro (BGR)\n",
    "    'Haas': (255, 255, 255),        # Blanco (BGR)\n",
    "    'Kick Sauber': (255, 255, 0),   # Cian (BGR)\n",
    "    'Racing Bulls': (0, 0, 255),    # Rojo (BGR)\n",
    "    'background': (128, 128, 128),  # Gris (BGR)\n",
    "    'unknown': (0, 255, 255)        # Amarillo para coches sin clasificación segura\n",
    "}\n",
    "\n",
    "# Umbrales para mostrar la clasificación (no para filtrar detecciones)\n",
    "class_thresholds = {\n",
    "    'Williams': 0.90,     # Muy alto para Williams\n",
    "    'Alpine': 0.90,       # Extremadamente alto para Alpine\n",
    "    'McLaren': 0.30,      # Bajo para McLaren\n",
    "    'Red Bull': 0.85,     # Alto para Red Bull\n",
    "    'Ferrari': 0.40,      # Normal\n",
    "    'Mercedes': 0.50,     # Medio-alto\n",
    "    'Haas': 0.40,         # Normal\n",
    "    'Kick Sauber': 0.40,  # Normal\n",
    "    'Racing Bulls': 0.40, # Normal\n",
    "    'Aston Martin': 0.40, # Normal\n",
    "    'background': 0.50    # Alto para fondo\n",
    "}\n",
    "\n",
    "# Historial de detecciones para estabilización\n",
    "last_detections = {}\n",
    "track_history = {}\n",
    "id_counter = 0\n",
    "class_history = {}\n",
    "\n",
    "def calculate_gap(box1, box2, class1, class2):\n",
    "    \"\"\"Calcula la distancia entre centros usando el ancho de los coches para la escala\"\"\"\n",
    "    # Centros de las cajas\n",
    "    cx1, cy1 = (box1[0] + box1[2])/2, (box1[1] + box1[3])/2\n",
    "    cx2, cy2 = (box2[0] + box2[2])/2, (box2[1] + box2[3])/2\n",
    "    \n",
    "    # Distancia en píxeles\n",
    "    pixel_distance = np.hypot(cx2 - cx1, cy2 - cy1)\n",
    "    \n",
    "    # Escala basada en el ancho promedio de los coches detectados\n",
    "    avg_width = ((box1[2] - box1[0]) + (box2[2] - box2[0])) / 2\n",
    "    scale = CAR_LENGTH_METERS / avg_width if avg_width != 0 else 0\n",
    "    \n",
    "    # Calcular tiempo de gap a 300km/h (83.33 m/s)\n",
    "    speed_mps = 83.33  # Metros por segundo a 300km/h\n",
    "    gap_time = (pixel_distance * scale) / speed_mps\n",
    "    \n",
    "    return {\n",
    "        'distance': pixel_distance * scale,  # Distancia en metros\n",
    "        'time': gap_time,                   # Tiempo en segundos a 300km/h\n",
    "        'car1': class1,                     # Equipo del primer coche\n",
    "        'car2': class2                      # Equipo del segundo coche\n",
    "    }\n",
    "\n",
    "def process_video_with_yolo(video_path, output_path=None):\n",
    "    global last_detections, track_history, id_counter, class_history, GAP_DETECTION_THRESHOLD\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error al abrir el video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Obtener dimensiones originales del video\n",
    "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    current_frame = 0\n",
    "    \n",
    "    # Calcular nuevo alto manteniendo la relación de aspecto\n",
    "    target_height = int(FRAME_WIDTH * original_height / original_width)\n",
    "    \n",
    "    # Configurar salida si se solicita\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (FRAME_WIDTH, target_height))\n",
    "    \n",
    "    # Variables para calcular FPS real\n",
    "    frame_count = 0\n",
    "    start_time = pytime.time()\n",
    "    current_fps = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        current_frame += 1\n",
    "        \n",
    "        # Redimensionar manteniendo la relación de aspecto\n",
    "        frame_resized = cv2.resize(frame, (FRAME_WIDTH, target_height))\n",
    "        original_frame = frame_resized.copy()\n",
    "        \n",
    "        # Ejecutar la detección con YOLOv8 con umbral bajo para maximizar detecciones\n",
    "        results = model.predict(\n",
    "            source=frame_resized, \n",
    "            conf=GAP_DETECTION_THRESHOLD,  # Umbral bajo para detectar todos los coches posibles\n",
    "            iou=0.45,   # IoU estándar\n",
    "            max_det=20, # Máximo de detecciones\n",
    "            verbose=False\n",
    "        )[0]\n",
    "        \n",
    "        # Detecciones actuales\n",
    "        current_detections = {}\n",
    "        \n",
    "        # Procesar resultados de la detección\n",
    "        if results.boxes and len(results.boxes) > 0:\n",
    "            boxes = results.boxes.xyxy.cpu().numpy()\n",
    "            confs = results.boxes.conf.cpu().numpy()\n",
    "            class_ids = results.boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            # Crear lista de detecciones con toda la información\n",
    "            detections = []\n",
    "            for i, box in enumerate(boxes):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                conf = float(confs[i])\n",
    "                class_id = int(class_ids[i])\n",
    "                cls_name = model.names[class_id]\n",
    "                \n",
    "                # Determinar si mostrar la clasificación del equipo basado en umbral\n",
    "                # Nota: seguimos detectando el coche pero podríamos no mostrar su equipo\n",
    "                classified = conf >= class_thresholds.get(cls_name, 0.40)\n",
    "                \n",
    "                # CLAVE: Para gaps, detectamos todos los coches incluso si no estamos seguros del equipo\n",
    "                center_x = (x1 + x2) // 2\n",
    "                center_y = (y1 + y2) // 2\n",
    "                area = (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                # Asignar ID único o recuperar ID existente\n",
    "                object_id = None\n",
    "                for old_id, old_info in last_detections.items():\n",
    "                    old_cx, old_cy = old_info['center']\n",
    "                    old_cls = old_info['class']\n",
    "                    \n",
    "                    # Distancia entre centros\n",
    "                    dist = np.sqrt((center_x - old_cx)**2 + (center_y - old_cy)**2)\n",
    "                    \n",
    "                    # Si está cerca, podría ser el mismo objeto\n",
    "                    if dist < 100:\n",
    "                        object_id = old_id\n",
    "                        \n",
    "                        # Si la clase anterior era válida y la nueva es incierta, mantener la anterior\n",
    "                        if old_info['classified'] and not classified:\n",
    "                            cls_name = old_cls\n",
    "                            classified = True\n",
    "                        \n",
    "                        # Estabilizar la clasificación con el historial para clases problemáticas\n",
    "                        if classified and old_cls != cls_name and (cls_name == 'Williams' or cls_name == 'Alpine'):\n",
    "                            if old_info['classified']:\n",
    "                                cls_name = old_cls\n",
    "                        break\n",
    "                \n",
    "                # Si no se encontró correspondencia, asignar nuevo ID\n",
    "                if object_id is None:\n",
    "                    object_id = id_counter\n",
    "                    id_counter += 1\n",
    "                    track_history[object_id] = []\n",
    "                    class_history[object_id] = []\n",
    "                \n",
    "                # Actualizar historial\n",
    "                if object_id in class_history:\n",
    "                    # Solo añadir al historial si estamos seguros de la clase\n",
    "                    if classified:\n",
    "                        class_history[object_id].append(cls_name)\n",
    "                        # Limitar historial a 5 clases\n",
    "                        if len(class_history[object_id]) > 5:\n",
    "                            class_history[object_id].pop(0)\n",
    "                    \n",
    "                    # Usar la clase más común del historial para estabilidad\n",
    "                    if len(class_history[object_id]) >= 3:\n",
    "                        counts = Counter(class_history[object_id])\n",
    "                        if counts:  # Asegurarse que no está vacío\n",
    "                            most_common = counts.most_common(1)[0][0]\n",
    "                            cls_name = most_common\n",
    "                            classified = True\n",
    "                \n",
    "                # Guardar detección actual\n",
    "                current_detections[object_id] = {\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'conf': conf,\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'center': (center_x, center_y),\n",
    "                    'area': area,\n",
    "                    'y_bottom': y2  # Para ordenar por posición vertical\n",
    "                }\n",
    "                \n",
    "                # Añadir a lista de detecciones para cálculo de gaps\n",
    "                detections.append({\n",
    "                    'id': object_id,\n",
    "                    'box': (x1, y1, x2, y2),\n",
    "                    'class': cls_name,\n",
    "                    'classified': classified,\n",
    "                    'conf': conf,\n",
    "                    'y_bottom': y2\n",
    "                })\n",
    "            \n",
    "            # Ordenar por posición vertical (coches más abajo primero - más cercanos)\n",
    "            detections = sorted(detections, key=lambda x: x['y_bottom'], reverse=True)\n",
    "            \n",
    "            # Dibujar cajas y gaps\n",
    "            for i, det in enumerate(detections):\n",
    "                x1, y1, x2, y2 = det['box']\n",
    "                cls_name = det['class']\n",
    "                conf = det['conf']\n",
    "                classified = det['classified']\n",
    "                \n",
    "                # Obtener color específico para el equipo\n",
    "                if classified:\n",
    "                    color = class_colors.get(cls_name, (0, 255, 0))\n",
    "                else:\n",
    "                    color = class_colors['unknown']  # Amarillo para coches sin clasificación segura\n",
    "                \n",
    "                # Dibujar caja con color del equipo\n",
    "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                # Etiqueta con clase y confianza\n",
    "                if classified:\n",
    "                    label = f\"{cls_name}: {conf:.2f}\"\n",
    "                else:\n",
    "                    label = f\"F1 Car: {conf:.2f}\"\n",
    "                \n",
    "                t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "                cv2.rectangle(frame_resized, (x1, y1-t_size[1]-3), (x1+t_size[0], y1), color, -1)\n",
    "                cv2.putText(frame_resized, label, (x1, y1-3), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "                # Solo si hay siguiente coche\n",
    "                if i < len(detections)-1:\n",
    "                    next_det = detections[i+1]\n",
    "                    gap_info = calculate_gap(\n",
    "                        det['box'], next_det['box'], \n",
    "                        det['class'] if det['classified'] else \"F1 Car\", \n",
    "                        next_det['class'] if next_det['classified'] else \"F1 Car\"\n",
    "                    )\n",
    "                    \n",
    "                    # Puntos de conexión\n",
    "                    cx1, cy1 = int((x1+x2)/2), int(y1)  # Usar parte superior del coche\n",
    "                    nx1, ny1, nx2, ny2 = next_det['box']\n",
    "                    cx2, cy2 = int((nx1+nx2)/2), int(ny2)  # Usar parte inferior del siguiente\n",
    "                    \n",
    "                    # Línea diagonal entre coches\n",
    "                    cv2.line(frame_resized, (cx1, cy1), (cx2, cy2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Texto en el punto medio con más información\n",
    "                    mid_x, mid_y = (cx1+cx2)//2, (cy1+cy2)//2\n",
    "                    \n",
    "                    # Distancia y tiempo de gap\n",
    "                    dist_text = f\"{gap_info['distance']:.1f}m\"\n",
    "                    time_text = f\"{gap_info['time']:.2f}s\"\n",
    "                    \n",
    "                    # Fondo para el texto\n",
    "                    dist_size = cv2.getTextSize(dist_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    time_size = cv2.getTextSize(time_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    \n",
    "                    # Dibujar fondo semitransparente\n",
    "                    overlay = frame_resized.copy()\n",
    "                    cv2.rectangle(overlay, \n",
    "                                 (mid_x - 5, mid_y - 50), \n",
    "                                 (mid_x + max(dist_size[0], time_size[0]) + 10, mid_y + 10),\n",
    "                                 (0, 0, 0), -1)\n",
    "                    cv2.addWeighted(overlay, 0.6, frame_resized, 0.4, 0, frame_resized)\n",
    "                    \n",
    "                    # Dibujar textos\n",
    "                    cv2.putText(frame_resized, dist_text, (mid_x, mid_y - 25),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                    cv2.putText(frame_resized, time_text, (mid_x, mid_y),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Actualizar last_detections para la próxima iteración\n",
    "        last_detections = current_detections\n",
    "        \n",
    "        # Calcular FPS\n",
    "        if frame_count % 10 == 0:\n",
    "            current_time = pytime.time()\n",
    "            current_fps = 10.0 / (current_time - start_time)\n",
    "            start_time = current_time\n",
    "        \n",
    "        # Mostrar FPS e información del modelo\n",
    "        cv2.putText(frame_resized, f\"FPS: {current_fps:.1f}\", (20, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame_resized, \"F1 Gap Detection\", (FRAME_WIDTH - 300, 40),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Mostrar modo de detección y progreso\n",
    "        detection_mode = f\"Detection Threshold: {GAP_DETECTION_THRESHOLD:.2f}\"\n",
    "        cv2.putText(frame_resized, detection_mode, (20, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Mostrar progreso del video\n",
    "        progress_text = f\"Frame: {current_frame}/{total_frames} ({current_frame/total_frames*100:.1f}%)\"\n",
    "        cv2.putText(frame_resized, progress_text, (FRAME_WIDTH - 400, target_height - 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Guardar frame procesado si se solicitó\n",
    "        if output_path:\n",
    "            out.write(frame_resized)\n",
    "        \n",
    "        # Mostrar frame\n",
    "        cv2.imshow(\"F1 Gap Detection\", frame_resized)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('+'):  # Aumentar umbral\n",
    "            GAP_DETECTION_THRESHOLD = min(GAP_DETECTION_THRESHOLD + 0.05, 0.95)\n",
    "            print(f\"Detection threshold increased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('-'):  # Disminuir umbral\n",
    "            GAP_DETECTION_THRESHOLD = max(GAP_DETECTION_THRESHOLD - 0.05, 0.05)\n",
    "            print(f\"Detection threshold decreased to {GAP_DETECTION_THRESHOLD:.2f}\")\n",
    "        elif key == ord('d'):  # Avanzar 10 segundos\n",
    "            skip_frames = int(fps * 10)  # 10 segundos * fps = número de frames a saltar\n",
    "            new_frame_pos = min(current_frame + skip_frames, total_frames - 1)\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame_pos)\n",
    "            current_frame = new_frame_pos - 1  # Se incrementará en el próximo ciclo\n",
    "            # Reiniciar tracking temporalmente\n",
    "            last_detections = {}\n",
    "            print(f\"Skipped forward 10 seconds to frame {new_frame_pos}\")\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Ejecutar con tu video\n",
    "def main():\n",
    "    #video_path = \"../f1-strategy/data/videos/best_overtakes_2023.mp4.f399.mp4\"\n",
    "    #video_path = \"../f1-strategy/data/videos/spain_2023_race.mp4.f399.mp4\"\n",
    "    \n",
    "    video_path = \"../f1-strategy/data/videos/belgium_gp.f399.mp4\"\n",
    "    output_path = \"../f1-strategy/data/videos/gap_detection_output.mp4\"\n",
    "    process_video_with_yolo(video_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controls\n",
    "\n",
    "'q': out\n",
    "'+': more detection threshold\n",
    "'-': less detection threshold\n",
    "'d': 10 seconds ahead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_strat_manager",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
